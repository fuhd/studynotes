Apache Lucene简介
==============================================================
在接触ElasticSearch提供的各种令人激动的功能之前，仍然要对Apache Lucene有一个快速了解，
因为ElasticSearch使用开源全文检索库Lucene进行索引和搜索。

### Lucene的总体架构
这些概念需要提前了解，以便更好地理解Lucene的架构，它们包括：
+ **文档（document）**：索引与搜索的主要 **数据载体**，它 **包含一个或多个字段**，存放将要写入索引或将从索引搜索出来的数据。
+ **字段（field）**：文档的一个 **片段**，它包括两个部分：**字段的名称** 和 **内容**。
+ **词项（term）**：搜索时的一个单位，代表 **文本中的某个词**。
+ **词条（token）**：词项在字段中的一次出现，包括 **词项的文本，开始和结束的位移以及类型**。

Apache Lucene将写入索引的所有信息组织成一种名为 **倒排索引**（inverted index）的结构。
该结构是一种 **将词项映射到文档的数据结构**，你大可以认为倒排索引是面向词项而不是面向文档的。

我们来看看简单的倒排索引是什么样的。例如，我们有一些只包含title字段的文档，如下所示：
+ ElasticSearch Server（文档1）
+ MasteringElasticSearch（文档2）
+ Apache solr 4 Cookbook（文档3）

而索引后的结构示意图如下：

| 词项 | 计数 | 文档 |
| :--  | :-- | :---|
| 4 | 1 | <3> |
| Apache | 1 | <3> |
| Cookbook | 1 | <3> |
| ElasticSearch | 2 | <1><2> |
| Mastering | 1 | <2> |
| Server | 1 | <1> |
| solr | 1 | <3> |

当然，实际中Lucene创建的索引更为复杂，也更先进，因为索引中还存储了很多其他信息，如词向量（为单个字段创建的小索引，
存储该字段中所有的词条），各字段的原始信息，文档删除标记等。然而，你只需知道Lucene索引中数据是如何组织的
即可，而不用知道到底存储了哪些东西。

每个索引由多个 **段（segment）** 组成，每个段只会被创建一次但会被查询多次。索引期间，段经创建就不会再被修改。
例如，文档被删除以后，删除信息被单独保存在一个文件中，而段本身并没有修改。

多个段会在一个叫作 **段合并（segments merge）的阶段** 被合并在一起，而且要么强制执行，要么由Lucene
的内在机制决定在某个时刻执行，合并后段的数量更少，但是更大。**段合并非常耗I/O，且合并期间有些不再使用的信息
也将被清理掉**，例如，被删除的文档。对于容纳相同数据的索引，段的数量较少时，搜索速度更快。尽管如此，
还是需要强调一下：**因为段合并非常耗I/O，请不要强制进行段合并，你只需要仔细配置段合并策略，剩余的事情Lucene会自行搞定**。

### 分析你的数据
读者也许会好奇，文档中的数据是如何转化为倒排索引的，而查询串又是如何转换为可用于搜索的词项的？这个转换过程称为分析。
**文本文件由分析器来执行**，而 **分析器** 由 **分词器**（tokenizer），**过滤器**（filter）和 **字符映射器**
（character mapper）组成。

`Lucene`的 **分词器** 用来将文本切割成 **词条**，其中携带各种额外信息的 **词项**，这些信息包括：词项在原始文本中的位置，
词项的长度。分词器的工作成果称为 **词条流**，因为这些词条被一个接一个地推送给 **过滤器** 处理。

除了分词器，**过滤器** 也是`Lucene`分析器的组成部分，过滤器 **数量可选**，可以为0个，1个或多个，用于处理词条流中的词条。
例如，它可以移除，修改词条流中的词条，甚至可以创造新的词条。`Lucene`提供了很多现成的过滤器，你也可以根据需要实现
新的过滤器。以下是一些过滤器的例子：
+ **小写过滤器：** 将所有词条转化为小写。
+ **ASCII过滤器：** 移除词条中所有非ASCII字符。
+ **同义词过滤器：** 根据同义词规则，将一个词条转化为另一个词条。

当分析器中有多个过滤器时，会逐个处理，理论上可以有无限多个过滤器。

最后我们介绍下 **字符映射器**，它用于调用分词器之前的 **文本预处理操作**，如HTML文本的去标签处理。
