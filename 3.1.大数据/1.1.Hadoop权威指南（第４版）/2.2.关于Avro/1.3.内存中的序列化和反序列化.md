内存中的序列化和反序列化
================================================================================
Avro为序列化和反序列化提供了一些API，如果想把Avro集成到现有系统（比如已定义帧格式的消息系统），
这些API函数就很有用，而对于其他情况，请考虑使用Avro的数据文件格式。

让我们 **写一个Java程序来从数据流读/写Avro数据**。首先以一个简单的Avro模式为例，它用于表示以
记录形式出现的一对字符串：
```json
{
  "type": "record"
  "name": "StringPair"
  "doc": "A pair of strings."
  "fields": [
    {"name": "left", "type": "string"}
    {"name": "right", "type": "string"}
  ]
}
```
如果此模式存储在类路径下一个名为`StringPair.avsc`的文件中（`.avsc`是Avro模式文件的常用扩展
名），我们可以通过下面的两行代码进行加载：
```java
Schema.Parser parser = new Schema.Parser();
Schema schema = parser.parse(getClass().getResourceAsStream("StringPair.avsc"));
```
可以使用以下的通用API新建一个Avro记录实例：
```java
GenericRecord datum = new GenericData.Record(schema);
datum.put("left", "L");
datum.put("right", "R");
```
接下来，**我们将记录序列化到输出流中**：
```java
ByteArrayOutputStream out = new ByteArrayOutputStream();
DatumWriter<GenericRecord> writer = new GenericDatumWriter<GenericRecord>(schema);
Encoder encoder = EncoderFactory.get().binaryEncoder(out, null);
writer.write(datum, encoder);
encoder.flush();
out.close();
```
其中有两个重要的对象：**DatumWriter** 和 **Encoder**。DatumWriter对象将数据对象翻译成
Encoder对象可以理解的类型，然后由后者写入输出流。这里，我们使用了 **GenericDatumWriter** 对
象，它将GenericRecord字段的值传递给Encoder对象。由于没有重用先前构建的encoder，此处我们将
null传递encoder工厂。

在本例中，只有一个对象需要写到输出流，但如果需要写若干个对象，可以调用`write()`方法，然后再关闭
输入流。

我们需要将该模式传递给GenericDatumWriter对象，因为它会根据模式来确定将数据对象中的哪些数值写到
输出流。在调用writer的`write()`方法后刷新encoder，然后关闭输出流。

我们也可以 **使用反向的处理过程来从字节缓冲区中读回对象**：
```java
DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(schema);
Decoder decoder = DecoderFactory.get().binaryDecoder(out.toByteArray(), null);
GenericRecord result = reader.read(null, decoder);
assertThat(result.get("left").toString(), is("L"));
assertThat(result.get("right").toString(), is("R"));
```































dd
