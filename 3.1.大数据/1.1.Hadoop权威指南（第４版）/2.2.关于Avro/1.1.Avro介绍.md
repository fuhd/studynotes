Avro介绍
================================================================================
**Apache Avro**(h`ttp://avro.apache.org/`)是一个独立于编程语言的 **数据序列化系统**。该
项目由`Doug Cutting`（`Hadoop`之父）创建，**旨在解决Hadoop中Writable类型的不足：缺乏语言的
可移植性**。拥有一个可被多种语言（当前是`C`、`C++`、`C#`、`Java`、`PHP`、`Python`和`Ruby`）
处理的数据格式与绑定到单一语言的数据格式相比，前者更易于与公众共享数据集。

**但为什么要有一个新的数据序列化系统**？与Apache Thrift和Google的Protocol Buffers相比，
Avro有其独有的特性。与前述系统及其他系统相似，**Avro数据是用语言无关的模式定义的。但与其他系统
不同的是，在Avro中，代码生成是可选的，这意味着你可以对遵循指定模式的数据进行读/写操作，即使在此
之前代码从来没有见过这个特殊的数据模式。为此，Avro假设数据模式总是存在的（在读/写数据时），它形
成的是非常精简的编码，因为编码后的数值不需要用字段标识符来打标签**。

**Avro模式通常用JSON来写，数据通常采用二进制格式编码**。但也有其他选择。还有一种高级语言称为
**Avro IDL**，可以使用开发人员更为熟悉的 **类C语言** 来写模式。还有一个 **基于JSON的数据编码
方式**（对构建原型和调试Avro数据很有用，因为它是我们人类可读的）。

**Avro规范**（`http://avro.apache.org/docs/current/spec.html`）对所有实现都必须支持的
二进制格式进行了精确定义，同时还指定这些实现需要支持的其他Avro特性。但是，该规范并没有为API制定
规范：实现可以根据自己的需求操作Avro数据并给出相关的API，因为每个API都与语言相关。重要的二进制
格式只有一种这一事实意味着绑定新的编程语言的门槛比较低，可以避免语言与格式组合爆炸问题，否则将对
互操作性造成一定的问题。

**Avro有丰富的模式解析（schema resolution）能力。在精心定义的约束条件下，读数据所用的模式不必
与写数据所有的模式相同。由此，Avro是支持模式演化的**。例如，**如果有一个新的、可选择的字段要加入
记录中，那么只需在用来读取老数据的模式中声明它即可。新客户端和以前的客户端非常相似，均能读取按旧
模式存储的数据，同时新的客户端可以使用新字段写入新的内容。相反，如果老客户端读取新客户端写入的数
据，会忽略新加入的字段并按照先前的数据模式处理**。

Avro为一系列的对象指定了一个对象容器格式，类似于Hadoop的顺序文件。**Avro数据文件包含元数据项
（模式数据存储其中），使此文件可以自我声明。Avro数据文件支持压缩，并且是可切分的，这对MapReduce
的输入格式至关重要**。对Avro的支持远不止于MapReduce，事实上本书中所有的数据处理框架（Pig、Hive、
Crunch、Spark）都能读/写Avro数据文件。

**`Avro`还可用于`RPC`**。                                    
