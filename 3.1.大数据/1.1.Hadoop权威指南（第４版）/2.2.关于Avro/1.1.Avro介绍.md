Avro介绍
================================================================================
**Apache Avro**(http://avro.apache.org/)是一个独立于编程语言的 **数据序列化系统**。该项
目由`Doug Cutting`（`Hadoop`之父）创建，**旨在解决Hadoop中Writable类型的不足：缺乏语言的
可移植性**。拥有一个可被多种语言（当前是`C`、`C++`、`C#`、`Java`、`PHP`、`Python`和`Ruby`）
处理的数据格式与绑定到单一语言的数据格式相比，前者更易于与公众共享数据集。

**但为什么要有一个新的数据序列化系统**？与Apache Thrift和Google的Protocol Buffers相比，
Avro有其独有的特性。与前述系统及其他系统相似，**Avro数据是用语言无关的模式定义的。但与其他系统
不同的是，在Avro中，代码生成是可选的，这意味着你可以对遵循指定模式的数据进行读/写操作，即使在此
之前代码从来没有见过这个特殊的数据模式。为此，Avro假设数据模式总是存在的（在读/写数据时），它形
成的是非常精简的编码，因为编码后的数值不需要用字段标识符来打标签**。

**Avro模式通常用JSON来写，数据通常采用二进制格式编码**。但也有其他选择。还有一种高级语言称为
**Avro IDL**，可以使用开发人员更为熟悉的 **类C语言** 来写模式。还有一个 **基于JSON的数据编码
方式**（对构建原型和调试Avro数据很有用，因为它是我们人类可读的）。

**`Avro`规范（`http://avro.apache.org/docs/current/spec.html`）对所有实现都必须支持的二进制格式
进行了精确定义，同时还指定这些实现需要支持的其他`Avro`特性。但是，该规范并没有为`API`制定规范：实现可以根据
自己的需求操作`Avro`数据并给出相关的`API`，因为每个`API`都与语言相关**。重要的二进制格式只有一种这一事实意味
着绑定新的编程语言的门槛比较低，可以避免语言与格式组合爆炸问题，否则将对互操作性造成一定的问题。

**`Avro`有丰富的模式解析（`schema resolution`）能力。在精心定义的约束条件下，读数据所用的模式不必与写数据
所有的模式相同。由此，`Avro`是支持模式演化的**。例如，**如果有一个新的、可选择的字段要加入记录中，那么只需在用来
读取老数据的模式中声明它即可。新客户端和以前的客户端非常相似，均能读取按旧模式存储的数据，同时新的客户端可以使用
新字段写入新的内容。相反，如果老客户端读取新客户端写入的数据，会忽略新加入的字段并按照先前的数据模式处理**。

`Avro`为一系列的对象指定了一个对象容器格式，类似于`Hadoop`的顺序文件。**`Avro`数据文件包含元数据项（模式数据存储
其中），使此文件可以自我声明。`Avro`数据文件支持压缩，并且是可切分的，这对`MapReduce`的输入格式至关重要**。
对`Avro`的支持远不止于`MapReduce`，事实上本书中所有的数据处理框架（`Pig`、`Hive`、`Crunch`、`Spark`）
都能读/写`Avro`数据文件。

**`Avro`还可用于`RPC`**。                                    
