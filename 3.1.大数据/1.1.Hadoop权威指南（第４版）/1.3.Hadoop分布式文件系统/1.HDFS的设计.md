HDFS的设计
================================================================================
当数据集的大小超过一台独立的物理计算机的存储能力时，就有必要对它进行分区（partition）并存储到若
干台单独的计算机上。管理网络中跨多台计算机存储的文件系统称为 **分布式文件系统（distributed
filesystem）**。

Hadoop自带一个称为 **HDFS** 的分布式文件系统，即 **Hadoop Distributed Filesystem**。

**HDFS以流式数据访问模式来存储超大文件**，运行于商用硬件集群上。
+ **超大文件**：“超大文件”在这里指具有几百MB、几百GB甚至几百TB大小的文件。目前已经有存储PB级数
据的Hadoop集群了。
+ **流式数据访问**：**HDFS的构建思路是这样的：一次写入、多次读取是最高效的访问模式**。数据集通
常由数据源生成或从数据源复制而来，接着长时间在此数据集上进行各种分析。**每次分析都将涉及该数据集
的大部分数据甚至全部**，因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。
+ **商用硬件**：Hadoop并不需要运行在昂贵且高可靠的硬件上。它是设计运行在 **商用硬件（在各种零
售店都能买到的普通硬件）** 的集群上的，因此至少对于庞大的集群来说，节点故障的几率还是非常高的。
**HDFS遇到上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断**。

同样，那些不适合在HDFS上运行的应用也值得研究。**目前HDFS对某些应用领域并不适合**，不过以后可能
会有所改进。
+ **低时间延迟的数据访问**：要求低时间延迟数据访问的应用，例如几十毫秒范围，不适合在HDFS上运行。
记住，**HDFS是为高数据吞吐量应用优化的**，这可能会以提高时间延迟为代价。目前，**对于低延迟的访
问需求，HBase是更好的选择**。
+ **大量的小文件**：**由于namenode将文件系统的元数据存储在内存中，因此该文件系统所能存储的文件
总数受限于namenode的内存容量**。根据经验，**每个文件、目录和数据块的存储信息大约占150字节**。
因此，举例来说，如果有一百万个文件，且每个文件占一个数据块，那至少需要300MB的内存。尽管存储上百
万个文件是可行的，但是存储数十亿个文件就超出了当前硬件的能力。
+ **多用户写入，任意修改文件**：**HDFS中的文件写入只支持单个写入者，而且写操作总是以“只添加”方
式在文件末尾写数据。它不支持多个写入者的操作，也不支持在文件的任意位置进行修改**。
