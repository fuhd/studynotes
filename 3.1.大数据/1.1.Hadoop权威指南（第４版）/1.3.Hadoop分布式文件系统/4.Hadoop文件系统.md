Hadoop文件系统
================================================================================
**Hadoop有一个抽象的文件系统概念，HDFS只是其中的一个实现**。Java抽象类
**org.apache.hadoop.fs.FileSystem定义了Hadoop中一个文件系统的客户端接口，并且该抽象类有几
个具体实现**，其中和Hadoop紧密相关的见下表：

| 文件系统 | URI方案 | Java实现（都在org.apache.hadoop包中）| 描述 |
|:--------|:-------|:----------------------------------|:-----|
| **Local** | **file** | **fs.LocalFileSystem** | 使用客户端校验和的本地磁盘文件系统。使用RawLocalFileSystem表示无校验和的本地磁盘文件系统 |
| **HDFS** | **hdfs** | **hdfs.DistributedFileSystem** | Hadoop的分布式文件系统。将HDFS设计成与MapReduce结合使用，可以实现高性能 |
| **WebHDFS** | **Webhdfs** | **Hdfs.web.WebHdfsFileSystem** | 基于HTTP的文件系统，提供对HDFS的认证读/写访问 |
| **Secure WebHDFS** | **swebhdfs** | **hdfs.web.SWebHdfsFileSystem** | WebHDFS的HTTPS版本 |
| **HAR** | **har** | **fs.HarFileSystem** | 一个构建在其他文件系统之上用于文件存档的文件系统。Hadoop存档文件系统通常用于将HDFS中的多个文件打包成一个存档文件，以减少namenode内存的使用。使用hadoop的achive命令来创建HAR文件 |
| **View** | **viewfs** | **viewfs.ViewFileSystem** | 针对其他Hadoop文件系统的客户端挂载表。通常用于为联邦namenode创建挂载点 |
| **FTP** | **ftp** | **fs.ftp.FTPFileSystem** | 由FTP服务器支持的文件系统 |
| S3 | S3a | fs.s3a.S3AFileSystem | 由Amazon S3支持的文件系统。替代老版本的s3n（S3原生）实现 |
| Azure | wasb | fs.azure.NativeAzureFileSystem | 由Microsoft Azure支持的文件系统 |
| Swift | swift | fs.swift.snative.SwiftNativeFileSystem | 由OpenStack  Swift支持的文件系统 |

尽管运行的MapReduce程序可以访问任何文件系统（有时也很方便），但在处理大数据集时，**建议你还是选
择一个有数据本地优化的分布式文件系统，如HDFS**。

## 接口
Hadoop是用Java写的，通过Java API可以调用大部分Hadoop文件系统的交互操作。例如，文件系统的命令
解释器就是一个Java应用，它使用Java的FileSystem类来提供文件系统操作。其他一些文件系统接口也将在
本小节中做简单介绍。这些接口通常与HDFS一同使用，因为Hadoop中的其它文件系统一般都有访问基本文件
系统的工具（对于FTP，有FTP客户端；对于S3，有S3工具，等等），但它们大多数都能用于任何Hadoop文件
系统。

### 1.HTTP
Hadoop以Java API的形式提供文件系统访问接口，非Java开发的应用访问HDFS会很不方便。**由WebHDFS
协议提供的HTTP REST API则使得其他语言开发的应用能够更方便地与HDFS交互**。注意，**HTTP接口比
原生的Java客户端要慢，所以不到万不得已，尽量不要用它来传输特大数据**。

通过HTTP来访问HDFS有 **两种方法：直接访问**，HDFS守护进程直接服务于来自客户端的HTTP请求；**通
过代理（一个或多个）访问**，客户端通常使用DistributedFileSystem API访问HDFS。因为这种接口使
用较少，所以不做详细的说明了。

### 2.C语言
Hadoop提供了一个名为libhdfs的C语言库，该语言库是Java FileSystem接口类的一个镜像（它被写成访
问HDFS的C语言库，但其实它可以访问任何一个Hadoop文件系统）。它使用Java原生接口（JNI，Java
Native Interface）调用Java文件系统客户端。同样还有一个libwebhdfs库，该库使用了前述章节描述
的WebHDFS接口。

这个C语言API与Java的API非常相似，**但它的开发滞后于Java API，因此目前一些新的特性可能还不支持**。

### 3.NFS
使用Hadoop的 **NFSv3网关** 将HDFS挂载为本地客户端的文件系统是可行的。然后你可以使用Unix实用
程序（如ls和cat）与该文件系统交互，上传文件，通过任意一种编程语言调用POSIX库来访问文件系统。由于
 **HDFS仅能以追加模式写文件，因此可以往文件末尾添加数据，但不能随机修改文件**。

### 4.FUSE
**用户空间文件系统**（FUSE,`FileSystem in Userspace`）允许将用户空间实现的文件系统作为Unix
文件系统进行集成。通过使用Hadoop的Fuse-DFS功能模块，HDFS（或任何一个Hadoop文件系统）均可以作
为一个标准的文本文件系统进行挂载。**Fuse-DFS是用C语言实现的，使用libhdfs作为访问HDFS的接口**。
在写操作时，Hadoop NFS网关对于挂载HDFS来说是更键壮的解决方案，相比Fure-DFS而言应优先选择。
