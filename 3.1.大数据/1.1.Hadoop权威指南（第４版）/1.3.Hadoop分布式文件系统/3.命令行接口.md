命令行接口
================================================================================
现在我们通过命令行交互来进一步认识HDFS。HDFS还有很多其他接口，但命令行是最简单的，同时也是许多开
发者最熟悉的。

在我们设置为 **分布配置** 时，有两个属性项需要进一步解释。**第一项是fs.defaultFS**，设置为
`hdfs://localhost/`，**用于设置Hadoop的默认文件系统**。文件系统是由URI指定的，这里我们已使
用hdfs URI来配置HDFS为Hadoop的默认文件系统。**HDFS的守护程序通过该属性来确定HDFS namenode
的主机及端口**。我们将在localhost默认的HDFS端口 **8020** 上运行namenode。这样一来，HDFS客
户端可以通过该属性得知namenode在哪里运行进而连接到它。

**第二个属性dfs.replication，我们设为1，这样一来，HDFS就不会按默认设置将文件系统块复本设置为
3。在单独一个datanode上运行时，HDFS无法将块复制到3个datanode上，所以会持续给出块复本不足的警
告**。设置这个属性之后，上述问题就不会在出现了。

## 文件系统的基本操作
至此，文件系统已经可以使用了，我们 **可以执行所有常用的文件系统操作**，例如，读取文件，新建目录，
移动文件，删除数据，列出目录，等等。可以输入命令：
```shell
$ hadoop fs -help
```
**获取每个命令的详细帮助文件**。

首先 **从本地文件系统将一个文件复制到HDFS**：
```shell
$ hadoop fs -copyFromLocal ~/input/docs/quangle.txt hdfs://localhost/quangle.txt
```
该命令调用hadoop文件系统的shell命令 **fs**，后者提供了一系列子命令，在这个例子中，我们执行的是
 **-copyFromLocal**。本地文件`quangle.txt`被复制到运行在`localhost`上的HDFS实例中，路径
 为：`hdfs://localhost/quangle.txt`。事实上，**我们可以简化命令格式以省略主机的URL并使用默
 认设置，即省略hdfs://localhost，因为该项已在core-site.xml中指定**。如下命令：
```shell
$ hadoop fs -copyFromLocal ~/input/docs/quangle.txt /quangle.txt
```
**我们也可以使用相对路径，并将文件复制到HDFS的home目录中（注意：没有用/作为开始）**，本例中为
`/user/fuhd`：
```shell
$ hadoop fs -copyFromLocal ~/input/docs/quangle2.txt quangle2.txt
# 上例与下面命令相等
# hadoop fs -copyFromLocal ~/input/docs/quangle2.txt /user/fuhd/quangle2.txt
```
我们 **把文件复制回本地文件系统，并检查是否一致**：
```shell
$ hadoop fs -copyToLocal /quangle.txt ~/quangle.copy.txt
$ md5sum ~/input/docs/quangle.txt ~/quangle.copy.txt

b537dc015ca9316e9a052ce01edeef96  /home/fuhd/input/docs/quangle.txt
b537dc015ca9316e9a052ce01edeef96  /home/fuhd/quangle.copy.txt
```
MD5键值相同，表明这个文件在HDFS之旅中得以幸存并保存完整。

最后，看一下 **HDFS文件列表**。我们 **新建一个目录**，看它在列表中怎么显示：
```shell
$ hadoop fs -mkdir /books
$ hadoop fs -ls /
Found 4 items
drwxr-xr-x   - fuhd supergroup          0 2018-01-02 16:15 /books
-rw-r--r--   1 fuhd supergroup         97 2018-01-02 12:47 /quangle.txt
-rw-r--r--   1 fuhd supergroup        130 2018-01-02 15:50 /quangle2.txt
drwxrwx---   - fuhd supergroup          0 2017-12-21 14:51 /tmp
```
返回的结果信息与Unix命令 **ls -l** 的输出结果非常相似，仅有细微差别。**第1列显示的是文件模式。
第2列是这个文件的备份数**（这在传统Unix文件系统是没有的）。由于我们在整个文件系统范围内设置的默
认复本数为1，所以这里显示的也都是1。**第3列和第4列显示文件的所属用户和组别。第5列是文件的大小，
以字节为单位，目录为0。第6列和第7列是文件的最后修改时期与时间。最后，第8列是文件或目录的名称**。
```
HDFS中的文件访问权限

针对文件和目录，HDFS的权限模式与POSIX的权限模式非常相似。

一共提供三类权限模式：只读权限（r）、写入权限（w）和可执行权限（x）。读取文件或列出目录内容时需要只读权限。写入一个文件或
是在一个目录上新建及删除文件或目录，需要写入权限。对于文件而言，可执行权限可以忽略，因为你不能在HDFS中执行文件（与POSIX
不同），但在访问一个目录的子项时需要该权限。

每个文件和目录都有所属用户（owner）、所属组别（group）及模式（mode）。这个模式是由所属用户的权限、组内成员的权限及其他
用户的权限组成的。

在默认情况下，Hadoop运行时安全措施处于停用模式，意味着客户端身份是没有经过认证的。由于客户端是远程的，一个客户端可以在远
程系统上通过创建和任一个合法用户同名的帐号来进行访问。当然，如果安全设施处于启用模式，这些都是不可能的。无论怎样，为防止用
户或自动工具及程序意外修改或删除文件系统的重要部分，启动权限控制还是很重要的(默认的配置，参见:dfs.permissions.enabled
属性)。

如果启用权限检查，就会检查所属用户权限，以确认客户端的用户名与所属用户是否匹配，另外也将检查所属组别权限，以确认该客户端
是否是该用户组的成员；若不符，则检查其他权限。

这里有一个超级用户（super-user）的概念，超级用户是namenode进程的标识。对于超级用户，系统不会执行任何权限检查。
```
