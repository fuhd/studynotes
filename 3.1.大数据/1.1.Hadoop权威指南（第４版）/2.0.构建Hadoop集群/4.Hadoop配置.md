Hadoop配置
=================================================================================
有多个配置文件适用于Hadoop安装，这几个重要文件都在Hadoop分发包的 **etc/hadoop目录** 中。**配置目录
可以被重新安置在文件系统的其他地方（Hadoop安装路径的外面，以便于升级）**，只要启动守护进程时使用
**--config选项**（或等价的，使用 **HADOOP_CONF_DIR** 环境变量集）说明这个目录在本地文件系统的位置
就可以了。

Hadoop配置文件：

| 文件名称 | 格式 | 描述 |
| :------------- | :------------- | :------------------ |
| **hadoop-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行Hadoop |
| **mapred-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行MapReduce（**覆盖hadoop-env.sh中设置的变量**）|
| **yarn-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行YARN（**覆盖hadoop-env.sh中设置的变量**）|
| **core-site.xml** | Hadoop配置XML | Hadoop Core的配置项，例如HDFS、MapReduce和YARN常用的I/O设置等 |
| **hdfs-site.xml** | Hadoop配置XML | Hadoop守护进程的配置项，包括namenode、辅助namenode和datanode等 |
| **mapred-site.xml** | Hadoop配置XML | MapReduce守护进程的配置项，包括作业历史服务器 |
| **yarn-site.xml** | Hadoop配置XML | YARN守护进程的配置项，包括资源管理器、web应用代理服务器和节点管理器 |
| **slaves** | 纯文本 | 运行datanode和节点管理器的机器列表（每行一个）|
| **hadoop-metrics2.properties** | Java属性文件 | 控制如何在Hadoop上发布度量的属性 |
| **log4j.properties** | Java属性文件 | 系统日志文件、namenode审计日志、任务JVM进程的任务日志的属性 |
| **hadoop-policy.xml** | Hadoop配置XML | 安全模式下运行Hadoop时的访问控制列表的配置项 |

### 配置管理
Hadoop并没有将所有配置信息放在一个单独的全局位置中。反之，**集群的每个Hadoop节点都各自保存一系列配置
文件，并由管理员完成这些配置文件的同步工作**。有 **并行shell工具** 帮助完成同步工作，诸如 **dsh或pdsh**。
在这方面，**Hadoop集群管理工具**，例如 **Cloudera Manager** 和 **Apache Ambari** 表现突出，
**因为在集群间传递修改信息是它们的关注点**。

**Hadoop也支持为所有master机器和worker机器采用同一套配置文件。这个做法的最大优势在于简单**，不仅体现在
理论上（仅需处理一套配置文件），也体现在可操作性上（使用Hadoop脚本就能进行管理）。

但是，**这种一体适用的配置模型并不合适某些集群**。以扩展集群为例，当试图为集群添加新机器，且新机器的硬件
规格与现有机器不同时，则需要新建一套配置文件，以充分利用新硬件的额外资源。

在这种情况下，需要引入“**机器类**”的概念，**为每一机器类维护单独的配置文件**。Hadoop没有提供执行这个
操作的工具。**需要借助外部工具** 来执行该配置操作，例如：**Chef、Puppet、CFEngine和Bcfg2等**。

对于任何规模的集群来说，**同步所有机器上的配置文件都极具挑战性**。因此，尽管用户能够使用控制脚本来管理
Hadoop，**仍然推荐使用控制管理工具管理集群**。使用这些工具也可以顺利完成日常维护，例如为安全漏洞打补丁，
升级系统包等。

### 环境设置
本节探讨如何 **设置hadoop-env.sh文件中的变量**。MapReduce和YARN（HDFS除外）都有类似的配置文件，
分别为 **mapred-env.sh** 和 **yarn-env.sh**，文件中的变量和组件相关，并且可以进行设置。**注意，
hadoop-env.sh文件里设置的值会被mapred-env.sh（MapReduce）和yarn-env.sh（YARN）文件覆盖**。

#### 1.Java
**需要设置Hadoop系统的Java安装的位置**。
+ 方法一：**是在hadoop-env.sh文件中设置JAVA_HOME项**；
+ 方法二：**是在shell中设置JAVA_HOME环境变量**；
相比之下，**方法一更好**，因为是需操作一次就能够保证整个集群使用同一版本的Java。































































ddd
