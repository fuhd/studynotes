Hadoop配置
=================================================================================
有多个配置文件适用于Hadoop安装，这几个重要文件都在Hadoop分发包的 **etc/hadoop目录** 中。**配置目录
可以被重新安置在文件系统的其他地方（Hadoop安装路径的外面，以便于升级）**，只要启动守护进程时使用
**--config选项**（或等价的，使用 **HADOOP_CONF_DIR** 环境变量集）说明这个目录在本地文件系统的位置
就可以了。

Hadoop配置文件：

| 文件名称 | 格式 | 描述 |
| :------------- | :------------- | :------------------ |
| **hadoop-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行Hadoop |
| **mapred-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行MapReduce（**覆盖hadoop-env.sh中设置的变量**）|
| **yarn-env.sh** | Bash脚本 | 脚本中要用到的环境变量，以运行YARN（**覆盖hadoop-env.sh中设置的变量**）|
| **core-site.xml** | Hadoop配置XML | Hadoop Core的配置项，例如HDFS、MapReduce和YARN常用的I/O设置等 |
| **hdfs-site.xml** | Hadoop配置XML | Hadoop守护进程的配置项，包括namenode、辅助namenode和datanode等 |
| **mapred-site.xml** | Hadoop配置XML | MapReduce守护进程的配置项，包括作业历史服务器 |
| **yarn-site.xml** | Hadoop配置XML | YARN守护进程的配置项，包括资源管理器、web应用代理服务器和节点管理器 |
| **slaves** | 纯文本 | 运行datanode和节点管理器的机器列表（每行一个）|
| **hadoop-metrics2.properties** | Java属性文件 | 控制如何在Hadoop上发布度量的属性 |
| **log4j.properties** | Java属性文件 | 系统日志文件、namenode审计日志、任务JVM进程的任务日志的属性 |
| **hadoop-policy.xml** | Hadoop配置XML | 安全模式下运行Hadoop时的访问控制列表的配置项 |

### 配置管理
Hadoop并没有将所有配置信息放在一个单独的全局位置中。反之，**集群的每个Hadoop节点都各自保存一系列配置
文件，并由管理员完成这些配置文件的同步工作**。有 **并行shell工具** 帮助完成同步工作，诸如 **dsh或pdsh**。
在这方面，**Hadoop集群管理工具**，例如 **Cloudera Manager** 和 **Apache Ambari** 表现突出，
**因为在集群间传递修改信息是它们的关注点**。

**Hadoop也支持为所有master机器和worker机器采用同一套配置文件。这个做法的最大优势在于简单**，不仅体现在
理论上（仅需处理一套配置文件），也体现在可操作性上（使用Hadoop脚本就能进行管理）。

但是，**这种一体适用的配置模型并不合适某些集群**。以扩展集群为例，当试图为集群添加新机器，且新机器的硬件
规格与现有机器不同时，则需要新建一套配置文件，以充分利用新硬件的额外资源。

在这种情况下，需要引入“**机器类**”的概念，**为每一机器类维护单独的配置文件**。Hadoop没有提供执行这个
操作的工具。**需要借助外部工具** 来执行该配置操作，例如：**Chef、Puppet、CFEngine和Bcfg2等**。

对于任何规模的集群来说，**同步所有机器上的配置文件都极具挑战性**。因此，尽管用户能够使用控制脚本来管理
Hadoop，**仍然推荐使用控制管理工具管理集群**。使用这些工具也可以顺利完成日常维护，例如为安全漏洞打补丁，
升级系统包等。

### 环境设置
本节探讨如何 **设置hadoop-env.sh文件中的变量**。MapReduce和YARN（HDFS除外）都有类似的配置文件，
分别为 **mapred-env.sh** 和 **yarn-env.sh**，文件中的变量和组件相关，并且可以进行设置。**注意，
hadoop-env.sh文件里设置的值会被mapred-env.sh（MapReduce）和yarn-env.sh（YARN）文件覆盖**。

#### 1.Java
**需要设置Hadoop系统的Java安装的位置**。
+ 方法一：**是在hadoop-env.sh文件中设置JAVA_HOME项**；
+ 方法二：**是在shell中设置JAVA_HOME环境变量**；

相比之下，**方法一更好**，因为是需操作一次就能够保证整个集群使用同一版本的Java。

#### 2.内存堆大小
在默认情况下，Hadoop为各个守护进程分配 **1000MB（1GB）** 内存。该内存值由 **hadoop-env.sh** 文件的
**HADOOP_HEAPSIZE** 参数控制。也可以通过设置环境变量为单个守护进程修改堆大小。例如，在 **yarn-env.sh**
文件中设置 **YARN_RESOURCEMANAGER_HEAPSIZE**，即 **可覆盖资源管理器的堆大小**。

令人惊讶的是，尽管namenode分配更多的堆空间是很常见的事，**但对于HDFS守护进程而言并没有相应的环境变量**。
当然有别的途径可以设置namenode堆空间大小。

除了守护进程对内存的需求，节点管理器还需为应用程序分配容器（container），因此需要综合考虑上述因素来
计算一个工作机器的总体内存需求。
```
一个守护进程究竟需要多少内存？

由于namenode会在内存中维护所有文件的每个数据块的引用，因此namenode很可能会“吃光”分配给它的所有内存。很难套用一个公式来精确
计算内存需求量，因为内存需求量取决于多个因素，包括每个文件包含的数据块数、文件名称的长度、文件系统中的目录数等。此外，在不同
Hadoop版本下，namenode的内存需求也不相同。

1000MB内存（默认配置）通常足够管理数百万个文件。但是根据经验来看，保守估计需要为每100万个数据块分配1000MB内存空间。

以一个含200节点的集群为例，假设每个节点有24TB磁盘空间，数据块大小是128MB，复本数是3的话，则约有200万个数据块（甚至更多）：
200 * 24000000MB /(128MB * 3)。因此，在本例中，namenode的内存空间最好一开始设为12000MB。

也可以只增加namenode的内存分配量而不改变其他Hadoop守护进程的内存分配，即设置hadoop-env.sh文件的HADOOP_NAMENODE_OPTS
属性包含一个JVM选项以设定内存大小。HADOOP_NAMENODE_OPTS允许向namenode的JVM传递额外的选项。以Sun JVM为例，-Xmx2000m
选项表示为namenode分配2000MB内存空间。

由于辅助namenode的内存需求量和主namenode差不多，所以一旦更改namenode的内存分配的话还需对辅助namenode做相同更改（使用
HADOOP_SECONDARYNAMENODE_OPTS变量）。
```

### 3.系统日志文件




































































ddd
