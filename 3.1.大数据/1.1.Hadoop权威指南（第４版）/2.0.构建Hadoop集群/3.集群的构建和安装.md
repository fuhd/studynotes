集群的构建和安装
=================================================================================
本节介绍如何在Linux（Unix）操作系统下使用Apache Hadoop分发包安装和配置一个基础的Hadoop集群。

### 安装Java
略

### 创建Linux（Unix）用户帐号
最好创建特定的Linux（Unix）用户帐号以区分各Hadoop进程，及区分同一机器上的其他服务。**HDFS、
MapReduce和YARN服务通常作为独立的用户运行，分别命名为hdfs、mapred和yarn。它们都属于同一hadoop组**。

### 安装Hadoop
从Apache Hadoop的发布页面下载Hadoop发布包，并在某一本地目录解压缩，**例如：/usr/local（/opt是另
一标准选项）。注意，鉴于hadoop用户的home目录可能挂载在NFS上，Hadoop系统最好不要安装在该目录上**：
```shell
$ cd /opt
$ sudo tar xzvf hadoop-x.y.z.tar.gz
```
**此外，还需将Hadoop文件的拥有者改为hadoop用户和组**：
```shell
$ sudo chown -R hadoop:hadoop hadoop-x.y.z
```
在shell路径里添加Hadoop执行程序所在目录很方便（注：**我认为还是在/etc/profile中添加更方便！**）：
```shell
$ export HADOOP_HOME=/usr/local/hadoop-x.y.z
$ export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

### SSH配置
**Hadoop控制脚本（并非守护进程）依赖SSH来执行针对整个集群的操作**。例如，某个脚本能够终止并重启集群
中的所有守护进程。值得注意的是，**控制脚本并非唯一途经**，用户也可以利用其他方法执行集群范围的操作，
例如，分布式shell或专门的Hadoop管理应用。

为了支持无缝式工作，**SSH安装好之后，需要允许来自集群内机器的hdfs用户和yarn用户能够无需密码即可登陆**。
（mapred用户不使用SSH，如同Hadoop2和以后版本中的一样，唯一的MapReduce守护进程是作业历史服务器。)
**最简单的方法是创建一个公钥/私钥对，存放在NFS之中，让整个集群共享该密钥对**。

首先，键入以下指令来 **产生一个RSA密钥对。你需要作两次，一次以hdfs用户身份，一次以yarn用户身份**：
```shell
$ ssh-keygen -t rsa -f ~/.ssh/id_rsa
```
尽管期望无密码登录，**但无口令的密钥并不是一个好的选择**（运行在本地、伪分布集群上时，倒也不妨使用一个空
口令）。因此，**当系统提示输入口令时，用户最好指定一个口令。可以使用ssh-agent以免为每个连接逐一输入密码**。

**私钥** 放在由 **-f选项** 指定的文件之中，例如 **~/.ssh/id_rsa**。存放公钥的文件名称与私钥类似，
但是以"**.pub**"作为后缀，例如 **~/.ssh/id_rsa.pub**。

接下来，需 **确保公钥存放在用户打算连接的所有机器的~/.ssh/authorized_keys文件中。如果用户的home目录
是存储在NFS文件系统中，则可以键入以下指令在整个集群内共享密钥（第一次作为hdfs用户，第二次作为yarn用户）**：
```shell
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
```
如果home目录并没有通过NFS共享，则需要利用其他方法共享公钥（比如 **ssh-copy-id**）。

测试是否可以从主机器SSH到工作机器。若可以，则表明ssh-agent正在运行，**再运行ssh-add来存储口令。这样
的话，用户即可不用再输入口令就能SSH到一台工作机器**。

### 配置Hadoop
如果希望Hadoop以分布式模式在集群上运行，必须正确对其进行配置（**下一节Hadoop配置中讲述**）。

### 格式化HDFS文件系统
在能够使用之前，**全新的HDFS安装需要进行格式化**。通过创建存储目录和初始版本的namenode持久数据结构，
**格式化进程将创建一个空的文件系统**。由于namenode管理所有的文件系统元数据，**datanode可以动态加入或
离开集群，所以初始的格式化进程不涉及到datanode**。同样原因，**创建文件系统时也无需指定大小**，这是由
集群中的datanode数目决定的，在文件系统格式化之后的很长时间内都可以根据需要增加。

格式化HDFS是一个快速操作。以 **hdfs用户身份** 运行以下命令：
```shell
$ hdfs namenode -format
```

### 启动和停止守护进程
**Hadoop自带脚本，可以运行命令并在整个集群范围内启动和停止守护进程。为使用这些脚本（在sbin目录下），
需要告诉Hadoop集群中有哪些机器。文件slaves正是用于此目的，该文件包含了机器主机名或IP地址的列表，每
行代表一个机器信息。文件slaves列举了可以运行datanode和节点管理器的机器。文件驻留在Hadoop配置目录
下，尽管通过修改hadoop-env.sh中的HADOOP_SLAVES设置可能会将文件放在别的地方（并赋予一个别的名称）。
并且，不需要将该文件分发给工作节点，因为仅有运行在namenode和资源管理器上的控制脚本使用它**。

以 **hdfs用户身份** 运行以下命令可以启动HDFS守护进程：
```shell
$ start-dfs.sh
```
namenode和辅助namenode运行所在的机器通过向Hadoop配置询问机器主机名来决定。例如，通过执行以下命令，
**脚本能够找到namenode的主机名**。
```shell
$ hdfs getconf -namenodes
```
**默认情况下，该命令从fs.defaultFS中找到namenode的主机名**。更具体一些，**start-dfs.sh脚本所做的
事情如下**：
1. **在每台机器上启动一个namenode，这些机器由执行hdfs getconf -namenodes得到的返回值所确定**。
2. **在slaves文件列举的每台机器上启动一个datanode**。
3. **在每台机器上启动一个辅助namenode，这些机器由执行hdfs getconf -secondarynamenodes得到的
返回值所确定**。

YARN守护进程以相同的方式启动，通过以 **yarn用户身份** 在托管资源管理器的机器上运行以下命令：
```shell
start-yarn.sh
```
**在这种情况下，资源管理器总是和start-yarn.sh脚本运行在同一机器上**。脚本明确完成以下事情：
1. **在本地机器上启动一个资源管理器**。
2. **在slaves文件列举的每台机器上启动一个节点管理器**。

同样，还提供了 **stop-dfs.sh** 和 **stop-yarn.sh** 脚本用于停止由相应的启动脚本启动的守护进程。

**这些脚本实质是使用了hadoop-daemon.sh脚本（YARN中是yarn-daemon.sh脚本）启动和停止Hadoop守护
进程。如果你使用了前面提到的脚本，那么你不能直接调用hadoop-daemon.sh。但是如果你需要从另一个系统
或从你自己的脚本来控制Hadoop守护进程，hadoop-daemon.sh脚本是一个很好的切入点**。类似的，当需要一个
主机上启动相同的守护进程时，使用hadoop-daemons.sh（带有“s”）会很方便。

最后，仅有一个MapReduce守护进程，即作业历史服务器，是以mapred用户身份用以下命令启动的：
```shell
$ mr-jobhistory-daemon.sh start historyserver
```

### 创建用户目录























































sss
