集群的构建和安装
=================================================================================
本节介绍如何在Linux（Unix）操作系统下使用Apache Hadoop分发包安装和配置一个基础的Hadoop集群。

### 安装Java
略

### 创建Linux（Unix）用户帐号
最好创建特定的Linux（Unix）用户帐号以区分各Hadoop进程，及区分同一机器上的其他服务。**HDFS、
MapReduce和YARN服务通常作为独立的用户运行，分别命名为hdfs、mapred和yarn。它们都属于同一hadoop组**。

### 安装Hadoop
从Apache Hadoop的发布页面下载Hadoop发布包，并在某一本地目录解压缩，**例如：/usr/local（/opt是另
一标准选项）。注意，鉴于hadoop用户的home目录可能挂载在NFS上，Hadoop系统最好不要安装在该目录上**：
```shell
$ cd /opt
$ sudo tar xzvf hadoop-x.y.z.tar.gz
```
**此外，还需将Hadoop文件的拥有者改为hadoop用户和组**：
```shell
$ sudo chown -R hadoop:hadoop hadoop-x.y.z
```
在shell路径里添加Hadoop执行程序所在目录很方便（注：**我认为还是在/etc/profile中添加更方便！**）：
```shell
$ export HADOOP_HOME=/usr/local/hadoop-x.y.z
$ export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

### SSH配置
**Hadoop控制脚本（并非守护进程）依赖SSH来执行针对整个集群的操作**。例如，某个脚本能够终止并重启集群
中的所有守护进程。值得注意的是，**控制脚本并非唯一途经**，用户也可以利用其他方法执行集群范围的操作，
例如，分布式shell或专门的Hadoop管理应用。

为了支持无缝式工作，**SSH安装好之后，需要允许来自集群内机器的hdfs用户和yarn用户能够无需密码即可登陆**。
（mapred用户不使用SSH，如同Hadoop2和以后版本中的一样，唯一的MapReduce守护进程是作业历史服务器。)
**最简单的方法是创建一个公钥/私钥对，存放在NFS之中，让整个集群共享该密钥对**。










































sss
