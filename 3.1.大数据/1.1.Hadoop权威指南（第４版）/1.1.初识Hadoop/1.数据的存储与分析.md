数据的存储与分析
================================================================================
在硬盘存储容量多年来不断提升的同时，访问速度（硬盘数据读取速度）却没有与时倶进。`1990`年，一个普
通硬盘可以存储`1370MB`数据，传输速度为 **`4.4MB/s`**，因此只需要`5`分钟就可以读完整个硬盘中
的数据。`20`年过去了，`1TB`的硬盘成为主流，但其数据传输速度约为 **`100MB/s`**，读完整个硬盘
中的数据至少得花`2.5`个小时。

读完整个硬盘中的数据需要更长时间，写入数据就别提了。一个很简单的减少读取时间的办法是 **同时从多个
硬盘上读数据**。试想，如果我们有`100`个硬盘，每个硬盘存储`1%`的数据，并行读取，那么不到两分钟就
可以读完所有数据。

虽然如此，**但要对多个硬盘中的数据并行进行读/写数据，还有更多问题要解决**。

**第一个需要解决的是硬件故障问题**。一旦开始使用多个硬件，其中个别硬件就很有可能发生故障。**为了
避免数据丢失，最常见的做法是复制（`replication`）：系统保存数据的复本（`replica`），一旦有系
统发生故障，就可以使用另外保存的复本**。例如，冗余硬盘阵列（`RAID`）就是按这个原理实现的，另外，
**`Hadoop`的文件系统（`Hadoop Distributed FileSystem, HDFS`）** 也是一类，不过它采取的
方法稍有不同。

**第二个问题是大多数分析任务需要以某种方式结合大部分数据来共同完成分析**，即从一个硬盘读取的数据
可能需要与从另外`99`个硬盘中读取的数据结合使用。各种分布式系统允许结合不同来源的数据进行分析，但
保证其正确性是一个非常大的挑战。**`MapReduce`提出一个编程模型，该模型抽象出这些硬盘读/写问题并
将其转换为对一个数据集（由键-值对组成）的计算**。
