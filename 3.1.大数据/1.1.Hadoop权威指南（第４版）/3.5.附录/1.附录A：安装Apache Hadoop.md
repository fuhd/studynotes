附录A：安装Apache Hadoop
=============================================================================
在单机上安装`Hadoop`来尝试一下是非常容易的，**面向集群的安装方法，可以参见第`10`章**。

这里将介绍如何使用一个`Apache Software Foundation`发布的二进制压缩包安装 **`Hadoop Common`、
`HDFS`、`MapReduce`和`YARN`**。

### 先决条件
必须确保安装的是合适版本的`Java`。可以通过`Hadoop wiki（http://wiki.apache.org/hadoop/HadoopJavaVersions）`
查看所安装版本的信息。以下命令可以帮助确认`Java`是正确安装的：
```shell
$ java -version
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```
```
注意：
Hadoop3.0要求的Java版本是: java8。
```

### 安装
首先，决定以什么用户的身份来运行`Hadoop`。如果只是想试用`Hadoop`或开发`Hadoop`程序，可以用用户帐号
在单机上运行`Hadoop`。

从`Apache Hadoop`发布页面（`http://hadoop.apache.org/common/releases.html`）下载个稳定版的发布包，
再解压缩到本地文件系统：
```shell
$ tar xzvf hadoop-3.0.0.tar.gz
```
在运行`Hadoop`安装程序之前，需要指定`Java`在本地系统中的路径。**如果系统的`JAVA_HOME`环境变量已经正确地
指向一个`Java`安装路径，且用户也希望使用该`Java`安装路径，则无需进行其他配置**（这通常在一个`shell`启动文件
中设置，例如 **`~/.bash_profile`** 或者 **`~/.bashrc`** ）。否则，**仍然需要编辑`etc/hadoop/hadoop-env.sh`
文件来设置`JAVA_HOME`环境变量以指定`Java`安装路径**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
```
很容易 **创建指向`Hadoop`安装目录（依照惯例是`HADOOP_HOME`）的环境变量**；此外，还要 **将`Hadoop`的二进制目录
添加到命令行路径上**。例如：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib

export HADOOP_HOME=/opt/hadoop-3.0.0
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```
注意，**`sbin`目录下有运行`Hadoop`守护进程的脚本，因此如果计划在本地机器上运行守护进程的话，需要将该
目录包含进命令行路径中**。
```
个人操作反馈：
目前hadoop3.0中，必须在etc/hadoop/hadoop-env.sh中添加JAVA_HOME环境变量才可以使用，要不然根本运行不起来。
而在hadoop2.x中，默认打开了JAVA_HOME=${JAVA_HOME}的配置。
```

输入以下指令来判断`Hadoop`是否工作：
```shell
$ hadoop version
Hadoop 3.0.0
Source code repository https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533
Compiled by andrew on 2017-12-08T19:16Z
Compiled with protoc 2.5.0
From source with checksum 397832cb5529187dc8cd74ad54ff22
This command was run using /opt/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar
```

### 配置
`Hadoop`的各个组件均可利用`XML`文件进行配置。**`core-site.xml`文件用于配置通用属性，`hdfs-site.xml`文件用于
配置`HDFS`属性，`mapred-site.xml`文件则用于配置`MapReduce`属性，`yarn-site.xml`文件用于配置`YARN`属性。
这些配置文件都放在`etc/hadoop`子目录中**。
```
上述配置文件中的属性都有默认设置，分别保存在Hadoop安装路径的share/doc子目录下，即：
share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml
share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
share/doc/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
```
`Hadoop`有以下三种运行模式：
+ **独立（或本地）模式**：无需运行任何守护进程，所有程序都在同一个`JVM`上执行。在独立模式下测试和调试`MapReduce`程序很方便，
因此该模式在开发阶段比较合适。
+ **伪分布模式**：`Hadoop`守护进程运行在本地机器上，模拟一个小规模的集群。
+ **全分布模式**：`Hadoop`守护进程运行在一个集群上。此模式的设置参见第`10`章。

在特定模式下运行`Hadoop`需要关注两个因素：**正确设置属性和启动`Hadoop`守护进程**。下表列举了配置各种模式所需要的 **最小属性集合**。
在独立模式下，将使用本地文件系统和本地`MapReduce`作业运行器；在分布模式下，将启动`HDFS`和`YARN`守护进程，此外还需配置`MapReduce`
以便能够使用`YARN`。

| 组件名称 | 属性名称 | 独立模式 | 伪分布模式 | 全分布模式 |
|:--------|:-------|:--------|:----------|:---------|
| Common | fs.defaultFS |file:/// (默认) | hdfs://localhost/ | hdfs://namenode/ |
| HDFS | dfs.replication | N/A | 1 | 3 |
| MapReduce | mapreduce.framework.name | local（默认）|yarn | yarn |
| YARN | yarn.resourcemanager.hostname, yarn.nodemanager.aux-services | N/A | localhost,mapreduce_shuffle | resourcemanager,mapreduce_shuffle |

### 独立模式
**由于默认属性专为本模式所设定，且本模式无需运行任何守护进程，因此在独立模式下不需要更多操作**。

### 伪分布模式
在伪分布模式下，使用如下内容 **创建配置文件**，并将其放在 **`etc/hadoop`** 目录下。**也可以把`etc/hadoop`目录复制到
另一个位置，然后把`*-site.xml`这些配置文件放在该目录下。这种方法的优点是，将配置设置和安装文件隔离开**。如果是这么做的，
那么需要 **将环境变量`HADOOP_CONF_DIR`设置成指向那个新目录**，或确定在启动守护进程时 **使用`--config选项**。
```xml
<?xml version="1.0"?>
<!--下面的内容放入core-site.xml -->
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost/</value>
    </property>
    <!-- 这是一个临时目录，经常造成 http://localhost:9870 访问不了（默认在tmp目录下，会定期清理），
    这里显示设置它（这个目录要提前准备好） -->
    <property>
        <name>hadoop.tmp.dir</name>
        <!-- 注意运行hadoop的用户一定要有操作${hadoop.tmp.dir}目录的权限 -->
        <value>/opt/hadoop/tmp</value>
        <description>A base for other temporary directories.</description>
    </property>
</configuration>
```
```xml
<?xml version="1.0"?>
<!-- 下面的内容放入hdfs-site.xml -->
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

</configuration>
```
```xml
<?xml version="1.0"?>
<!-- 下面的内容放入mapred-site.xml -->
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```
```xml
<?xml version="1.0"?>
<!-- 下面的内容放入yarn-site.xml -->
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```
#### 1.配置SSH
如前所述，**在伪分布模式下工作时必须启动守护进程**，而启动守护进程的前提是 **成功安装`SSH`**。`Hadoop`并不严格区分伪分布模式和
全分布模式，它只是在集群内的（多台）主机（由`slaves`文件定义）上启动守护进程：**`SSH`连接到各个主机并启动一个守护进程**。
**伪分布模式是全分布模式的一个特例**。在伪分布模式下，（单）主机就是本地计算机（`localhost`），**因此需要确保用户能够用`SSH`连接到本地
主机，并且可以不输入密码登录**。

首先，确保`SSH`已经安装，且服务器正在运行。例如，在`Ubuntu`上可通过以下指令进行测试：
```shell
$ sudo apt-get install ssh
```
**然后基于空口令生成一个新`SSH`密钥，以实现无密码登录**：
```shell
$ ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa
$ cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
$ chmod 0600 ~/.ssh/authorized_keys
```
如果正运行的是`ssh-agent`，可能还需要运行`ssh-add`。

用以下指令测试是否能够连接：
```shell
$ ssh localhost
```
如果成功，则无需键入密码。

#### 2.格式化HDFS文件系统
**在首次使用`Hadoop`前，必须格式化文件系统**。只需键入如下指令：
```shell
#注意，namenode节点下的${hadoop.tmp.dir}目录下的目录清空时，基本都需要再格式化一下的。
# *-site.xml中的配置修改后，好像也是要格式化一下的，还需要再测试一下！
$ hdfs namenode -format
```

#### 3.启动和终止守护进程
为启动`HDFS`、`YARN`和`MapReduce`守护进程，键入如下指令：
```shell
$ start-dfs.sh
$ start-yarn.sh
# hadoop3.0之前的启动方式
# $ mr-jobhistory-daemon.sh start historyserver
# hadoop3.0以及之后的启动方式
$ mapred --daemon start historyserver
```
```
说明：
如果配置文件并不位于默认的 etc/hadoop 目录中，则或者在运行脚本前输出 HADOOP_CONF_DIR 环境变量，
或者启动守护进程时使用 --config 选项，该选项带有一条绝对路径指向配置目录。
$ start-dfs.sh --config path-to-config-directory
$ start-yarn.sh --config path-to-config-directory
$ mr-jobhistory-daemon.sh --config path-to-config-directory start historyserver
```
本地计算机将启动以下守护进程：**一个`namenode`、一个辅助`namenode`、一个`datanode(HDFS)`、一个资源管理器、
一个节点管理器（`YARN`）和一个历史服务器（`MapReduce`）**。可以浏览 **`logs`目录**（在`Hadoop`安装目录下）中的日志文件
来检查守护进程是否成功启动，或通过`Web`界面：在 **`http://localhost:9870`** 查看`namenode`、在 **`http://localhost:8088/`**
查看资源管理器、在 **`http://localhost:19888/`** 查看历史服务器。此外，`Java`的 **`jps`命令** 也能查看守护进程是否正在运行。

终止守护进程也很容易，示例如下：
```shell
# hadoop3.0之前的停止方式
# $ mr-jobhistory-daemon.sh stop historyserver
# hadoop3.0以及之后的停止方式
$ mapred --daemon stop historyserver
$ stop-yarn.sh
$ stop-dfs.sh
```

#### 4.创建用户目录
为自己创建一个主目录需键入以下指令：
```shell
$ hadoop fs -mkdir -p /user/$USER
```

### 全分布式模式
在集群上安装`Hadoop`还需要考虑更多因素，所以第`10`章专门对此模式进行了全面的描述。
