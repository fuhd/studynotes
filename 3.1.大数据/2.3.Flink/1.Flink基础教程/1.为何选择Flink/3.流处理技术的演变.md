流处理技术的演变
================================================================================
**分开处理连续的实时数据和有限批次的数据，可以使系统构建工作变得更加简单，但是这种做法将管理两套
系统的复杂性留给了系统用户**：应用程序的开发团队和DevOps团队需要自己使用并管理这两套系统。

为了处理这种情况，有些用户开发出了自己的流处理系统。**在开源世界里，Apache Storm项目是流处理先
锋**。Storm最早由Nathan Marz和创业公司BackType（后来被Twitter收购）的一个团队开发，后来才
被Apache软件基金会接纳。**Storm提供了低延迟的流处理，但是它为实时性付出了一些代价：很难实现高
吞吐，并且其正确性没有达到通常所需的水平。换句话说，它并不能保证exactly-once；即便是它能够保证
的正确性级别，其开销也相当大**。

```
Lambda架构概述：优势和局限性

对低成本规模化的需求促使人们开始使用分布式文件系统，例如HDFS和基于批量数据的计算系统（MapReduce作业）。但是这种系统很
难做到低延迟。用Storm开发的实时流处理技术可以帮助解决延迟性的问题，但并不完美。其中的一个原因是，Storm不支持
exactly-once语句，因此不能保证状态数据的正确性，另外它也不支持基于事件时间的处理。有以上需求的用户不得不在自己的应用程
序代码中加入这些功能。

后来出现了一种混合分析的方法，它将上述两个方案结合起来，既保证低延迟，又保障正确性。这个方法被称作Lambda架构，它通过批
量MapReduce作业提供了虽有些延迟但是结果准确的计算，同时通过Storm将最新数据的计算结果初步展示出来。

Lambda架构是构建大数据应用程序的一种很有效的框架，但它还不够好。举例来说，基于MapReduce和HDFS的Lambda架构系统有一个
长达数小时的时间窗口，在这个窗口内，由于实时任务失败而产生的不准确的结果会一直存在。Lambda架构需要在两个不同的API中对
同样的业务逻辑进行两次编程：一次为批量计算的系统，一次为流式计算的系统。针对同一个业务问题产生了两个代码库，各有不同的漏
洞。这种系统实际上非常难维护。
```
```
Lambda架构背景介绍

Lambda架构是由Storm的作者Nathan Marz提出的一个实时大数据处理架构。Marz在Twitter工作期间开发了著名的实时大数据处理
框架Storm，Lambda架构是其根据多年进行分布式大数据系统的经验总结提炼而成。

Lambda架构的目标是设计出一个能满足实时大数据系统关键特性的架构，包括有：高容错、低延时和可扩展等。Lambda架构整合离线计
算和实时计算，融合不可变性（Immunability），读写分离和复杂性隔离等一系列架构原则，可集成Hadoop，Kafka，Storm，
Spark，Hbase等各类大数据组件。
```
```
提示：

若要依靠多个流事件来计算结果，必须将数据从一个事件保留到下一个事件。这些保存下来的数据叫作计算的状态。准确处理状态对于计
算结果的一致性至关重要。在故障或中断之后能够继续准确地更新状态是容错的关键。
```
在低延迟和高吞吐的流处理系统中维持良好的容错性是非常困难的，但是为了得到有保障的准确状态，人们想
出了一种替代方法：**将连续事件中的流数据分割成一系列微小的批量作业。如果分割得足够小（即所谓的微
批处理作业），计算就几乎可以实现真正的流处理。因为存在延迟，所以不可能做到完全实时，但是每个简单
的应用程序都可以实现仅有几秒甚至几亚秒的延迟。这就是在Spark批处理引擎上运行的
Apache Spark Streaming（以下简称Spark Streaming）所使用的方法**。

更重要的是，**使用微批处理方法，可以实现`exactly-once`语义，从而保障状态的一致性**。如果一个
微批处理作业失败了，它可以重新运行。这比连续的流处理方法更容易。**Storm Trident是对Storm的延
伸，它的底层流处理引擎就是基于微批处理方法来进行计算的，从而实现`exactly-once`语义，但是在延迟
性方面付出了很大的代价**。

然而，通过间歇性的批处理作业来模拟流处理，会导致开发和运维相互交错。完成间歇性的批处理作业所需的
时间和数据到达的时间紧密耦合，任何延迟都可能导致不一致（或者说错误）的结果。**这种技术的潜在问题
是，时间由系统中生成小批量作业的那一部分全权控制。Spark Streaming等一些流处理框架在一定程度上
弱化了这一弊端，但还是不能完全避免**。另外，使用这种方法的计算有着糟糕的用户体验，尤其是那些对延
迟比较敏感的作业，而且人们需要在写业务代码时花费大量精力来提升性能。

为了实现理想的功能，人们继续改进已有的处理器（比如Storm Trident的开发初衷就是试图克服Storm的
局限性）。当已有的处理器不能满足需求时，产生的各种后果则必须由应用程序开发人员面对和解决。**以微
批处理方法为例，人们往往期望根据实际情况分割事件数据，而处理器只能根据批量作业时间（恢复间隔）的
倍数进行分割。当灵活性和表现力都缺乏的时候，开发速度变慢，运维成本变高**。

于是，Flink出现了。这一数据处理器可以避免上述弊端，并且拥有所需的诸多功能，还能按照连续事件高效
地处理数据。Flink的一些功能如下图：











































dd
