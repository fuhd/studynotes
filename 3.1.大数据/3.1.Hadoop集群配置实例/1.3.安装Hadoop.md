安装Hadoop
=================================================================================
配置Hadoop集群（示例有三个节点：server1（172.16.177.168）、server2（172.16.177.166）、
server3（172.16.177.167）），下面以其中一台（server2）作为演示。

### 下载并解压
从Hadoop官网下载hadoop-2.9.0.tar.gz，然后解压到/opt目录下：
```shell
$ sudo tar xzvf hadoop-2.9.0.tar.gz
$ sudo mv hadoop-2.9.0/ /opt/
```

### 改变hadoop文件的用户与组
将Hadoop文件的拥有者改为 **hadoop用户和组**：
```shell
$ sudo chown -R hadoop:hadoop hadoop-2.9.0/
```

### 添加Hadoop的环境变量
在 **/etc/profile** 中添加Hadoop的环境变量：
```shell
export HADOOP_HOME=/opt/hadoop-2.9.0
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```
再执行：
```shell
$ source /etc/profile
```

### 配置免密的SSH

#### 配置hdfs用户
**1. 从root帐户切换到hdfs帐户**

```shell
su - hdfs

上一次登录：三 1月 17 10:11:13 CST 2018pts/0 上
```
**2. 生成密钥**

```shell
$ ssh-keygen -t rsa -f ~/.ssh/id_rsa

Generating public/private rsa key pair.
Created directory '/home/hdfs/.ssh'.
Enter passphrase (empty for no passphrase):
Enter same passphrase again:
Your identification has been saved in /home/hdfs/.ssh/id_rsa.
Your public key has been saved in /home/hdfs/.ssh/id_rsa.pub.
The key fingerprint is:
0e:76:79:13:a9:1e:ad:c8:0d:db:95:c1:c8:ec:78:e4 hdfs@Tythin
The key‘s randomart image is:
+--[ RSA 2048]----+
|                 |
|       o o .     |
|        = =      |
|       = + +     |
|      = E *      |
|     o % = .     |
|      + *        |
|                 |
|                 |
+-----------------+
```
注意：上面要输入两次密码，假如为123456。

**3. 保存公钥到想要连接的节点上**

例如：server1、server3（当前节点为server2）。
```shell
$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@172.16.177.168
$ ssh-copy-id -i ~/.ssh/id_rsa.pub hadoop@172.16.177.167
```

#### 配置yarn用户
配置方法与hdfs用户配置类似，不在赘述！

#### 配置SSH免密钥密码
**在/etc/profile.d下新建ssh-agent.sh文件**：
```shell
sudo vim /etc/profile.d/ssh-agent.sh
```
```bash
#!/bin/sh
if [ -f ~/.agent.env ]; then
        . ~/.agent.env >/dev/null
        if ! kill -0 $SSH_AGENT_PID >/dev/null 2>&1; then
                echo "Stale agent file found. Spawning new agent..."
                eval `ssh-agent |tee ~/.agent.env`
                ssh-add
        fi
else
        echo "Starting ssh-agent..."
        eval `ssh-agent |tee ~/.agent.env`
        ssh-add
fi
```
然后，再回到 **用户主目录（hdfs、yarn）** 下执行：
```shell
su - hdfs
$ ssh-add
# 下面测试一下
$ ssh hadoop@172.16.177.168
$ ssh hadoop@172.16.177.168
```
```shell
su - yarn
$ ssh-add
# 下面测试一下
$ ssh hadoop@172.16.177.168
$ ssh hadoop@172.16.177.168
```














































sss
