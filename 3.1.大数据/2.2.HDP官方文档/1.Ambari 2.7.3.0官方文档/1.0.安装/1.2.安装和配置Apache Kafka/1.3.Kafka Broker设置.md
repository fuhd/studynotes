Kafka Broker设置
================================================================================
以下小节介绍了影响Kafka brokers性能的配置设置。

## 1.连接设置
查看高级kafka-broker类别中的以下连接设置，并根据需要进行修改：

| 属性 | 描述 |
| :------------- | :------------- |
| zookeeper.session.timeout.ms | 指定ZooKeeper会话超时，以毫秒为单位。默认值为30000毫秒；如果服务器在这段时间内未能向ZooKeeper发出心跳信号，则认为该服务器已经死机。如果将此值设置得太低，则可能会错误地将服务器视为已死，如果你设置得太高，可能需要很长时间才能识别真正死机的服务器；如果您发现频繁断开与ZooKeeper服务器的连接，请查看此设置。如果长时间的垃圾收集暂停导致Kafka丢失其ZooKeeper会话，则可能需要配置更长的超时值。|
| advertised.listeners | 如果已手动将侦听器设置为`advertised.listeners = PLAINTEXT://$HOSTNAME:$PORT`，则在启用Kerberos后，将侦听器配置更改为`advertised.listeners = SASL_PLAINTEXT://$HOSTNAME:$PORT`。 |

```
重要：

请勿更改以下连接设置.
zookeeper.connect : 逗号分隔的ZooKeeper <主机名:端口>对列表。Ambari设定了这个值。请勿更改此设置。
```

## 2.Topic设置
对于每个主题，Kafka都维护一个带有一个或多个分区的结构化提交日志。这些主题分区构成了Kafka的基本
并行单元。通常，Kafka群集中的分区越多，可以添加的并行消费者越多，从而导致更高的吞吐量。

您可以根据吞吐量要求计算分区数。如果从生产者到单个分区的吞吐量为`P`，并且从单个分区到使用者的吞吐
量为`C`，并且如果目标吞吐量为`T`，则所需分区的最小数量为：
```
max(T/P,T/C)
```
另请注意，**更多分区可能会增加延迟**：
+ Kafka中的端到端延迟定义为从生成器发布消息到消费者读取消息的时间差。
+ 将消息复制到所有同步副本后，Kafka只有在消费者提交后才向消费者公开消息。
+ 从一个broker到另一个broker的一千个分区的复制可能需要20ms。这对于某些实时应用来说太长了。
+ 在新的Kafka生产者中，消息在生产者一方积累；生产者缓冲每个分区的消息。此方法允许用户设置用于缓
冲传入消息的内存量的上限。累积足够的数据或经过足够的时间后，累积的消息将被删除并发送给broker。如
果定义了更多分区，则会在生产者端为更多分区累积消息。
+ 类似地，消费者每个分区获取批量消息。消费者内存要求与消费者订阅的分区数成正比。

### 重要Topic题属性
查看高级`kafka-broker`类别中的以下设置，并根据需要进行修改：

| 属性 | 描述 |
| :------------- | :------------- |
| auto.create.topics.enable | 启用在服务器上自动创建主题。如果此属性设置为true，则尝试生成，使用或获取不存在主题的元数据会自动创建具有默认复制因子和分区数的主题。默认设置已启用。 |
| default.replication.factor | 指定自动创建的主题的默认复制因子。对于高可用性生产系统，应将此值设置为至少3。|
| num.partitions | 为自动创建的主题指定每个主题的默认日志分区数。默认值为1。根据与主题和分区设计相关的要求更改此设置。 |
| delete.topic.enable | 允许用户使用管理工具从Kafka中删除`Kafka 0.9`及更高版本的主题。果关闭此设置，则通过管理工具删除主题将不起作用。默认情况下，此功能处于关闭状态（设置为false）。|

## 3.日志设置
**查看Kafka Broker类别中的以下设置，并根据需要进行修改**：

| 属性 | 描述 |
| :------------- | :------------- |
| log.roll.hours | 推出新日志段之前的最长时间（以小时为单位）。默认值为168小时（七天）。此设置控制Kafka强制日志滚动的时间段，即使段文件未满。这可确保保留过程能够删除或压缩旧数据。|
| log.retention.hours | 在删除日志文件之前保留日志文件的小时数。默认值为168小时（七天）。设置此值时，请考虑您的磁盘空间以及您希望消息可用的时间。活跃的消费者可以快速阅读并将消息传递到目的地。保留设置越高，数据保留的时间越长。较高的设置会生成较大的日志文件，因此增加此设置可能会降低整体存储容量。|
| log.dirs | 以逗号分隔的目录列表，其中保存了日志数据。如果您有多个磁盘，请列出每个磁盘下的所有目录。|

**查看高级kafka-broker类别中的以下设置，并根据需要进行修改**：

| 属性 | 描述 |
| :------------- | :------------- |
| log.retention.bytes | 每个主题分区的日志中保留的数据量。默认情况下，日志大小不受限制；请注意，这是每个分区的限制，因此将此值乘以分区数以计算为主题保留的总数据；如果同时设置了log.retention.hours和log.retention.bytes，则Kafka会在超出任一限制时删除一个段。|
| log.segment.bytes | 主题分区的日志存储为segment文件的目录。此设置控制在日志中滚动新段之前段文件的最大大小。默认值为1GB。 |

### 日志刷新管理
Kafka在收到后立即将主题消息写入日志文件，但数据最初在页面缓存中缓冲。日志刷新强制Kafka从页面缓
存中刷新主题消息，将消息写入磁盘。**我们建议使用默认的刷新设置**，它依赖于Linux和Kafka完成的后
台刷新。默认设置提供高吞吐量和低延迟，并且它们通过使用复制保证恢复。

如果您决定指定自己的刷新设置，则可以在一段时间后，或在指定数量的消息之后或两者都强制刷新（以先达
到的限制为准）。您可以全局设置属性值，并基于每个主题覆盖它们。

有关日志文件刷新的几个重要注意事项：
+ **耐用性**：在发生崩溃时，未刷新的数据更容易丢失。失败的broker可以从其副本中恢复主题分区，但
是如果跟随者未在`replica.lag.time.max.ms`指定的时间内发出获取请求或从领导者的日志末端偏移中
消耗（默认为10秒），领导者从同步副本（“ISR”）中删除跟随者。发生这种情况时，如果没有显式设置
`log.flush.interval.messages`，则可能会丢失一小部分消息。如果领导经纪人失败并且追随者没有赶
上领导者，则追随者仍然可以在ISR下持续10秒，并且领导者过渡到追随者期间的消息可能会丢失。
+ **延迟增加**：在刷新之前，消费者无法获得数据（大多数Linux文件系统中的fsync实现会阻止写入文件
系统）。
+ **吞吐量**：刷新操作通常是昂贵的操作。
+ 磁盘使用模式效率较低。
+ 背景刷新中的页级锁定更加精细。

`log.flush.interval.messages`指定在Kafka强制将数据刷新到磁盘之前在日志分区上累积的消息数。

`log.flush.scheduler.interval.ms`指定Kafka检查日志是否需要刷新到磁盘的时间（以毫秒为单位）。

`log.segment.bytes`指定日志文件的大小。只要日志文件达到其最大大小，Kafka就会将日志文件刷新到
磁盘。

`log.roll.hours`指定新日志段推出之前的最长时间（以小时为单位）;此值是`log.roll.ms`的次要值。
只要日志文件达到此时间限制，Kafka就会将日志文件刷新到磁盘。

## 4.压缩设置
查看高级kafka-broker类别中的以下设置，并根据需要进行修改：

| 属性 | 描述 |
| :------------- | :------------- |
| log.cleaner.dedupe.buffer.size | 指定跨所有清整线程，用于日志重复数据删除的总内存。默认情况下，分配128MB的缓冲区。您可能希望查看此日志和其他log.cleaner配置值，并根据您对压缩主题的使用（__consumer_offsets和其他压缩主题）调整设置。 |
| log.cleaner.io.buffer.size | 指定用于所有清理程序线程中的日志清理程序I/O缓冲区的总内存。默认情况下，分配512KB的缓冲区。您可能需要查看此日志和其他log.cleaner配置值，并根据您对压缩主题的使用情况调整设置（__consumer_offsets和其他压缩主题）。|

## 5.一般broker设置
查看高级kafka-broker类别中的以下设置，并根据需要进行修改：

| 属性 | 描述 |
| :------------- | :------------- |
| auto.leader.rebalance.enable | 实现自动leader平衡。后台线程定期检查并触发leader平衡（如果需要）。默认设置已启用。 |
| unclean.leader.election.enable | 此属性允许您指定可用性或持久性的首选项。这是一个重要设置：如果可用性比避免数据丢失更重要，请确保将此属性设置为true。如果防止数据丢失比可用性更重要，请将此属性设置为false。此设置操作如下：a.如果unclean.leader.election.enable设置为true（启用），则在没有实时同步副本（ISR）时，将选择不同步副本作为leader。这样可以保留分区的可用性，但可能会丢失数据。b.如果将unclean.leader.election.enable设置为false并且没有实时同步副本，则Kafka将返回错误并且该分区将不可用；默认情况下，此属性设置为true，这有利于可用性。如果持久性优于可用性，请将unclean.leader.election设置为false。 |
| controlled.shutdown.enable | 启用服务器的受控关闭。默认设置已启用。|
| min.insync.replicas | 当生产者将acks设置为“all”时，min.insync.replicas指定必须确认写入被认为成功的最小副本数。如果无法满足此最小值，则生产者将引发异常。当一起使用时，min.insync.replicas和producer acks允许您强制执行更强的持久性保证。您应该将min.insync.replicas设置为2，复制因子等于3。 |
| message.max.bytes | 指定服务器可以接收的最大消息大小。重要的是，应考虑消费者使用的最大提取大小来设置此属性，否则生产者可能会发布过大的消息以供消费者使用。请注意，目前有两个版本的消费者和生产者API。message.max.bytes的值必须小于新使用者中的max.partition.fetch.bytes设置，或者小于旧消费者中的fetch.message.max.bytes设置。 此外，该值必须小于replica.fetch.max.bytes。|
| replica.fetch.max.bytes | 指定要尝试获取的消息的字节数。该值必须大于message.max.bytes。|
| broker.rack | 机架感知功能可在不同机架上分配分区的副本。您可以通过“Custom kafka-broker”菜单选项指定broker属于特定机架。有关的更多信息请参阅http://kafka.apache.org/documentation.html#basic_ops_racks。 |



































dd
