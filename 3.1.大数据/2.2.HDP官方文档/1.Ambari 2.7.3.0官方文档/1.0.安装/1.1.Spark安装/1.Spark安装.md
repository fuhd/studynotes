Spark安装
================================================================================
## 1.Spark先决条件
在安装Spark之前，请确保您的群集满足以下先决条件：
+ HDP集群堆栈版本为3.0或更高版本
+ Ambari版本为2.7.0或更高版本（可选）
+ HDFS和YARN部署在群集上

**仅支持Spark版本2**。

此外，请注意以下有关可选Spark服务和功能的要求和建议：
+ Spark Thrift服务器需要在群集上部署Hive。
+ SparkR需要在所有节点上安装R二进制文件。
+ 通过Livy访问Spark需要在群集上安装Livy服务器。
+ PySpark和相关库需要在所有节点上安装Python2.7或更高版本，或Python3.4或更高版本。
+ 要获得MLlib的最佳性能，请考虑安装`netlib-java`库。
    ```
    netlib-java相关信息：
    https://github.com/fommil/netlib-java
    ```

## 2.使用Ambari安装Spark
使用以下步骤在Ambari管理的群集上安装Apache Spark。

### 2.1.关于这个任务
下图显示了使用Ambari的Spark安装过程。在使用Ambari安装Spark之前，请参阅Ambari管理和监视群集
指南中的“*添加服务*”，以获取有关如何使用Ambari安装Hortonworks Data Platform（HDP）组件的
背景信息。

![安装spark](img/1.png)

```
警告

在安装过程中，Ambari会创建并编辑多个配置文件。如果使用Ambari配置和管理群集，请不要在安装期间或之后编辑这些文件。而是使用
Ambari Web UI修改配置设置。
```






























dd
