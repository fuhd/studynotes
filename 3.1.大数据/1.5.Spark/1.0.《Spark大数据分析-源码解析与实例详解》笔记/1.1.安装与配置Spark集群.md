安装与配置Spark集群
================================================================================
## 1.下载Spark安装包
本书将使用Spark官方编译好的软件包进行安装。**在少数情况下，才会自行编译Spark源码或在编译之前根
据具体业务修改部分源码**。
+ 进入版本选择页面后，选择2.3.1版本，并单击“spark-2.3.1-bin-hadoop2.7.tgz”链接。
+ 将下载好的Spark压缩包上传至第1台虚拟机的“home/admin/softwares/installations”目录下。

## 2.检查与准备集群环境 

### 2.1.虚拟机的配置项
下表列出了三台虚拟机的核心配置项：
> 三台虚拟机的系统均为CentOS6.8版本，其与CentOS7.x系列版本的使用方式大同小异。

| 配置项 | linux01 | linux02 | linux03 |
|:------|:--------|:--------|:--------|
| 内存 | 4GB | 2GB | 2GB |
| CPU内核数 | 2 | 1 | 1 |
| 硬盘 | 50GB（单分区）| 50GB（单分区）|50GB（单分区）|
| 网络适配器 | NAT | NAT | NAT |

### 2.2.配置虚拟机系统
在部署Spark集群之前，需要确保三台虚拟机的软件环境一致的。

#### 2.2.1.禁用SELinux
分布式框架在进行端口通信时，**SELinux有可能阻塞其中的通信，因此暂且将其禁用**。在CentOS6.8中，
使用如下命令编辑SELinux配置文件：
```shell
vi /etc/sysconfig/selinux00000
```
并将SELINUX选项改为：
```ini
SELINUX:disable
```

#### 2.2.2.关闭防火墙
防火墙也可以导致分布式框架之间的通信被拒绝，因此暂且关闭防火墙。**在CentOS6.8系统中**，使用如下
命令关闭iptables防火墙。
```shell
service iptables stop
chkconfig iptables off
```
> 在CentOS7.X系统中，用firewalld替代了iptables。关闭防火墙的命令如下：
>
> systemctl stop firewalld.service
>
> systemctl disable firewalld.service 

#### 2.2.3.配置网卡文件
在CentOS6.8中编辑网卡配置文件的命令如下：
```shell
vi /etc/sysconfig/network-scripts/ifcfg-eth0
```
编辑内容如下：
```ini
#当前机器的IP地址
IPADDR=192.168.216.20
#固定的子网掩码地址
NETMASK=255.255.255.0
#网关地址
GATEWAY=192.168.216.2
#首选DNS，设置为网关的IP地址即可
DNS1=192.168.216.2
#备选DNS，设置为如下即可
DNS2=8.8.8.8
#设置为静态配置IP地址模式 
BOOTPROTO=static
#是否开机自动启动网卡
ONBOOT=yes
```
编辑完后，重启网卡：
```shell
service network restart
```
其余两台虚拟机网卡配置过程与上述过程基本一致。

#### 2.2.4.修改IP地址与主机名的映射关系 
```shell
vi /etc/hosts
```
将其修改为如下内容：
```ini
192.16.216.20 linux01
192.16.216.21 linux02
192.16.216.22 linux03
```

#### 2.2.5.实现3台虚拟机之间的无秘钥访问 
以其中一台虚拟机上的操作为例，首先，执行以下命令生成秘钥：
```shell
ssh-keygen -t rsa
```
然后，分发公钥至3台虚拟机，命令如下：
```shell
ssh-copy-id linux01;
ssh-copy-id linux02;
ssh-copy-id linux03;
```

#### 2.2.6.关闭桌面GUI
开发者几乎不会在Linux虚拟机中使用桌面UI，而是全部通过命令行进行系统操作，并且开启桌面UI会额外地 
增加系统的开销。因此可以考虑关闭GUI。

首先，在CentOS中关闭GUI需要 **编辑inittab文件**：
```shell
vi /etc/inittab
```
然后，**根据inittab文件中的描述，将其中的id修改为“2”**。

> 在CentOS7.X版本的系统中，关闭GUI的命令如下：
>
> systemctl set-default multi-user.target

#### 2.2.7.配置sudo权限
为方便普通用户临时使用更高的权限来执行命令，**需要编辑sudo文件来对普通用户进行授权**。首先编辑
sudo文件，具体命令如下：
```shell
visudo
```
然后在文件中增加如下内容：
```shell
admin ALL=(ALL) NOPASSWD: ALL
```

#### 2.2.8.配置时间服务器
三台虚拟机的系统时间应该是一致的。所以最好的方法是：**将第一台虚拟机配置为时间服务器，其余两台虚
拟 机通过ntpdate命令同步第一台虚拟机的时间，并将ntpdate命令配置到crontab脚本中，以使每隔若干
分钟同步一次**。具体操作这里不再详述。

#### 2.2.9.配置Java环境变量
系统变量与用户变量的配置文件所在位置分别如下所示：
+ 系统变量： /etc/profile
+ 用户变量：~/.bashrc

配置内容如下：
```shell
JAVA_HOME=/home/admin/modules/jdk1.8.0.121
export PATH=$PATH:$JAVA_HOME/bin
```

### 2.3.配置Windows中的hosts文件
在Windows中，为了可以通过虚拟机的主机名来访问虚拟机，最好将虚拟机的主机名与IP地址的映射关系保存
在Windows的“C:\Windows\System32\drivers\etc\hosts“文件中，示例内容如下：
```ini
192.168.216.20  linux01
192.168.216.21  linux02
192.168.216.22  linux03
```

## 3.了解目前集群中已经部署的框架服务 
**在生产环境中，完全独立地使用Spark的场景极其罕见**。大多数情况下Spark会与Hadoop及其他相关框
架配合使用。下表列出了目前在虚拟机中已部署的框架服务。

| 框架类别 | Linux01 | Linux02 | Linux03 |
|:--------|:--------|:--------|:--------|
| HDFS(Hadoop2.7.2) | NameNode, DataNode | DateNode | DataNode, SecondaryNameNode |
| YARN-MR(Hadoop2.7.2)|NodeManger, JobHistoryServer | ResourceManager, NodeManger | NodeManger |
| Zookeeper(Zookeeper3.4.x)|QuorumPeerMain | QuorumPeerMain | QuorumPeerMain |

## 4.部署Spark集群
下面详细列举了Spark目前支持的部署模式：
+ **Local模式**：在本地部署单个Spark服务。
+ **Standalone模式**：Spark自带的任务调度模式（**国内常用**）。
+ **YARN模式**：Spark使用Hadoop的YARN组件来进行资源与任务的调度（**国内常用**）。
+ **Mesos模式**：Spark使用Mesos平台进行资源与任务的调度。
+ **Kubernates模式**：自Spark2.3.x版本之后才开始支持Kubernates模式。

> 在Spark2.3.x之前的版本中，仅支持其它四种模式。

### 4.1.实例1：基于Standalone模式部署Spark集群
**在中小规模的集群中，基于Standalone模式部署Spark集群十分常见。利用Standalone模式自带的任务、
资源调度引擎，无须依赖其他调度平台即可正常运行Spark，减少了部署时的麻烦**。

> 提示：
>
> 在部署时，会涉及两个新的概念：Master服务与Worker服务。
>
> Master服务所在的虚拟机被称为：Spark主节点。
>
> Worker服务所在的虚拟机被称为：Spark从节点。

#### 4.1.1.解压缩 
用以下命令解压缩刚才下载好的Spark安装包：
```shell
tar -zxf /home/admin/softwares/installations/spark-2.3.1-bin-hadoop2.7.tgz -C /home/admin/modules/
```

#### 4.1.2.查看默认的配置文件
1. 执行如下命令，进入Spark配置文件所在目录：
```shell
cd spark-2.3.1-bin-hadoop2.7/conf
```
2. 通过`ll`或`ls -l`命令查看目录下的文件列表。所有文件的后缀后都是”template“，这是官方默认的
文件命名方式。如果此时直接启动Spark，则这些文件内的属性不会生效。

#### 4.1.3.去掉默认配置文件的后缀名
**将文件名中的后缀名”.template“去掉**，命令如下：
```shell
for i in *.template; do mv ${i} ${i%.*}; done
```
> 提示
>
> 这里使用shell语法中的 **for循环**，对当前目录中的所有文件进行重命名操作。**其中”`${i%.*}`"
> 的含义是：从右边截取字符串到第1个“.”字符出现的位置，并删除该字符右边的全部内容，保留该字符右边
> 的全部内容**。

#### 4.1.4.修改默认配置

1. **修改slaves文件**
**该文件描述了Spark有哪些虚拟机负责启动Worker服务**。先删除“localhost”所在的哪一行内容，然后
添加主机名称 （IP地址），配置如下：
```shell
vi slaves
```
添加：
```shell
linux01
linux02
linux03
```
> 在添加主机名时，请确保每一个主机名独占一行。

2. **继续修改spark-env.sh文件**
添加如下配置：
```ini
SPARK_MASTER_HOST=linux01
SPARK_MASTER_PORT=7077
```

3. **将配置好的Spark安装文件分发到其他集群**
```shell
scp -r spark-2.3.1-bin-hadoop2.7/ linux02:/home/admin/modules/
scp -r spark-2.3.1-bin-hadoop2.7/ linux03:/home/admin/modules/
```

#### 4.1.5.启动并查看服务 

1. **执行并查看服务**
进入第一台虚拟机的Spark安装目录，启动所有Spark节点的相关服务。
```shell
sbin/start-all.sh
```

2. **访问 Web页面，查看Spark的运行状态**
可以通过Web页面来查看Spark的运行状态。在本例中，在浏览器中输入：`http://linux01:8080`。

### 4.2.实例2：部署Spark的历史服务———Spark History Server
