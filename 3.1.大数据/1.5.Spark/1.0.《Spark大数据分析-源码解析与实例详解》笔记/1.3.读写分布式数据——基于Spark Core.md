读写分布式数据——基于Spark Core
================================================================================
## 1.RDD诞生
在Hadoop MapReduce中进行reduce操作时，也会将多个数据封装到某个集合中进行迭代聚合，代码如下：
```java
protected void reduce(Text key, Iterable<LongWritable> values, Context context)
```
其中，reduce方法中第2个参数"values"就是一个可以迭代的集合。

因此，如果想要方便处理数据，Spark也需要引入 **集合** 的概念————”**DataSet(数据集)**“。其次，
Spark的研发目标是解决大数据量的数据分析问题，那么数据一定是分布式存储的，所以引入 **分布式**概念
————”**Distributed(分布式)**“。

**在Hadoop MapReduce中，Shuffle过程会频繁将内存中保存的中间计算结果数据”溢写“到磁盘中，从而
引发大量磁盘I/O，导致处理数据的效率大幅度下降**。而Spark中有一个 **基于内存缓存**的”集合“概念，
可以解决类似问题。**并且Spark允许在内存不足的情况下，将这个集合内的数据溢写到磁盘中，即：数据优
先存储在内存中，如果内存空间不足，再将数据溢写到磁盘中**。这种行为引申出一个概念————”**Resilient
（弹性的）**“。