读写分布式数据——基于Spark Core
================================================================================
## 1.RDD诞生
在Hadoop MapReduce中进行reduce操作时，也会将多个数据封装到某个集合中进行迭代聚合，代码如下：
```java
protected void reduce(Text key, Iterable<LongWritable> values, Context context)
```
