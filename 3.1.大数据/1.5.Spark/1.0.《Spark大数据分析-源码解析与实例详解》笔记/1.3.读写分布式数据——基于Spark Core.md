读写分布式数据——基于Spark Core
================================================================================
## 1.RDD诞生
在Hadoop MapReduce中进行reduce操作时，也会将多个数据封装到某个集合中进行迭代聚合，代码如下：
```java
protected void reduce(Text key, Iterable<LongWritable> values, Context context)
```
其中，reduce方法中第2个参数"values"就是一个可以迭代的集合。

因此，如果想要方便处理数据，Spark也需要引入 **集合** 的概念————”**DataSet(数据集)**“。其次，
Spark的研发目标是解决大数据量的数据分析问题，那么数据一定是分布式存储的，所以引入 **分布式**概念
————”**Distributed(分布式)**“。

**在Hadoop MapReduce中，Shuffle过程会频繁将内存中保存的中间计算结果数据”溢写“到磁盘中，从而
引发大量磁盘I/O，导致处理数据的效率大幅度下降**。而Spark中有一个 **基于内存缓存**的”集合“概念，
可以解决类似问题。**并且Spark允许在内存不足的情况下，将这个集合内的数据溢写到磁盘中，即：数据优
先存储在内存中，如果内存空间不足，再将数据溢写到磁盘中**。这种行为引申出一个概念————”**Resilient
（弹性的）**“。

当然，我们后续会了解到，可以切换存储方式（内存或磁盘）并非”Resilient（弹性）“的唯一特征。

综上所述，**Spark引入了一个弹性的、分布式的数据集合————RDD（resilient distributed dataset）**。

## 2.进一步理解RDD
先从三个不同的角度理解RDD：**数据存储、数据分析、程序调度**。

### 2.1.数据存储

#### 2.1.1.分布式存储
单台机器的处理能力无法满足大数据场景，因此需要使用多台机器同时处理数据。**而在多台机器同时处理数据
之前，必须先将数据切分成多份，以便分散存储在不同的机器中。当所有数据都处理完毕后，再将处理结果汇
总到某一台机器上，这就是分布式运算的大致思想**。

RDD中的数据被切分成多个 **分区**（也可以称为”**分片**“）分别存储在不同的机器上。在RDD中，可以
通过 **foreachPartition方法** 遍历当前RDD中的每一个分区，进而遍历分区内的每一个数据元素。

开发者可以通过3种方式创建RDD:
1. **在程序内部创建**：将某个集合作为参数传入`sparkContext.parallelize(Seq)`方法，就可以
生成一个RDD集合。
> 提示：这里的“某个集合”是指编程语言中的”有序集合”。
2. **从程序外部读取**：通过类似于`sparkContext.textFile(path)`这样的方法读取外部文件系统中
的数据，并生成RDD。
3. **RDD转换操作**：通过对一个RDD执行转换操作，得到一个新的RDD。

#### 2.1.2.内存优先
Spark为了实现快速运算，优先使用内存缓存数据。**在默认情况下，如果某个分区中的数据可以完整地缓存
到内存中，则不会使用磁盘缓存数据**。将数据缓存到内存中的Spark程序比Hadoop MapReduce程序运算
速度快100倍左右。

在Spark中，**可以手动调整缓存数据的方式（内存或磁盘）**。即使是基于磁盘缓存数据，Spark程序的运
算速度也比Hadoop MapReduce程序快10倍左右。所以，存储上的优化并不是Spark比MapReduce快的唯一
原因，但却是显著原因。

#### 2.1.3.保障数据可靠性
**RDD通过”血统（lineage）“关系保障数据可靠性**。例如，RDD3是由RDD2运算生成的，RDD2是由RDD1
运算生成的，这个过程可以表述为：RDD3依赖RDD2，RDD2依赖RDD1。**每个RDD实例都会记录上层的依赖关
系**。
> 提示：多个RDD之间的”血缘关系”也可被称为RDD的“依赖链”。

**程序在运行时，如果中间某个RDD的数据出现丢失或错误，通过RDD的血缘关系重新运算后即可恢复**。在
恢复过程中，并不是一定需要对全景数据进行重算，有时只需要重算某些分区中的数据即可。

假设某条RDD的依赖链很长，如果此时依赖链尾部的某个RDD出现问题，则恢复该RDD必会耗费大量时间。为了
解决这个问题，**Spark为开发者提供了持久化RDD的API，开发者可以缓存依赖链中的某个RDD，或对其中某
个RDD设置检查点（`Checkpoint`），从而减少数据重算的工作量**。在比较长的依赖链中，合理缓存多个
RDD可以大幅度提高容错效率。

### 2.2.数据分析
开发者可以通过RDD中封装的各种方法来操作其内部的数据。
```scala
sc.textFile("hdfs://linux01:8020/words.txt")                    //1
    .flatMap(_.split(" "))                                      //2
    .map((_, 1))                                                //3                         
    .reduceByKey(_ + _, 1)                                      //4
    .sortBy(_._2, false)                                        //5
    .saveAsTextFile("hdfs://linux01:8020/output")               //6
```
一般将RDD操作归为两类，结合上述代码说明如下：

#### 2.2.1.转换（transformations）操作 
+ 代码第1行，通过`sc.textFile`方法读取数据并生成RDD，暂且称之为RDD1。
+ 代码第2行：RDD1执行flatMap转换转换操作，生成一个新的RDD3。
+ RDD2是通过RDD1利用转换操作得到的。所以它们之间存在依赖关系。代码第3～5行都属性“转换操作”，但
**转换操作不会立即执行，而是制定了一个任务计划。直到出现“行动操作”，该任务计划才会变成具体任务被
执行**。

#### 2.2.2.行动（actions）操作 
+ 代码第6行，是一个“行动操作”。`saveAsTextFile`方法是将RDD中的数据保存到外部文件系统中（本例
是HDFS）。
+ **“行动操作”可以触发Spark任务计划开始执行**。

### 2.3.程序调度
分布式Spark程序的调度过程会涉及如下概念。

#### 2.3.1.Driver
在WordCount实例中，首先编写了一个 **“驱动程序”（`Driver Program`），简称“Driver”**。它的
主要功能是在工程的主方法中创建 **Spark的上下文实例（`SparkContext`），上下文实例是连接Spark
集群的入口。Driver包含WordCount程序的全部代码，并记录着每一个RDD的依赖关系**。

#### 2.3.2.Job
**提交程序，可以描述为“提交Driver Program”。这并不是提交一个工作（`Job`），也不是提交一个任
务（`Task`）。在整个程序中，每出现一个“行动操作”就会生成一个Job**。`saveAsTextFile`操作会产
生一个Job。而“转换操作“并不会产生Job。

#### 2.3.3.Stage







