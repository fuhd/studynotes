读写分布式数据——基于Spark Core
================================================================================
## 1.RDD诞生
在Hadoop MapReduce中进行reduce操作时，也会将多个数据封装到某个集合中进行迭代聚合，代码如下：
```java
protected void reduce(Text key, Iterable<LongWritable> values, Context context)
```
其中，reduce方法中第2个参数"values"就是一个可以迭代的集合。

因此，如果想要方便处理数据，Spark也需要引入 **集合** 的概念————”**DataSet(数据集)**“。其次，
Spark的研发目标是解决大数据量的数据分析问题，那么数据一定是分布式存储的，所以引入 **分布式**概念
————”**Distributed(分布式)**“。

**在Hadoop MapReduce中，Shuffle过程会频繁将内存中保存的中间计算结果数据”溢写“到磁盘中，从而
引发大量磁盘I/O，导致处理数据的效率大幅度下降**。而Spark中有一个 **基于内存缓存**的”集合“概念，
可以解决类似问题。**并且Spark允许在内存不足的情况下，将这个集合内的数据溢写到磁盘中，即：数据优
先存储在内存中，如果内存空间不足，再将数据溢写到磁盘中**。这种行为引申出一个概念————”**Resilient
（弹性的）**“。

当然，我们后续会了解到，可以切换存储方式（内存或磁盘）并非”Resilient（弹性）“的唯一特征。

综上所述，**Spark引入了一个弹性的、分布式的数据集合————RDD（resilient distributed dataset）**。

## 2.进一步理解RDD
先从三个不同的角度理解RDD：**数据存储、数据分析、程序调度**。

### 2.1.数据存储

#### 2.1.1.分布式存储
单台机器的处理能力无法满足大数据场景，因此需要使用多台机器同时处理数据。**而在多台机器同时处理数据
之前，必须先将数据切分成多份，以便分散存储在不同的机器中。当所有数据都处理完毕后，再将处理结果汇
总到某一台机器上，这就是分布式运算的大致思想**。

RDD中的数据被切分成多个 **分区**（也可以称为”**分片**“）分别存储在不同的机器上。在RDD中，可以
通过 **foreachPartition方法** 遍历当前RDD中的每一个分区，进而遍历分区内的每一个数据元素。

开发者可以通过3种方式创建RDD:
1. **在程序内部创建**：将某个集合作为参数传入`sparkContext.parallelize(Seq)`方法，就可以
生成一个RDD集合。
> 提示：这里的“某个集合”是指编程语言中的”有序集合”。
2. **从程序外部读取**：通过类似于`sparkContext.textFile(path)`这样的方法读取外部文件系统中
的数据，并生成RDD。
3. **RDD转换操作**：通过对一个RDD执行转换操作，得到一个新的RDD。

#### 2.1.2.内存优先
Spark为了实现快速运算，优先使用内存缓存数据。**在默认情况下，如果某个分区中的数据可以完整地缓存
到内存中，则不会使用磁盘缓存数据**。将数据缓存到内存中的Spark程序比Hadoop MapReduce程序运算
速度快100倍左右。

在Spark中，**可以手动调整缓存数据的方式（内存或磁盘）**。即使是基于磁盘缓存数据，Spark程序的运
算速度也比Hadoop MapReduce程序快10倍左右。所以，存储上的优化并不是Spark比MapReduce快的唯一
原因，但却是显著原因。

#### 2.1.3.保障数据可靠性
**RDD通过”血统（lineage）“关系保障数据可靠性**。例如，RDD3是由RDD2运算生成的，RDD2是由RDD1
运算生成的，这个过程可以表述为：RDD3依赖RDD2，RDD2依赖RDD1。**每个RDD实例都会记录上层的依赖关
系**。
> 提示：多个RDD之间的”血缘关系”也可被称为RDD的“依赖链”。

**程序在运行时，如果中间某个RDD的数据出现丢失或错误，通过RDD的血缘关系重新运算后即可恢复**。在
恢复过程中，并不是一定需要对全景数据进行重算，有时只需要重算某些分区中的数据即可。

假设某条RDD的依赖链很长，如果此时依赖链尾部的某个RDD出现问题，则恢复该RDD必会耗费大量时间。为了
解决这个问题，**Spark为开发者提供了持久化RDD的API，开发者可以缓存依赖链中的某个RDD，或对其中某
个RDD设置检查点（`Checkpoint`），从而减少数据重算的工作量**。在比较长的依赖链中，合理缓存多个
RDD可以大幅度提高容错效率。





