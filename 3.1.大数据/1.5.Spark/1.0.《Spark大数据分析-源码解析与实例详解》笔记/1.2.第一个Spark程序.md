第一个Spark程序
================================================================================
## 1.运行第1个Spark程序
在运行第1个Spark程序之前，需要先了解提交并运行程序的流程。
1. **在提交一个Spark程序时，用于提交该程序的窗口被称为Client（客户）端。提交后的程序会向Master
服务申请资源，并启动一个Driver进程，其中包含该程序的全部代码**。
2. **每个Worker服务会启动Executor进程，该进程负责与Driver进程建立RPC通信，用于接收并运行
Driver进程派发过来的任务，并将任务的执行状态持续反馈给Driver进程**。

### 1.1.实例5：基于Standalone模式运行第1个Spark程序
使用蒙特卡洛算法求Pi的值。

#### 1.1.1.提交程序 
进入Spark的安装目录，通过脚本提交程序：
```shell
bin/spark-submit --class org.apache.spark.examples.SparkPi
    --master spark://linux01:7077
    --executor-memory 1G
    --total-executor-cores 3
    /home/admin/modules/spark-2.3.1-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.3.1.jar
    100
```
+ 通过`--class`参数设置jar包中入口类的类名。
+ 通过`--master`参数设置Master服务的通信地址，包含机器的IP地址和端口号（可以使用IP地址来代替
主机名）。
+ 通过`--executor-memory`参数设置每个Executor进程的可用内存，如果任务运行时所使用的内存超过
该值，则会出现虚拟机内存溢出错误。
    > 提示：每一个Worker节点都可以创建若干个Executor进程来执行具体任务，即Executor是具体执行任务的进程。
+ 通过`--total-executor-cores`参数设置集群中一共可以调度多少个CPU内核（CPU Cores）来执行任
务。一个CPU内核在同一时间 内只能运行一个任务（Task）。在设置该参数时，需要结合机器硬件资源的配置
情况。例如，分配到的CPU内核越多，则任务的并行度越高，任务完成的时间也越短。
+ 第五行代码指定jar包的位置。该jar包中包含要运行的程序。
+ 最后一行，100为程序参数，该参数会被传递到主方法中。该参数用于指定随机“点”的个数。

> 提示：在执行该任务时，如果没有启动Spark的历史服务，则任务执行完毕后无法查看任务日志。

#### 1.1.2.观察与总结
在上述操作中，即使没有明显的报错信息，也应该去看一下任务日志。下面将通过Spark历史服务（History 
Server）页面来查看任务日志。
1. **查看Spark的历史任务**
在任务成功运行后，可以看到Pi的粗略值已经被计算出来了：Pi is roughly 3.1417199141719916。此
时来到Spark历史服务页面`http://linux01:4000`，可以看到该任务日志。
2. **查看HDFS中的日志文件**
访问`http://linux01:50070/explorer.html#/spark-logs`，来到HDFS的“/spark-logs”目录下，
可以看到，产生了一个对应刚才任务的文件。该文件夹目录下的文件记录着刚才任务的日志信息。

### 1.2.实例6：基于YARN模式运行第1个Spark程序

#### 1.2.1.确认Hadoop集群已正常运行
> 提示：
>
> Hadoop的Job History Server并不是Spark的History Server，这是完全不同的两个服务。
>
> + Hadoop的Job History Server，为YARN中运行的程序提供历史日志服务。
>
> + Spark的History Server，为所有Spark程序提供历史日志服务。
>
> 基于Spark on YARN运行的程序，也可以通过 Spark History Server查看日志。

#### 1.2.2.用YARN-Client方式提交程序 
1. 提交程序 
进入Spark的安装目录，使用YARN-Client方式提交程序。具体命令如下：
```shell
bin/spark-submit 
    --class org.apache.spark.examples.SparkPi
    --master yarn
    --deploy-mode client
    --executor-memory 1G
    --total-executor-cores 3
    /home/admin/modules/spark-2.3.1-bin-hadoop2.7/ecamples/jars/spark-examples_2.11-2.3.1.jar
    100
```
2. 查看任务进度
在提交程序之后，可以进入YARN的Web页面查看任务度。Web页面 地址如下：
http://linux02:8088/cluster/apps 

> 当前我使用的端口是：8099，这是YARN的HA方案配置:
> ```xml
> <property>
>     <name>yarn.resourcemanager.webapp.address.rm005</name>
>     <value>bigdata005:8099</value>
> </property>
> <property>
>     <name>yarn.resourcemanager.webapp.address.rm008</name>
>     <value>bigdata008:8099</value>
> </property>
> ```

> 提示：
>
> 基于该方式运行的程序，Client客户端会与Driver进程绑定在一起，如果用于提交程序的Client客户端退出，则意味着Driver进程退出，程序将无法继续执行。

#### 1.2.3.用YARN-Cluster方式提交程序 
1. 提交程序 
进入Spark的安装目录后，执行如下命令：
```shell
bin/spark-submit
    --class org.apache.spark.examples.SparkPi
    --master yarn
    --deploy-mode cluster
    --executor-memory 1G
    --total-executor-cores 3
    /home/admin/modules/spark-2.3.1-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.3.1.jar 
    100
```

2. 查看任务记录
此时并不能在控制台直接看到输出结果，只是看到程序在进行。当程序运行完毕后，前往YARN的Web页面，找
到本次程序的运行记录，然后依次单击“History”链接——>"Logs"链接找开日志，在日志最后一行可以看到已
经求出了Pi的值。
> 提示：
>
> 基于该方式运行的程序，Client客户端不会与Driver进程绑定在一起。如果用于提交程序的Client客户端退出，程序依然可以继续执行。这种方式可以保障集群内Executor进程和Driver进程通信更加稳定。

#### 1.2.4.总结
总结如下：
1. 如果现有集群中没有部署YARN集群，则使用Standalone模式提交程序。
2. 如果在现在的集群中已经部署了YARN集群，则使用YARN模式提交程序。当基于YARN模式提交程序时：
    + 在正式的生产环境中，推荐使用YARN-Cluster方式提交程序。
    + 在调试环境中，推荐使用YARN-Client方式提交程序。

### 1.3.提交Spark程序时的参数规范

| 参数 | 解释 | 可选值举例 |
|:----|:-----|:---------|
| `--class` | Spark程序中包含主函数的类 |  |
| `--master` | Spark程序运行的模式 | `local[*]`、`spark://linux01:7077`、`yarn` |
| `--deploy-mode` | Spark程序运行的方式 | `client`、`cluster` |
| `--driver-memory` | 每一个Driver进程的内存 | 符合集群内存配置即可。具体情况具体分析 |
| `--executor-memory` | 每一个Executor进程的可用内存 | 符合集群内存配置即可。具体情况具体分析 |
| `--executor-cores` | 每一个Executor进程的可用CPU核数 |  |
| `--total-executor-cores` | 所有Executor进程可用的总CPU核数 |  |
| `<application-jar>` | 程序对应的jar包路径 |  |
| `[application-arguments]` | 该程序主方法所接受的参数 |  |

 



