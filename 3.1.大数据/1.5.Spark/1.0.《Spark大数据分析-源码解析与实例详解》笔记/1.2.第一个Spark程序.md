第一个Spark程序
================================================================================
## 1.运行第1个Spark程序
在运行第1个Spark程序之前，需要先了解提交并运行程序的流程。
1. **在提交一个Spark程序时，用于提交该程序的窗口被称为Client（客户）端。提交后的程序会向Master
服务申请资源，并启动一个Driver进程，其中包含该程序的全部代码**。
2. **每个Worker服务会启动Executor进程，该进程负责与Driver进程建立RPC通信，用于接收并运行
Driver进程派发过来的任务，并将任务的执行状态持续反馈给Driver进程**。

### 1.1.实例5：基于Standalone模式运行第1个Spark程序
使用蒙特卡洛算法求Pi的值。

#### 1.1.1.提交程序 
进入Spark的安装目录，通过脚本提交程序：
```shell
bin/spark-submit --class org.apache.spark.examples.SparkPi
    --master spark://linux01:7077
    --executor-memory 1G
    --total-executor-cores 3
    /home/admin/modules/spark-2.3.1-bin-hadoop2.7/examples/jars/spark-examples_2.11-2.3.1.jar
    100
```
+ 通过`--class`参数设置jar包中入口类的类名。
+ 通过`--master`参数设置Master服务的通信地址，包含机器的IP地址和端口号（可以使用IP地址来代替
主机名）。
+ 通过`--executor-memory`参数设置每个Executor进程的可用内存，如果任务运行时所使用的内存超过
该值，则会出现虚拟机内存溢出错误。
> 提示：每一个Worker节点都可以创建若干个Executor进程来执行具体任务，即Executor是具体执行任务的进程。
+ 通过`--total-executor-cores`参数设置集群中一共可以调度多少个CPU内核（CPU Cores）来执行任
务。一个CPU内核在同一时间 内只能运行一个任务（Task）。在设置该参数时，需要结合机器硬件资源的配置
情况。例如，分配到的CPU内核越多，则任务的并行度越高，任务完成的时间也越短。
+ 第五行代码指定jar包的位置。该jar包中包含要运行的程序。


