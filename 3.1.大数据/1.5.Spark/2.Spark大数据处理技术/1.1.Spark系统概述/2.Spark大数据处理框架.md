Spark大数据处理框架
=================================================================================
针对上一节中MapReduce及各种专有系统中出现的不足，伯克利大学推出了全新的统一大数据处理框架Spark，
创新性地提出了 **RDD概念（一种新的抽象的弹性数据集）**，在某种程度上Spark是对MapReduce模型的一
种扩展。要在MapReduce上实现其不擅长的计算工作（比如 **迭代式、交互式和流式**），看上去是一件非常
困难的事情，**其实主要的原因是MapReduce缺乏一种特性，即在并行计算的各个阶段进行有效的数据共享，这
种共享就是RDD的本质**。利用这种有效的数据共享和类似MapReduce的操作接口，上述的各种专有类型计算都
能够有效地表达，而且能够获得与专有系统同等的性能。

特别值得一提的是，从前对于 **集群处理的容错方式**，比如 **MapReduce** 和Dryad，是将计算构建成为
一个 **有向无环图的任务集**。而这 **只能允许它们有效地重新计算部分DAG**。**在单独的计算之间（在迭
代的计算步骤之间），除了复制文件，这些模型没有提供其他的存储抽象，这就显著地增加了在网络之间复制文件
的代价。RDD能够适应当前大部分的数据并行算法和编程模型**。

### RDD表达能力
可以使用RDD实现很多现有的集群编程模型以及一些以前的模型不支持的新应用。在这些模型中，**RDD能够取得
和专有系统同样的性能**，还能提供包括 **容错处理、滞后节点（straggler node）处理** 等这些专有系统
缺乏的特性。这里会重点讨论如下 **四类模型**：
+ **迭代算法**：这是目前专有系统实现的非常普遍的一种应用场景，比如迭代算法可以用于 **图处理和机器学
习**。RDD能够很好地实现这些模型，包括Pregel、HaLoop和GraphLab等模型。
+ **关系型查询**：对于MapReduce来说非常重要的需求就是 **运行SQL查询**，包括长期运行、数小时的批
处理作业和交互式的查询。然而对于MapReduce而言，对比并行数据库进行交互式查询，有其内在的缺点，比如由
于 **其容错的模型而导致速度很慢。利用RDD模型，可以通过其实现许多通用的数据库引擎特性，从而获得非常好
的性能**。
+ **MapReduce批处理：RDD提供的接口是MapReduce的超集**，所以RDD可以有效地运行利用MapReduce实现
的应用程序，另外 **RDD还适合更加抽象的基于DAG的应用程序**，比如DryadLINO。
+ **流式处理**：目前的流式系统也只提供了 **有限的容错处理，需要消耗系统非常大的拷贝代价或者非常长的
容错时间**。特别是在目前的系统中，基本都是 **基于连续计算的模型，常驻的有状态的操作会处理到达的每一条
记录。为了恢复失败的节点，它们需要为每一个操作复制两份操作，或者是将上游的数据进行代价非常大的操作重放**。
利用RDD实现一种新的模型————**离散数据流（D-Stream）**，可以克服上面的这些问题。**D-Stream将流式计
算当作一系列的短小而确定的批处理操作，而不是常驻的有状态的操作，将两个离散流之间的状态保存在RDD中。离散
流模型能够允许通过RDD的继承关系图（lineage）进行并行性的恢复而不需要进行数据拷贝**。

### Spark子系统
如果按照目前流行的大数据处理场景来划分，可以将大数据处理分为如下三种情况。
+ **复杂的批量数据处理**（batch data processing），通常的时间跨度为数十分钟到数小时。
+ **基于历史数据的交互式查询**（interactive query），通常的时间跨度为数十秒到数分钟。
+ **基于实时数据流的数据处理**（streaming data processing），通常的时间跨度为数百毫秒到数秒。

由于RDD具有丰富的表达能力，所以伯克利 **在Spark Core的基础之上衍生出了能够同时处理上述三种情形的统一
大数据处理平台**，如下图：









































dd
















































ddd
