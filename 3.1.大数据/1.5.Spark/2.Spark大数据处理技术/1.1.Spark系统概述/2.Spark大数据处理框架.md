Spark大数据处理框架
=================================================================================
针对上一节中MapReduce及各种专有系统中出现的不足，伯克利大学推出了全新的统一大数据处理框架Spark，
创新性地提出了 **RDD概念（一种新的抽象的弹性数据集）**，在某种程度上Spark是对MapReduce模型的一
种扩展。要在MapReduce上实现其不擅长的计算工作（比如 **迭代式、交互式和流式**），看上去是一件非常
困难的事情，**其实主要的原因是MapReduce缺乏一种特性，即在并行计算的各个阶段进行有效的数据共享，这
种共享就是RDD的本质**。利用这种有效的数据共享和类似MapReduce的操作接口，上述的各种专有类型计算都
能够有效地表达，而且能够获得与专有系统同等的性能。

特别值得一提的是，从前对于 **集群处理的容错方式**，比如 **MapReduce** 和Dryad，是将计算构建成为
一个 **有向无环图的任务集**。而这 **只能允许它们有效地重新计算部分DAG**。**在单独的计算之间（在迭
代的计算步骤之间），除了复制文件，这些模型没有提供其他的存储抽象，这就显著地增加了在网络之间复制文件的
代价。RDD能够适应当前大部分的数据并行算法和编程模型**。










































ddd
