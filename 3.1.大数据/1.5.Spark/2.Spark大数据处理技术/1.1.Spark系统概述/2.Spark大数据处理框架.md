Spark大数据处理框架
=================================================================================
针对上一节中MapReduce及各种专有系统中出现的不足，伯克利大学推出了全新的统一大数据处理框架Spark，
创新性地提出了 **RDD概念（一种新的抽象的弹性数据集）**，在某种程度上Spark是对MapReduce模型的一
种扩展。要在MapReduce上实现其不擅长的计算工作（比如 **迭代式、交互式和流式**），看上去是一件非常
困难的事情，**其实主要的原因是MapReduce缺乏一种特性，即在并行计算的各个阶段进行有效的数据共享，这
种共享就是RDD的本质**。利用这种有效的数据共享和类似MapReduce的操作接口，上述的各种专有类型计算都
能够有效地表达，而且能够获得与专有系统同等的性能。

特别值得一提的是，从前对于 **集群处理的容错方式**，比如 **MapReduce** 和Dryad，是将计算构建成为
一个 **有向无环图的任务集**。而这 **只能允许它们有效地重新计算部分DAG**。**在单独的计算之间（在迭
代的计算步骤之间），除了复制文件，这些模型没有提供其他的存储抽象，这就显著地增加了在网络之间复制文件的
代价。RDD能够适应当前大部分的数据并行算法和编程模型**。

### RDD表达能力
可以使用RDD实现很多现有的集群编程模型以及一些以前的模型不支持的新应用。在这些模型中，**RDD能够取得和专
有系统同样的性能**，还能提供包括 **容错处理、滞后节点（straggler node）处理** 等这些专有系统缺乏的特
性。这里会重点讨论如下 **四类模型**：
+ **迭代算法**：这是目前专有系统实现的非常普遍的一种应用场景，比如迭代算法可以用于 **图处理和机器学习**。
RDD能够很好地实现这些模型，包括Pregel、HaLoop和GraphLab等模型。
+ **关系型查询**：对于MapReduce来说非常重要的需求就是 **运行SQL查询**，包括长期运行、数小时的批处理作
业和交互式的查询。然而对于MapReduce而言，对比并行数据库进行交互式查询，有其内在的缺点，比如由于 **其容错
的模型而导致速度很慢。利用RDD模型，可以通过其实现许多通用的数据库引擎特性，从而获得非常好的性能**。














































ddd
