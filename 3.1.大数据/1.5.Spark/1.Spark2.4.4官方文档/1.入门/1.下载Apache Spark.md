下载Apache Spark
===================================================================================
## 1. 下载Apache Spark™
1. 选择一个Spark版本：
    + 3.0.0  预览版（2019年11月6日）
    + 2.4.4 （2019年8月30日）
2. 选择包装类型：
    + 为Apache Hadoop2.7预先构建
    + 为Apache Hadoop2.6预先构建
    + 由用户提供的Apache Hadoop预告构建
    + 使用Scala 2.12和用户提供的Apache Hadoop预告构建
    + 源代码
3. 下载Spark（注：下载对应的Spark）
4. 使用2.4.4 签名，校验和和和项目版本KEYS验证此版本。

请注意，Spark是用Scala 2.11预先构建的，而版本2.4.2是用Scala 2.12预先构建的。

## 2. 最新预览版
顾名思义，预览版是用于预览即将发布的功能的版本。与nightly 软件包不同，预览版本已由项目管理委员会审
核，以满足Apache Software Foundation发行策略的法律要求。预览版并非功能正常，即它们可能且很可能会包
含严重的错误或文档错误。最新的预览版本是 **Spark 3.0.0-preview**，已于2019年11月6日发布。您可以在
上面选择并下载它。

## 3. 与Spark链接
Spark工件存放在 **Maven Central** 中。您可以使用以下坐标添加Maven依赖项：
```ini 
groupId: org.apache.spark
artifactId: spark-core_2.11
version: 2.4.4
```

## 4. 使用PyPi安装
PySpark现在在 **pypi** 中可用。要安装只需运行`pip install pyspark`。

## 5. 稳定版本的发行说明
+ Spark 2.4.4（2019年8月30日）
