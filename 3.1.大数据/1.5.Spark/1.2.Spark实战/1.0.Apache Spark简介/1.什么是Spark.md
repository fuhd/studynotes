什么是Spark
===================================================================================
**Apache Spark通常被定义为一个快速、通用的分布式计算平台**。Spark能高效地使用内存，执行同样的工作，
它比Hadoop's MapReduce快10 ~ 100倍。最重要的是，**Spark的创造者设法将用户从正在处理的计算机集群中
抽象出来，向用户呈现一组基于集合的API。使用Spark的集合感觉好像在使用本地Scala、Java和Python的集合，
但是Spark的集合实际上引用分布在许多节点的数据。这些集合的操作被转换为复杂的并行程序**。

Spark最初是在 **Berkeley** 的AMPLab由Matei Zaharia设计的，他与他的导师Ion Stoica以及Reynold Xin、
Patrick Wendell、Andy Konwinski和Ali Ghodsi共同创立了Databricks。**虽然Spark是开源的，但是Databricks
是Apache Spark的主要力量，它贡献了Spark的75%以上的代码**。它还提供了Databricks Cloud——一种基于
Apache Spark的大数据分析的商业产品。

