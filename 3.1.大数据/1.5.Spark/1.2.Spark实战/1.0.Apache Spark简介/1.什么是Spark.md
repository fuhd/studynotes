什么是Spark
===================================================================================
**Apache Spark通常被定义为一个快速、通用的分布式计算平台**。Spark能高效地使用内存，执行同样的工作，
它比Hadoop's MapReduce快10 ~ 100倍。最重要的是，**Spark的创造者设法将用户从正在处理的计算机集群中
抽象出来，向用户呈现一组基于集合的API。使用Spark的集合感觉好像在使用本地Scala、Java和Python的集合，
但是Spark的集合实际上引用分布在许多节点的数据。这些集合的操作被转换为复杂的并行程序**。

Spark最初是在 **Berkeley** 的AMPLab由Matei Zaharia设计的，他与他的导师Ion Stoica以及Reynold Xin、
Patrick Wendell、Andy Konwinski和Ali Ghodsi共同创立了Databricks。**虽然Spark是开源的，但是Databricks
是Apache Spark的主要力量，它贡献了Spark的75%以上的代码**。它还提供了Databricks Cloud——一种基于
Apache Spark的大数据分析的商业产品。

通过支持 **Python、Java、Scala和R语言，Spark可以向广泛的用户开放：传统上倾向于Python和R的科学界、
仍然广泛使用的Java社区以及使用越来越流行的Scala的人们**。Spark在Java虚拟机（JVM）上提供了函数式编
程。

最后，**Spark将批处理、实时流计算功能、类似SQL的结构化数据处理、图算法和机器学习等类似MapReduce
的功能整合在一个框架中。这使它成为大多数大数据处理需求的一站式服务平台**。

**Spark并没有考虑到在线事务处理（OLTP）**，它更适合在线分析处理（OLAP）：批处理作业和数据挖掘等
方面起作有。

## Spark革命





