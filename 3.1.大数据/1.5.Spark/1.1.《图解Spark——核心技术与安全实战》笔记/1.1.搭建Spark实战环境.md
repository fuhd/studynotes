搭建Spark实战环境
================================================================================
## 1.基础环境搭建
在这里我们将 **搭建Spark集群运行模式**（当然在该集群中将 **安装Hadoop**，实战中需要它提供HDFS
文件存储和YARN资源调度管理）。该集群 **不少于3个节点**，如果没有物理节点，可以利用虚拟机软件，
如VMware、VirtualBox等工具进行搭建。

集群网络环境配置：

| 序号 | IP地址 | 机器名 | 运行进程 | 核数/内存 | 用户名 |
|:----|:-------|:------|:-------|:---------|:------|
| 1 | 192.168.1.10 | master | NN/SNN/DN/RM/Master/Worker | 1核/3G | spark |
| 2 | 192.168.1.11 | slave1 | DN/NM/Worker | 1核/2G | spark |
| 1 | 192.168.1.10 | slave2 | DN/NM/Worker | 1核/2G | spark |

目录：
+ `/app`
+ `/app/soft`
+ `/app/compile`
+ `/app/spark`
+ `/home/spark`

说明：
+ 所有节点均安装CentOS6.5版本64位系统，**防火墙/SElinux均禁用**，所有节点上均创建一个 **spark
用户**，该用户工作目录是`/home/spark`，**上传文件存放在`/home/spark/work`目录** 中。
+ 所有节点上均创建一个 **目录`/app`用于存放程序，并且拥有者是spark用户**。在`/app`目录下创建 
`soft`、`compile`和`spark`三个子目录：**`/app/soft`子目录用于存放支持Spark运行相关基础软件，
`/app/compile`子目录用于编译时存放源代码及编译结果，而`/app/spark`子目录则存放Spark和Hadoop
等**。

### 1.1.搭建集群样板机

#### 1.1.1.设置系统环境

+ **设置机器名**

为了方便Hadoop和Spark设置配置的方便，将设置每个服务器的机器名。以root用户登录，在命令行终端使
用：
```shell
vi /etc/sysconfig/network
```
打开配置文件，根据前面的规划设置服务器机器名：
```ini
NETWORKING=yes
HOSTNAME=master
```

+ **设置IP地址**

以root帐号登录，在如下配置文件中设置网卡信息：
```shell
vi /etc/sysconfig/network-scripts/ifcfg-eth0
```
主要参数信息如下：
```ini
#对应第一张网卡 
DEVICE=eth0
#以太网类型
TYPE=Ethernet
#是否启动时运行
ONBOOT=yes
#使用静态IP,而不是DHCP分配IP
BOOTPROTO=static 
#风格连接名称
NAME="System etho"
#eth0的MAC地址，根据实际情况而定，对应配置
HWADDR=00:50:56:94:04:3C
#指定本地IP地址
IPADDR=192.168.1.10
#指定子网掩码
NETMASK=255.255.255.0
#指定网关
GATEWAY=192.168.1.1
#DNS地址，配置后同步到/etc/resolv.conf文件
```
通过以上方法设置网络配置以后，使用命令：
```shell
service network restart
```
重启网络或重启机器，并 **使用ifconfig命令查看设置IP地址是否生效**。

+ **设置Host映射文件**

以root用户，在命令行使用命令：
```shell
vi /etc/hosts
```
编辑文件添加如下内容：
```shell
192.168.1.10 master
192.168.1.11 slave1
192.168.1.12 slave2
```
设置完毕后，可以使用：
```shell
ping master
```
直接检查master服务器是否连通以及检测服务器是响应速度。

+ **关闭防火墙和SELinux**

关闭防火墙和SELinux的原因在于Hadoop和Spark运行过程需要通过端口进行通信，而这些安全设施会进行
阻拦。另外，在使用SSH无密码访问时也存在同样的情况。

关闭iptables时，以root帐号使用如下命令：
```shell
service iptables status
```
查看 **iptables状态**，如果显式“iptables: Firewall is not running”表示iptables已经关闭；
如果显示iptables设置信息，则需要使用如下命令 **关闭iptables**：
```shell
chkconfig iptables off
```
同样，使用root用户编辑：
```shell
vi /etc/selinux/config
```
在该配置文件中设置 **SELINUX=disable，关闭防火墙和SELinux的设置需要重启机器才能够生效**。

#### 1.1.2.配置运行环境

+ **更新OpenSSL**

由于 **CentOS系统自带的OpenSSL存在Bug（6.5版本？）**，如果不更新OpenSSL，在部署过程会出现无
法通过SSH连接节点，使用如下命令 **更新SSH**：
```shell
yum update openssl
```

+ **修改OpenSSL配置**

在集群环境中需要 **进行SSH进行免密码登录，需要修改OpenSSL配置文件**，确认使用RSA算法（非对称加
密算法）进行公钥加密并确认生成私钥存放文件等。配置过程需以root用户身份，执行命令：
```shell
vi /etc/ssh/sshd_config
```
编辑：
```ini
#设置是否使用RSA算法进行加密 
RSAAuthentication yes
#设置是否使用口令验证
PubkeyAuthentication yes
#生成密钥存放的文件
AuthorizedKeysFile .ssh/authorized_keys
```
保存配置后，需要通过：
```shell
service sshd restart
```
重启SSH服务，以便生效配置。

+ **增加Spark组和用户**
在节点中创建spark组和spark用户，创建命令如下：
```shell
#-g指定组ID号
groupadd -g 1000 spark
#-u指定用户ID号
useradd -u 2000 -g spark spark
passwd spark
```
在后面执行中 **需要使用到sudo命令，应把spark用户加入到sudoers文件中**，先修改该配置文件的权限：
```shell
# u:用户,g:用户组，o:其他，a:所有
# + 表示增加权限，如u+x, u+r, u+w, g+w, g+r, o+r， a+r等
# - 表示取消权限，如u-x, u-r, u-w, g-w, g-r, o-r， a-r等
# = 表示赋予给定权限，并取消其他所有权限（如果有的话，如原来u是rwx，设置u=r，u就剩r）
chmod u+w /etc/sudoers
```
再使用`vi /etc/sudoers`命令打开该文件，找到这行：`root ALL=(ALL)ALL`，在它下面添加：
```ini
spark ALL=(ALL) ALL
```
根据前面集群安装配置规划，**创建运行环境所需要的目录结构，创建spark用户临时上传文件目录**，设置
这些目录所属组和用户均为：spark：
```shell
mkdir /app
chown -R spark:spark /app
mkdir /app/soft
mkdir /app/compile
mkdir /app/spark 
mkdir -p /home/spark/work
chown -R spark:spark /home/spark/work 
```

+ **安装和配置JDK**
如：jdk-7u55-linux-x64.tar.gz。下载完毕后，把该安装包保存在spark用户临时上传文件目录
`/home/spark/work`中，解压该文件并移动到`/app/soft`中。
```shell
cd /home/spark/work
tar -xzvf dk-7u55-linux-x64.tar.gz
mv jdk1.7.0_55 /app/soft
```
以root用户执行：`vi /etc/profile`命令，增加如下内容：
```shell
export JAVA_HOME=/app/soft/jdk1.7.0_55
export PATH=$PATH:$JAVA_HOME/bin:$JAVA_HOME/jre/bin
```
配置完毕后，需要编译该配置文件或重新登录以生效该配置：
```shell
source /etc/profile
```

+ **安装和配置Scala**
Spark2.0版本使用的Scala2.11.X，需要在Scala官方站点下载Scala2.11.6及以上版本的安装包，如：
scala-2.11.8.tgz。把该安装包保存在spark用户临时上传目录`/home/spark/work`中，解压该文件并
移动到`/app/soft`中：
```shell
cd /home/spark/work
tar -xzvf scala-2.11.8.tgz
mv scala-2.11.8 /app/soft
```
配置`/etc/profile`文件，在该配置文件中加入相关Scala环境变量：
```shell
export SCALA_HOME=/app/soft/scala-2.11.8
export PATH=$PATH:$SCALA_HOME/bin
```
执行如下命令使配置生效：
```shell
source /etc/profile
```

### 1.2.配置集群环境 
**通过前面的步骤搭建完毕集群样板机，以该机为模板复制出两份**，按照前面规划集群配置，需要设置机器
名和IP地址，同时设置SSH无密码登录。

#### 1.2.1.复制样板机
可以通过复制样板机目录或使用VMware克隆功能进行样板机的复制，复制出两份副本，分别对应 **slave1和
slave2节点**。

#### 1.2.2.设置机器名和IP地址
略

#### 1.2.3.配置SSH无密码登录

+ **生成私角和公钥**
使用spark用户登录，在3个节点中使用如下命令生成私钥和公钥，为简单起见，在生成私钥和公钥过程中提示
问题均按回车键。
```shell
ssh-keygen -t rsa
```
命令执行完毕后，可以在`/home/spark/.ssh`目录中看见两个文件：**id_rsa和id_rsa.pub**，其中以
pub结尾的是公钥，**把公钥命名为authorized_keys_master.pub**，使用的命令如下：
```shell
cd /home/spark/.ssh
mv id_rsa.pub authorized_keys_master.pub
```
同样地把其他两个节点的公钥命名为：**authorized_keys_slave1.pub和authorized_keys_slave2.pub**。
```shell
mv id_rsa.pub authorized_keys_slave1.pub
mv id_rsa.pub authorized_keys_slave2.pub
```

+ **合并公钥信息**
把两个从节点（slave1和slave2）的公钥使用 **scp命令** 传送到master节点的`/home/spark/.ssh`
目录中。
```shell
scp authorized_keys_slave1.pub spark@master:/home/spark/.ssh
scp authorized_keys_slave2.pub spark@master:/home/spark/.ssh
```
使用 **cat命令** 把3个节点的公钥信息保存到a **uthorized_key文件** 中：
```shell
cat authorized_keys_master.pub >> authorized_keys
cat authorized_keys_slave1.pub >> authorized_keys
cat authorized_keys_slave2.pub >> authorized_keys
```
使用scp命令把密码文件分发到slave1和slave2节点，如下：
```shell
scp authorized_keys spark@slave1:/home/spark/.ssh
scp authorized_keys spark@slave2:/home/spark/.ssh
```
传输完毕后，**需要在3台节点中设置authorized_keys读写权限**：
```shell
cd /home/spark/.ssh
chmod 400 authorized_keys #设置400就可以？不应该是600??
```

+ **验证免密码登录**
在各个节点中使用ssh命令，验证它们之间是否可以免密码登录：
```shell
ssh master
ssh slave1
ssh slave2
```

## 2.编译Spark源代码


## 3.搭建Spark运行集群


## 4.搭建Spark实战开发环境 


