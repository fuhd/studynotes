搭建Spark实战环境
================================================================================
## 1.基础环境搭建
在这里我们将 **搭建Spark集群运行模式**（当然在该集群中将 **安装Hadoop**，实战中需要它提供HDFS
文件存储和YARN资源调度管理）。该集群 **不少于3个节点**，如果没有物理节点，可以利用虚拟机软件，
如VMware、VirtualBox等工具进行搭建。

集群网络环境配置：

| 序号 | IP地址 | 机器名 | 运行进程 | 核数/内存 | 用户名 |
|:----|:-------|:------|:-------|:---------|:------|
| 1 | 192.168.1.10 | master | NN/SNN/DN/RM/Master/Worker | 1核/3G | spark |
| 2 | 192.168.1.11 | slave1 | DN/NM/Worker | 1核/2G | spark |
| 1 | 192.168.1.10 | slave2 | DN/NM/Worker | 1核/2G | spark |

目录：
+ `/app`
+ `/app/soft`
+ `/app/compile`
+ `/app/spark`
+ `/home/spark`

说明：
+ 所有节点均安装CentOS6.5版本64位系统，**防火墙/SElinux均禁用**，所有节点上均创建一个 **spark
用户**，该用户工作目录是`/home/spark`，**上传文件存放在`/home/spark/work`目录** 中。
+ 所有节点上均创建一个 **目录`/app`用于存放程序，并且拥有者是spark用户**。在`/app`目录下创建 
`soft`、`compile`和`spark`三个子目录：**`/app/soft`子目录用于存放支持Spark运行相关基础软件，
`/app/compile`子目录用于编译时存放源代码及编译结果，而`/app/spark`子目录则存放Spark和Hadoop
等**。







## 2.编译Spark源代码


## 3.搭建Spark运行集群


## 4.搭建Spark实战开发环境 


