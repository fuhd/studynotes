Spark编程模型
================================================================================
## 1.RDD简介
Spark编程模型是 **弹性分布式数据集（Resilient Distributed Dataset, RDD）**，它是MapReduce
模型的扩展和延伸，但它 **解决了MapReduce的缺陷：在并行计算阶段高效地进行数据共享**。

相比以前集群容错处理模型，如：MapReduce、Dryad，它们 **将计算转换为一个有向无环图（DAG）的任
务集合**。这使在这些模型中能够 **有效地恢复DAG中故障和慢节点执行的任务**，但是这些模型中除了文
件系统外没有提供其他的存储方式，这就导致了在 **网络上进行频繁的数据复制而造成I/O压力**。由于RDD
提供一种基于粗粒度变换（如：map、filter和join等）的接口，该接口会将相同的操作应用到多个数据集上，
**这就使得它们可以记录创建数据集的“血缘”（Lineage），而不需要存储真正的数据**，从而达到高效的容
错性。**当某个RDD分区丢失的时候，RDD记录有足够的信息来重新计算，而且只需要计算该分区，这样丢失的
数据可以很快地恢复，不需要昂贵的复制代价**。

