Spark编程模型
================================================================================
## 1.RDD简介
Spark编程模型是 **弹性分布式数据集（Resilient Distributed Dataset, RDD）**，它是MapReduce
模型的扩展和延伸，但它 **解决了MapReduce的缺陷：在并行计算阶段高效地进行数据共享**。

相比以前集群容错处理模型，如：MapReduce、Dryad，它们 **将计算转换为一个有向无环图（DAG）的任
务集合**。这使在这些模型中能够 **有效地恢复DAG中故障和慢节点执行的任务**，但是这些模型中除了文
件系统外没有提供其他的存储方式，这就导致了在 **网络上进行频繁的数据复制而造成I/O压力**。由于RDD
提供一种基于粗粒度变换（如：map、filter和join等）的接口，该接口会将相同的操作应用到多个数据集上，
**这就使得它们可以记录创建数据集的“血缘”（Lineage），而不需要存储真正的数据**，从而达到高效的容
错性。**当某个RDD分区丢失的时候，RDD记录有足够的信息来重新计算，而且只需要计算该分区，这样丢失的
数据可以很快地恢复，不需要昂贵的复制代价**。

**基于RDD机制实现了多类模型计算**，包括多个现有的集群编程模型。这些模型包括以下几方面的内容：
1. **迭代计算**： 目前最常见的工作方式。比如应用于图处理、数据优化以及机器学习中的算法。
2. **交互式SQL查询**： Spark的RDD不仅拥有很多常见数据库引擎的特性，达到可观的性能，而且Spark
SQL中提供完善的容错机制，能够在短查询和长查询中很好地处理故障和慢节点。
3. **MapReduceRDD**：通过提供MapReduce的 **超集**，能够高效地执行MapReduce程序。
4. **流式数据处理**：当前的模型没有解决在大规模集群中频繁出现 **慢节点的问题**，同时对故障解决
办法有限，需要大量的复制或浪费很长的恢复时间。**Spark提出了离散数据流（D-Stream）** 来解决这样
的问题。**`D-Streams`把流式计算的执行当作一系列短而确定的批量计算的序列，并将状态保存在RDD中**。
D-Streams根据相关RDD的依赖关系图进行并行化恢复，可以达到快速故障恢复，避免了数据复制。

## 2.RDD的类型
Spark编程中开发者需要 **编写一个驱动程序来连接到工作进程（Worker）。驱动程序定义一个或多个RDD
以及相关行动操作，驱动程序同时记录RDD的继承关系，即“血缘”**。而工作进程（Worker）是一直运行的进
程，它将经过一系列操作后的RDD分区数据保存在内存中。

Spark中的操作大致可以分为四类操作：
+ **创建操作**：用于RDD创建工作。RDD创建只有两种方法，一种是来 **自于内存集合和外部存储系统**，
另一种是 **通过转换操作生成的RDD**。
+ **转换操作**：将RDD通过一定的操作变换成新的RDD，比如：HadoopRDD可以使用map操作变换为MappedRDD，
**RDD的转换操作是惰性操作，它只是定义了一个新的RDDs，并没有立即执行**。
+ **控制操作：进行RDD持久化，可以让RDD按不同的存储策略保存在磁盘或者内存中**，比如cache接口默
认将RDD缓存在内存中。
+ **行动操作**：能够触发Spark运行的操作，例如，对RDD进行collect就是行动操作。Spark中行动操作 
分为两类，**一类的操作结果变成Scala集合或者变量，另一类将RDD保存到外部文件系统或者数据库中**。

## 3.RDD的实现

### 3.1.作业调度
当对RDD执行转换操作时，**调度器会根据RDD的”血缘“来构建由若干调度阶段组成的有向无环图（DAG），
每个调度阶段包含尽可能多的连续窄依赖转换**。调度器按照有向无环图顺序进行计算，并最终得到目标RDD。

调度器向各节点分配任务采用 **延时调度机制** 并根据数据存储位置来确定。**若一个任务需要处理的某个
分区刚好存储在某个节点的内存中，则该任务会分配给该节点；如果在内存中不包含该分区，调度器会找到包
含该RDD的较佳位置，并把任务分配给所在节点**。

**对应宽依赖的操作**，在Spark **将中间结果物化到父分区的节点上**，这和MapReduce物化map的输出
类似，**可以简化数据的故障恢复过程**。如下图：

![Spark如何计算作业调度阶段](img/1.jpg)

实线圆角方框（**线框**）标识的是 **RDD**，**阴影背景的矩形是分区**，若已存在于内存中，则用黑色
背景标识。RDD上一个行动操作的执行将会以 **宽依赖** 为分区来构建各个调度阶段，对各调度阶段内部的
**窄依赖** 则前后连接构建流水线。本例中，Stage1的输出已经在内存中，所以直接执行Stage2，然后执
行Stage3。

对于执行失败的任务，只要它对应调度阶段父类信息仍然可用，该任务会分散到其他节点重新执行。如果某些
调度阶段不可用，则重新提交相应的任务，并以并行方式计算丢失的分区。在作业中如果某个任务执行缓慢（即
Straggler），系统则会在某他节点上执行该任务的副本。该方法与MapReduce推测执行做法类似，并取最快
得到的结果作为最终的结果。

### 3.2.内存管理
**Spark提供了3种持久化RDD的存储策略：未序列化Java对象存在内存中、序列化的数据存于内存中以及存
储在磁盘中**。第一个选项的性能是最优的，因为可以直接访问在Java虚拟机内存里的RDD对象；在空间有限
的情况下，第二种方式可以让用户采用比Java对象更有效的内存组织方式，但代价是降低了性能；第三种策略
使用于RDD太大的情形，每次重新计算该RDD会带来额外的资源开销（如I/O等）。

**对于内存使用LRU回收算法来进行管理，当计算得到一个新RDD分区，但没有足够空间来存储时，系统会从最
近最少使用的RDD回收其一个分区的空间。除非该RDD是新分区对应的RDD，这种情况下Spark会将旧的分区继
续保留在内存中，防止同一个RDD的分区被循环调入/调出**。这点很关键，因为大部分的操作会在一个RDD的
所有分区上进行，那么很有可能已经存在内存中的分区将再次被使用。

### 3.3.检查点支持
**虽然“血缘”可以用于错误后RDD的恢复，但是对于很长的“血缘“的RDD来说，这样的恢复耗时比较长，因此
需要通过检查点操作（`Checkpoint`）保存到外部存储中**。

**通常情况下，对于包含依赖的长”血缘“的RDD设置检查点操作是非常有用的**。在这种情况下，集群中某个
节点出现故障时，会使得从各个父RDD计算出的数据丢失，造成需要重新计算。相反，对于那些窄依赖的RDD，
对其进行检查点操作就不是必须，**在这种情况下如果一个节点发生故障，RDD在该节点中丢失的分区数据可
以通过并行的方式从其他节点中重新计算出来，计算成本只是复制RDD的很小部分**。

**Spark提供为RDD设置检查点操作的API，可以让用户自行决定需要为哪些数据设置检查点操作**。另外由
于RDD的只读特性，使得不需要关心数据一致性问题。

## 4.编程接口



