Spark及其生态圈概述
================================================================================
## 1.什么是Spark
Spark是加州大学伯克利分样AMP实验室开发的通用大数据处理框架。围绕着Spark推出了Spark SQL、Spark
Streaming、MLlib、GraphX和SparkR等组件，这些组件逐渐形成大数据处理一站式解决平台。

Scala是使用 **Scala语言** 实现。

Spark的中文意思是：电光火石。官方提供 的数据表明：如果数据由磁盘读取，速度是Hadoop MapReduce
的10倍以上；如果数据从内存中读取，速度可以高达100多倍。**Spark相对于Hadoop有如此之快的计算速度
有数据本地性、调度优化和传输优化等原因，其中最主要是基于内存计算和引入DAG执行引擎**。
1. **Spark默认情况下迭代过程的数据保存到内存中，后续的远行作业利用这些结果进行计算，而Hadoop每
次计算结果都直接存储到磁盘中，在随后的计算中需要从磁盘中读取上次计算的结果。由于从内存读取数据时
间比磁盘读取时间低两个数量级，这就造成了Hadoop的运行速度较慢，这种情况在迭代计算中尤为明显**。
2. **由于较复杂的数据计算任务需要多个步骤才能实现，且步骤之间具有依赖性。对于这些步骤之间，Hadoop
需要借助Oozie等工具进行处理。而Spark在执行任务前，可以将这些步骤根据依赖关系形成DAG图（有向无环
图），任务执行可以按图索骥，不需要人工干预，从而优化了计算路径，大大减少了I/O读取操作**。

## 2.Spark与MapReduce比较 
1. **Spark把中间数据放在内存中，迭代运算效率高**。MapReduce中的计算结果是保存在磁盘上，这亲势
必会影响整体的运行速度，而Spark支持DAG图的分布式并行计算的编程框架，减少了迭代过程中数据的落地，
提高了处理效率。
2. **Spark的容错性高**。Spark引进了 **弹性分布式数据集**（Resilient Distributed Dataset，
**RDD**）的概念，它是分布在一组节点中的只读对象集合，这些集合是弹性的，**如果数据集一部分丢失，
则可以根据“血缘”对它们进行重建**。另外，**在RDD计算时可以通过 CheckPoint来实现容错，而CheckPoint
有两种方式，即CheckPoint Data和Logging The Updates**，用户可以控制采用哪种方式来实现容错。
3. **Spark更加通用**。不像Hadoop只提供了Map和Reduce两种操作，Spark提供的数据集操作类型有很
多种，大致分为 **转换操作** 和 **行动操作** 两大类。转换操作包括Map、Filter、FlatMap、Sample、
GroupByKey、ReduceByKey、Union、Join、Cogroup、MapValues、Sort和PartionBy等多种操作类
型，行支操作包括Collect、Reduce、Lookou和Save等操作类型。另外，各个处理节点之间的通信模型不再
像Hadoop只有Shuffle一种模式，用户可以命名、物化、控制中间结果的存储、分区等。

## 3.Spark的演进路线图
+ 2009年由Berkeley's AMBLab开始编写最初的源代码
+ 2010年开放源代码
+ 2013年年中Spark主要成员创立Databricks公司
+ 2014年5月底Spark1.0.0发布
+ **2016年7月Spark2.0.0正式版本发布**

**Apache Mahout放弃MapReduce，使用Spark作为后续算子的计算平台**。

## 4.Spark生态系统
Spark生态系统以 **Spark Core** 为核心，能够读取传统文件（如文本文件）、HDFS、Amazon S3、
Alluxio、和NoSQL等数据源，利用 **Standalone、YARN和Mesos** 等资源调度管理，完成应用程序分
析与处理。

### 4.1.Spark Core
Spark Core是整个生态系统的核心组件，是一个分布式大数据处理框架。
+ Spark Core提供了 **多种运行模式**，不仅可以使用自身运行模式处理任务，如 **本地模式、
Standalone**，而且可以使用第三方资源调度框架来处理任务，如：**YARN、MESOS** 等。
+ Spark Core提供了 **有向无环图（DAG）的分布式并行计算框架**，并提供 **内存机制** 来支持多次
迭代的数据计算或者数据共享，**大大减少迭代计算之间读取数据的开销**，这对于需要进行多次迭代的数据
挖掘和分析，性能有极大提升。另外，**在任务处理过程中移动计算而非移动数据**，RDD Partition可以
就近读取分布式文件系统中的数据块到各个节点内存中进行计算。
+ 在Spark中引入了 **RDD的抽象，它是分布在一组节点中的只读对象集合**。这些集合是弹性的，如果数
据集一部分丢失，则可以根据“血缘”对它们进行重建，保证了数据的高容错性。

### 4.2.Spark Streaming
**Spark Streaming是一个对实时数据流进行高吞吐、高容错的流式处理系统**，可以对多种数据源（如：
Kafka、Flume和ZeroMQ等）进行类似Map、Reduce和Join等复杂操作，并将结果保存到外部文件系统、数
据库或应用到实时仪表盘。

对于传统流处理中一次处理一条记录的方式而言，Spark Streaming使用的是将流数据离散化处理，通过 该
处理方式能够进行秒级以下的数据批处理。**在Spark Streaming处理过程中，Receiver并行接收数据，
并将数据缓存到Spark工作节点的内存中。经过延迟优化后，Spark引擎对短任务（几十毫秒）能够进行批处
理**，并将结果输出至其他系统中。

Spark Streaming具有如下特性：
+ **动态负载均衡**：Spark Streaming将数据划分为 **小批量**，通过这种方式可以实现对资源更细粒
度的分配。Spark Streaming中，作业任务将会动态地平衡分配给各个节点。
+ **快速故障恢复机制**：在Spark中，计算将分成许多小的任务，保证能在任何节点运行后能够正确进行合
并。因此，**在某节点出现的故障的情况，这个节点的任务将均匀地分散到集群中的其他节点进行计算**。
+ **批处理、流处理与交互式分析的一体化**：Spark Streaming是将流式计算分解成一系列短小的批处理
作业，也就是把Spark Streaming的输入数据按照批处理大小（如几秒）分成一段一段的离散数据流，每一
段数据都转换成Spark中的RDD，然后将Spark Streaming中对DStream流处理操作变为针对Spark中对RDD
的批处理操作。

### 4.3.Spark SQL
**Spark SQL的前身是Shark，Shark即Hive on Spark，本质上是通过Hive的HQL进行解析，把HQL翻译
成Spark上对应的RDD操作，然后通过Hive的Metadata获取数据库里的表信息**，实际为HDFS上的数据和文
件，最后由Shark获取并放到Spark上运算。


                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    










