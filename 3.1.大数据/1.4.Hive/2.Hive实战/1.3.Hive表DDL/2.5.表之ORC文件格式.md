表之ORC文件格式
===================================================================================
**ORC文件格式用于减少要从磁盘读取的数据量。Hive中有很多新的性能优化都仅采用ORC文件**，因此
对于大多数用例来说，**推荐将原始数据转换成ORC文件**。第9章将详细解释这种格式。本节讨论一下将基
于文本文件的外部表转换成ORC文件应该遵循的步骤：

让我们将transactions表转换成ORC格式并且查看其属性：
```sql
CREATE TABLE transactions_orc STORED AS ORC TBLPROPERTIES('ORC.COMPRESS'='SNAPPY')
	AS SELECT * FROM transactions;
```
查看建表语句：
```sql
SHOW CREATE TABLE transactions_orc;
```
打印：
```
createtab_stmt                                                                                            |
----------------------------------------------------------------------------------------------------------|
CREATE TABLE `transactions_orc`(                                                                          |
  `transdate` date,                                                                                       |
  `transid` int,                                                                                          |
  `custid` int,                                                                                           |
  `fname` string,                                                                                         |
  `lname` string,                                                                                         |
  `item` string,                                                                                          |
  `qty` int,                                                                                              |
  `price` float,                                                                                          |
  `store` string)                                                                                         |
ROW FORMAT SERDE                                                                                          |
  'org.apache.hadoop.hive.ql.io.orc.OrcSerde'                                                             |
STORED AS INPUTFORMAT                                                                                     |
  'org.apache.hadoop.hive.ql.io.orc.OrcInputFormat'                                                       |
OUTPUTFORMAT                                                                                              |
  'org.apache.hadoop.hive.ql.io.orc.OrcOutputFormat'                                                      |
LOCATION                                                                                                  |
  'hdfs://sandbox-hdp.hortonworks.com:8020/warehouse/tablespace/managed/hive/shopping.db/transactions_orc'|
TBLPROPERTIES (                                                                                           |
  'ORC.COMPRESS'='SNAPPY',                                                                                |
  'bucketing_version'='2',                                                                                |
  'transactional'='true',                                                                                 |
  'transactional_properties'='default',                                                                   |
  'transient_lastDdlTime'='1580390956')                                                                   |
```

## 合并表的文件
**在Hadoop中处理小文件是永恒的挑战，因为它们需要耗费大量的NameNode元数据记录。将小文件组合成较大的
文件经常是一种推荐做法**。如果你有一个ORC文件格式的表，其中含有很多小文件，**你可以将它们合并以充分
利用 NameNode中的HDFS元数据空间。可以使用`ALTER TABLE`命令来实现**。HDFS的NameNode进程维护了HDFS
上所有文件的元数据。

**对于以RCFile或ORCFile格式存储的Hive表**，可以做如下操作:
```sql
ALTER TABLE transactions_orc CONCATENATE;
```
**该命令会将多个数据文件合并成较大的文件**。

**避免小文件的最佳方式是，在数据进入Hadoop之前，将它们合并成集群数据块数倍大小的文件，通常为好几GB或
者更大**。在数据进入Hadoop之后，有很多种方式可以将它们整合到一起，**但是由于Hadoop在处理大量小文件
方面并不在行，因此这样合并的过程速度会比较慢**。




