安装Kafka
===================================================================================
## 1.准备

### 1.1.选择操作系统
主要在Linux上使用。

### 1.2.安装Java
略

### 1.3.安装Zookeeper
**Kafka使用Zookeeper保存集群的元数据信息和消费者信息**。Kafka发行版自带了Zookeeper，可以直接从
脚本启动。

#### 1.3.1.单机服务
安装目录为`/usr/local/zookeeper`，数据目录为`/var/lib/zookeeper`。
```shell
tar -zxf zookeeper-3.4.6.tar.gz
mv zookeeper-3.4.6 /usr/local/zookeeper 
mkdir -p /var/lib/zookeeper
cat > /usr/local/zookeeper/conf/zoo.cfg << EOF
```
```
> tickTime=2000
> dataDir=/var/lib/zookeeper
> clientPort=2181
> EOF
```
```shell
export JAVA_HOME=/usr/java/jdk1.8.0_51
/usr/local/zookeeper/bin/zkServer.sh start 
```
现在可以连到 **Zookeeper端口** 上，通过发送命令 **srvr** 来验证Zookeeper是否安装正确。
```shell
telnet localhost 2181
```
```
Trying ::1...
Connected to localhost.
Escape character is '^]'.

srvr 
Zookeeper version: 3.4.6-1569965, built on 02/20/2014 09:09 GMT
Latency min/avg/max: 0/0/0
Received: 1
Sent: 0
......
```

#### 1.3.2.Zookeeper群组
**Zookeeper集群被称为群组**。Zookeeper使用的是一致性协议，所以建议每个群组里应该包含 **奇数** 个
节点（**比如3个、5个等，不过也不建议一个群组包含超过7个节点**。因为Zookeeper使用了一致性协议，节
点过多会降低整个群组的性能）。

群主需要有一些 **公共配置**，并且每个服务器还要在 **数据目录** 中创建一个 **myid文件**，用于指明自己
的ID。示例：
```ini
tickTime=2000
dataDir=/var/lib/zookeeper 
clientPort=2181
initLimit=20
syncLimit=5
server.1=zoo1.example.com:2888:3888
server.2=zoo2.example.com:2888:3888
server.3=zoo3.example.com:2888:3888
```
在这个配置中，`initLimit`表示用于在从节点与主节点之间建立初始化连接的时间上限，`syncLimit`表示允许
从节点与主节点处于不同步状态的时间上限。这两个值都是`tichTime`的倍数。服务器地址遵循：
`server.X=hostname:peerPort:leaderPort`格式，说明如下：
+ **X：服务器ID，它必须是一个整数，不过不一定要从0开始，也不要求是连续的**；X与myid文件中的值一致。
+ **hostname：服务器的机器名或IP地址**；
+ **peerPort：用于节点间通信的TCP端口**；
+ **leaderPort：用于首领选举的TCP端口**；

客户端只需要通过`clientPort`就能连接到群组，而群组节点的通信则需要同时用到这 **3个端口（`peerPort`、
`leaderPort`、`clientPort`）**。

## 2.安装Kafka Broker
下面的示例将Kafka安装在`/usr/local/kafka`目录下，使用之前配置好的Zookeeper，并把消息日志保存在
`/tmp/kafka-logs`目录下。
```shell
tar -zxf kafka_2.11-0.9.0.1.tgz
mv kafka_2.11-0.9.0.1 /usr/local/kafka
mkdir /tmp/kafka-logs
export JAVA_HOME=/usr/java/jdk1.8.0_51
/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
```
**验证是否安装正确**，比如创建一个测试主题，发布一些消息，然后读取它们。

**创建并验证主题**：
```shell
#创建
/usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
#展示
/usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test 
```

**往测试主题上发布消息**：
```shell
/usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test

Test Message 1
Test Message 2
^D
```

**从测试主题上读取消息**：
```shell
/usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning 

Test Message 1
Test Message 2
^C
```

## 3.broker配置
Kafka发行包里 **自带的配置样本** 可以用来安装 **单机服务**，但并不能满足大多数安装场景的需求。

### 3.1.常规配置
有一些配置选项，在单机安装时可以直接使用默认值，部署到其他环境时要小心，**其中的大部分需要修改后才
能使用**。

#### broker.id
broker的标识符，这个值在整个Kafka集群里 **必须是唯一** 的，这个值可以任意选定。

#### port
用 **配置样本** 来启动Kafka，它会监听 **9092** 端口，可以是任意端口。要注意，如果使用1024以下的端口，
需要使用root权限启动Kafka，不建议这样做。

#### zookeeper.connect 
用于 **保存broker元数据的Zookeeper地址** 是通过`zookeeper.connect`来指定的。该配置参数是用 **冒号** 
分隔的一组`hostname:port/path`列表。
+ **hostname** 是Zookeeper服务器的机器名或IP地址；
+ **port** 是Zookeeper的客户端连接端口；
+ **`/path`** 是可选的Zookeeper路径，作为Kafka集群的chroot环境。如果不指定，默认使用根路径。

**如果指定的chroot路径不存在，broker会在启动的时候创建它**。

#### log.dirs
**Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过`log.dirs`指定的**。它是一组用 **逗号** 
分隔的 **本地文件系统路径**。broker会根据“**最少使用**”原则，把同一个分区的日志片段保存到同一个路
径下。要注意，**broker会往拥有最少数目分区的路径新增分区**，而不是往拥有最小磁盘空间的路径新增分区。

#### num.recovery.threads.per.data.dir
对于如下3种情况，**Kafka会使用可配置的线程池来处理日志片段**：
+ 服务器正常启动，用于打开每个分区的日志片段；
+ 服务器崩溃后重启，用于检查和截短每个分区的日志片段；
+ 服务器正常关闭，用于关闭日志片段；

默认情况下，每个日志目录只使用一个线程。完全可以 **设置大量的线程** 来达到 **并行** 操作的目的。设置
此参数时需要注意， **所配置的数字对应的是`log.dirs`指定的单个日志目录**。也就是说，如果
`num.recovery.threads.per.data.dir`设置为 **8**，并且`log.dirs`指定了3个路径，那么总共需要 **24** 个
线程。

#### auto.create.topics.enable
**默认情况下，Kafka会在如下几种情形下自动创建主题**：
+ 当一个生产者开始往主题写入消息时；
+ 当一个消费者开始从主题读取消息时；
+ 当任意一个客户端向主题发送元数据请求时；

**如果显式地创建主题**，不管是手动创建还是通过其他配置系统来创建，都可以把：
**`auto.create.topics.enable`设置为false**。

### 3.2.主题的默认配置
Kafka为新创建的主题提供了很多默认配置参数。可以通过 **管理工具** 为 **每个主题** 单独配置一部分参数。

#### 3.2.1.num.partitions
`num.partitions`参数指定了 **新创建的主题将包含多少个分区**。如果启用了 **主题自动创建功能**（默认
启用的），主题分区的个数就是该参数指定的值。该参数默认值是1。注意，**可以增加主题分区的个数，不能减
少分区的个数。要让一个主题的分区个数少于`num.partitions`指定的值，需要手动创建该主题**。

根据经验，把 **分区的大小** 限制在 **25GB以内** 可以得到比较理想的效果。

### 3.2.2.log.retention.ms
Kafka通常根据时间来决定数据可以被保留多久。**默认使用`log.retention.hours`参数来配置时间**，默认
值为 **168小时**，也就是 **一周**。还有两个参数`log.retention.minutes`和`log.retention.ms`。这3个参
数作用是一样的，都决定消息多久以后会被删除，**推荐使用`log.retention.ms`**。如果指定了 **多个参数**，
Kafka会优先使用 **具有最小值** 的那个参数。

根据时间保留数据是通过检查磁盘上 **日志片段** 文件的 **最后修改时间** 来实现的。最后修改时间就是日志
片段的 **关闭时间**。如果使用管理工具在服务器间 **移动分区**，最后修改时间就 **不准确了**。

### 3.2.3.log.retention.bytes
另一种方式是通过保留的 **消息字节数** 来判断消息是否过期，**作用在每一个分区上**。也就是说，如果有一
个包含 **8个分区** 的主题，并且`log.retention.bytes`被设为 **1GB**，那么这个主题最多可以保留 **8GB**
的数据。

如果同时指定了`log.retention.bytes`和`log.retention.ms`（或者另一个时间参数），**只要任意一个条件得
到满足，消息就会被删除**。

### 3.2.4.log.segment.bytes
当消息到达broker时，它们被 **追加** 到分区的 **当前日志片段** 上。当日志片段大小达到`log.segment.bytes`
指定的上限（**默认是1GB**）时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被
关闭，就开始 **等待过期**。这个参数值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。

如果一个主题每天只接收100MB的消息，而`log.segment.bytes`使用默认设置，那么需要10天时间才能填满一
个日志片段。因为 **在日志片段被关闭之前消息是不会过期的**，所以如果`log.retention.ms`被设为6048000000
（也就是1周），那么日志片段 **最多需要17天** 才会过期。

**使用时间戳获取偏移量**：日志片段的大小会影响使用时间戳获取偏移量。**日志片段越小，结果越准确**。

### 3.2.5.log.segment.ms
另一个可以 **控制日志片段关闭时间** 的参数是`log.segment.ms`，它指定了多长时间之后日志片段会被关闭。
`log.segment.bytes`和`log.segment.ms`，就看哪个条件先得到满足。**默认情况下，`log.segment.ms`没
有设定值**，所以只根据大小来关闭日志片段。

**基于时间的日志片段对磁盘性能的影响**：如果多个分区的 **日志片段永远不能达到大小的上限**，因为
broker在 **启动之后** 就开始计算日志片段的 **过期时间**，对于那些数据量小的分区来说，日志片段的 **关
闭操作总是同时发生**。

### 3.2.6.message.max.bytes
该参数用来 **限制单个消息的大小**。默认值是1000000，也就是 **1MB**。如果生产者尝试发送的消息 **超
过** 这个大小，不仅消息不会被接收，**还会收到broker返回的错误信息**。该参数指的是 **压缩后** 的消息
大小。**该值对性能有显著影响**。

消费者客户端设置的 **`fetch.message.max.bytes`** 必须与服务器端 **设置的消息大小进行协调**。如果
这个值比`message.max.bytes`小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。在为
集群里的broker配置 **`replica.fetch.max.bytes`** 参数时，也遵循同样的原则。

##  4.硬件的选择

### 4.1.内存
运行Kafka的 **JVM不需要太大的内存**，剩余的系统内存可以用作 **页面缓存**，或者用来缓存正在使用的日
志片段。这也就是为什么 **不建议把Kafka同其他重要的应用程序部署在一起** 的原因，它们需要共享页面缓存，
最终会降低Kafka消费者的性能。

### 4.2.CPU
与磁盘和内存相比，**Kafka对计算处理能力的要求相对较低**。不过一定程度上还是会影响整体的性能。客户
端为了优化网络和磁盘空间，会对消息进行 **压缩**。服务器需要对消息进行批量 **解压**，设置偏移量，然后
重新进行批量 **压缩**，再保存到磁盘上。

### 4.3.磁盘吞吐量
磁盘写入速度越快，生成消息的延迟就越低。

## 5.Kafka集群
使用集群最大的好处是可以 **跨服务器进行负载均衡**，再则就是可以使用 **复制功能** 来 **避免因单点故障** 
造成的数据丢失。

### 5.1.需要多少个broker
首先，**需要多少磁盘空间** 来保留数据，以及单个broker有多少空间可用。如果集群需要保留10GB的数据，
每个broker可以存储2TB，那么至少需要5个broker。如果启用了 **数据复制**，那么 **至少还需要一倍的空间**，
不过这要取决于配置的 **复制系数** 是多少。如果启用了数据复制，那么这个集群至少需要10个broker。

第二个要考虑的因素是集群的 **处理请求的能力**。这通常与网络接口处理客户端流量的能力有关。

### 5.2.broker配置
要把一个broker加入到集群里，只需要修改 **两个配置参数**。首先，所有broker都必须配置 **相同** 的
`zookeeper.connect`。每个broker都必须为`broker.id`参数设置 **唯一** 的值。在运行集群时，还可以配置
其他一些参数，特别是那些用于 **控制数据复制的参数**。

### 5.3.操作系统调优

#### 虚拟内存
一般来说，**Linux的虚拟内存** 会根据系统的工作负荷进行自动调整。我们可以对 **交换分区** 的处理方式和
**内存脏页** 进行调整，从而让Kafka更好地处理工作负载。

对于大多数依赖 **吞吐量** 的应用程序来说，**要尽量避免内存交换**。**内存页和磁盘之间的交换** 对Kafka
各方面的性能都有重在影响。**Kafka大量地使用系统页面缓存**，如果虚拟内存被交换到磁盘，说明已经没有
多余内存可以分配给页面缓存了。

**内存交换不是必需的**，不过它确实能够在系统发生灾难性错误时提供一些帮助。基于上述原因，**建议把
`vm.swappiness`参数的值设置得小一点，比如1**。

为什么不把`vm.swappiness`设置为0：**0** 意味着“**在任何情况下都不要发生交换**”，**1** 意味着
“**除非发生内存溢出，否则不要进行内存交换**”。

**脏页** 会被冲刷到磁盘上，调整内核对脏页的处理方式可以让我们从中获益。**Kafka依赖I/O性能为生产者提
供快速的响应**。这就是为什么日志片段一般要保存在 **快速磁盘** 上。在后台刷新进程将脏页写入磁盘之前，
可以减少脏页的数量，这个可以通过将 **`vm.dirty_background_ratio`设为小于10的值来实现。该值指的是系
统内存的百分比，大部分情况下设为5就可以了**。它不应该被设为0，因为那样会促使内核频繁地刷新页面，从
而降低内核为底层设备的磁盘写入提供缓冲能力。

为了给这些参数设置合适的值，最好是在Kafka集群运行期间 **检查脏页的数量**，不管是在生产环境还是模拟
环境。可以在 **`/proc/vmstat`文件里查看当前脏页数量**。
```shell
cat /proc/vmstat | egrep "dirty|writeback"

nr_dirty 3875
nr_writeback 29
nr_writeback_temp 0
```

#### 磁盘
除了选择合适的磁盘硬件设备和使用RAID外，**文件系统是影响性能的另一个重要因素**。不过对于本地文件系
统来说，EXT4和XFS最为常见。近来，**XFS成为很多Linux发行版默认的文件系统**，因为它只需要做少量调优
就可以承担大部分的工作负荷，**比EXT4具有更好的表现。XFS为Kafka提供了更好的性能，除了由文件系统提
供的自动调优之外，无需额外的调优**。

不管使用哪一种文件系统来存储日志片段，最好要对挂载点的`noatime`参数进行合理的设置。文件元数据包含
3个时间戳：创建时间（ctime）、最后修改时间（mtime）以及最后访问时间（atime）。**默认情况下，每次
文件被读取后都会更新atime，这会导致大量的磁盘写操作，而且atime属性的用处不大。Kafka用不到该属性，
所以完全可以把它禁用掉**。为挂载点 **设置noatime参数** 可以防止更新atime，但不会影响ctime和mtime。

#### 网络
默认情况下，系统内核没有针对快速的大流量网络传输进行优化，所以对于应用程序来说，一般需要 **对Linux
系统的网络栈进行调优，以实现对大流量的支持**。首先可以对分配给socket读写缓冲区的内存大小作出调整，
这样可以显著提升网络的传输性能。socket **读写缓冲区** 对应的参数分别是 **`net.core.wmem_default`和
`net.core.rmem_default`**，合理的值是131072（也就是128KB）。**读写缓冲区最大值** 对应的参数分别
是 **`net.core.wmem_max`和`net.core.rmem_max`**，合理的值是2097152（也就是 **2MB**）。根据
Kafka服务器接收流量的实际情况，**可能需要设置更高的最大值，为网络连接提供更大的缓冲空间**。

还有其他一些有用的网络参数。例如，把 **`net.ipv4.tcp_window_scaling`设为1，启用 TCP时间窗扩展，可
以提升客户端传输数据的效率，传输的数据可以在服务器端进行缓冲。把`net.ipv4.tcp_max_syn_backlog`设
为比默认值1024更大的值，可以接受更多的并发连接。把`net.core.netdev_max_backlog`设置为比默认值1000
更大的值，有助于应对网络流量的爆发，特别是在使用千兆网络的情况下，允许更多的数据包排队等待内核处理**。

## 6.生产环境的注意事项

### 6.1.垃圾回收选项
java7为我们带来了 **G1垃圾回收器**，G1会自动根据工作负载情况进行自我调节，而且它的 **停顿时间是恒定
的**。它可以轻松地处理大块的堆内存，把堆内存分为若干小块的区域，**每次停顿并不会对整个堆空间进行回
收**。

G1的两个调整参数：
+ **MaxGCPauseMillis**：该参数指定 **每次垃圾回收默认的停顿时间**。该值不是固定的，G1可以根据需要
使用更长的时间。**它的默认值是200ms**。
+ **InitiatingHeapOccupancyPercent**：该参数指定了 **在G1启动新一轮垃圾回收之前可以使用的堆内存百
分比，默认值是45**。在堆内存的使用率达到45%之前，G1不会启动垃圾回收。**这个百分比包括新生代和老年
代内存**。

**Kafka对堆内存的使用率非常高，容易产生垃圾对象，所以可以把这些值设得小一些**。如果一台服务器有
**64GB内存**，并且使用 **5GB** 堆内存来运行Kafka，那么可以参考以下的配置：**`MaxGCPauseMillis`**
可以设为 **20ms**，**`InitiatingHeapOccupancyPercent`**可以设为 **35**，这样可以让垃圾回收比默
认的要早一些启动。

**Kafka的启动脚本并没有启用G1回收器**，而是使用了Parallel New和CMS垃圾回收器。不过它可以通过 **环
境变量** 来修改：
```shell
export JAVA_HOME=/usr/java/jdk1.8.0.51
export KAFKA_JVM_PERFORMANCE_OPTS="-server -XX:+UseG1GC -XX:MaxGCPauseMillis=20 -XX:InitiatingHeapOccupancyPercent=35 
        -XX:+DisableExplicitGC -Djava.awt.headless=true"

/usr/local/kafka/bin/kafka-server-start.sh -daemon /usr/local/kafka/config/server.properties
```

### 6.2.数据中心布局
最好把集群的broker安装在 **不同的机架** 上，至少 **不要让它们共享可能出现单点故障的基础设施**，比如
电源和网络。也就是说，部署服务器需要 **至少两个电源连接和两个网络交换器**。除了这些以外，最好还要把
broker安放在不同的机架上。因为随着时间的推移，机架也需要进行维护，而这会导致机器离线。

### 6.3.共离Zookeeper
Kafka使用Zookeeper来保存 **broker、主题** 和 **分区** 的元数据信息。对于一个包含多个节点的Zookeeper
群组来说，**Kafka集群的这些流量并不算多**，那些写操作只是用于 **构造消费者群组或集群本身**。实际上，
在很多部署环境里，会让 **多个Kafka集群共享一个Zookeeper群组（每个集群使用一个chroot路径）**。

在 **Kafka0.9.0.0版本之前**，除了broker之外，**消费者也会使用Zookeeper来保存一些信息**，比如消费
者群组的信息、主题信息、消费分区的偏移量。**到了Kafka0.9.0.0版本**，Kafka引入了一个 **新的消费者接
口，允许broker直接维护这些信息**。

**消费者** 可以选择将 **偏移量** 提交到 **Zookeeper**或 **Kafka**。**如果消费者将偏移量提交到
Zookeeper**，那么在每个提交时间点上，消费者将会为每个消费者的分区往Zookeeper写入一次偏移量。合理
的提交时间是1分钟，因为这刚好是消费者群组的某个消费者发生失效时能够读取到重复消息的时间。**这些提交
对于Zookeeper来说流量不算小，特别是当集群里有多个消费者的时候**。如果Zookeeper群组无法处理太大的
流量，就有必要使用长一点的提交时间间隔。不过不管怎样，**还是建议使用最新版本的Kafka，让消费者把偏
移量提交到Kafka服务器上，消除对Zookeeper的依赖**。

虽然多个Kafka集群可以共享一个Zookeeper群组，但如果有可能的话，**不建议把Zookeeper共享给其他应用程
序。Kafka对Zookeeper的延迟和超时比较敏感**，与Zookeeper群组之间的一个通信异常就可能导致Kafka服务
器出现无法预测的行为。这很容易让多个broker同时离线。







