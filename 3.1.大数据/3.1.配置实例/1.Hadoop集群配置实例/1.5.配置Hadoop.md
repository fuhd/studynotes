配置Hadoop
=================================================================================
```
说明：
我们计划配置Hadoop集群（三个节点：server1（172.16.177.168）,server2（172.16.177.166）,server3（172.16.177.167））
，下面以其中一台（server2作为master节点）作为演示。

server2：namenode，资源管理器，datanode1
server1：辅助namenode，datanode2
server3: namenode（备），datanode3
```

### 1.在hadoop-env.sh文件中设置HADOOP_CONF_DIR属性
**该属性表示hadoop配置文件所在目录**，在 **$HADOOP_HOME/etc/hadoop/hadoop-env.sh** 文件中，
包含该属性：
```shell
export HADOOP_CONF_DIR=${HADOOP_CONF_DIR:-"/etc/hadoop"}
```
也就是说，**默认情况下，Hadoop会在/etc/hadoop目录下查找配置文件**。
```
说明：
应该不是$HADOOP_HOME/etc/hadoop目录，要不然不会有前面第一个斜杠（/etc/hadoop）。是不是？？是不是？？？？
```
**第一步，为了避免歧义，明确指定绝对路径**：
```shell
export HADOOP_CONF_DIR=/etc/hadoop
```

**第二步，在/etc目录下创建hadoop目录**：
```shell
$ sudo mkdir -p /etc/hadoop
```

**第三步，让/etc/hadoop目录属于hadoop用户与hadoop用户组**：
```shell
$ sudo chown -R hadoop:hadoop /etc/hadoop/
```

### 2.在hadoop-env.sh文件中设置JAVA_HOME属性
**该属性表示Hadoop要使用的Java的安装目录**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_151
```

### 3.在hadoop-env.sh文件中设置HADOOP_HEAPSIZE属性
**该属性表示各个Hadoop守护进程的堆内存大小，默认为1000MB**，暂时可以不用配置。

### 4.在hadoop-env.sh文件中设置HADOOP_NAMENODE_OPTS属性
**该属性表示namenode使用的JVM相关选项**。目前，**HADOOP_NAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```
**namenode需要的内存要大些**，这里暂时设置为2000MB，加入配置 **-Xmx2000m**：
```shell
export HADOOP_NAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```

### 5.在hadoop-env.sh文件中设置HADOOP_SECONDARYNAMENODE_OPTS属性
**该属性表示辅助namenode使用的JVM相关选项**。目前，**HADOOP_SECONDARYNAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```
namenode的堆内存设置为2000MB了，那么 **辅助namenode也要改成一样大小**：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```

### 6.在hadoop-env.sh文件中设置HADOOP_LOG_DIR属性
**该属性表示Hadoop的日志文件存放目录**，默认是$HADOOP_HOME/logs目录。

**第一步配置Hadoop日志目录**：
```shell
export HADOOP_LOG_DIR=/var/log/hadoop
```

**第二步创建/var/log/hadoop目录**：
```shell
$ sudo mkdir -p /var/log/hadoop
```

**第三步让/var/log/hadoop目录属于hadoop用户与hadoop用户组**：
```shell
$ sudo chown -R hadoop:hadoop /var/log/hadoop/
```

### 7.在$HADOOP_CONF_DIR下新增配置core-site.xml
```shell
$ sudo touch core-site.xml
$ sudo chown hadoop:hadoop core-site.xml
```
编辑：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://172.16.177.166/</value>
    </property>
</configuration>
```

### 8.在$HADOOP_CONF_DIR下新增配置hdfs-site.xml
```shell
$ sudo touch hdfs-site.xml
$ sudo chown hadoop:hadoop hdfs-site.xml
```
下面，创建namenode的元数据目录、辅助namenode的检查点数据目录和datanode的数据块存储目录：
```shell
# namenode的元数据目录，最好配置三个。在两个磁盘上各创建一个，在NFS上再创建一个。
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/name
$ sudo mkdir -p hadoop_data/dfs/data
$ sudo mkdir -p hadoop_data/dfs/namesecondary
$ chown -R hadoop:hadoop hadoop_data/
```
编辑hdfs-site.xml：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop_data/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_data/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/opt/hadoop_data/dfs/namesecondary</vlaue>
    </property>
</configuration>
```

### 9.在$HADOOP_CONF_DIR下新增配置yarn-site.xml
```shell
$ sudo touch yarn-site.xml
$ sudo chown hadoop:hadoop yarn-site.xml
```
下面，**创建资源管理器存储临时文件的目录**：
```shell
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/yarn_local_dir
$ chown -R hadoop:hadoop hadoop_data/dfs/yarn_local_dir
```
编辑yarn-site.xml文件：
```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>172.16.177.166</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/opt/hadoop_data/dfs/yarn_local_dir</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce.shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>6144</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
    </property>
</configuration>
```

### 10.配置slaves文件
**这个slaves文件只需要在namenode节点上配置就可以了**，不用复制到其它节点。修改 **$HADOOP_HOME/etc/hadoop/slaves** 文件：
```shell
172.16.177.168
172.16.177.167
# 在166上，namenode与datanode同时存在
172.16.177.166
```
