配置Hadoop
=================================================================================
```
说明：
该测试计划配置Hadoop集群，一共三个节点：
    node-master（172.16.177.166）
    node-slave01（172.16.177.167）
    node-slave02（172.16.177.168）

node-master：namenode，资源管理器，datanode3
node-slave01：辅助namenode，datanode1
node-slave02: namenode（备），datanode2
```

### 1.在hadoop-env.sh文件中设置JAVA_HOME属性
**该属性表示Hadoop要使用的Java的安装目录**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_151
```

### 2.在hadoop-env.sh文件中设置HADOOP_HEAPSIZE属性
**该属性表示各个Hadoop守护进程的堆内存大小，默认为1000MB**，暂时可以不用配置。

### 3.在hadoop-env.sh文件中设置HADOOP_NAMENODE_OPTS属性
**该属性表示namenode使用的JVM相关选项**。目前，**HADOOP_NAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```
**namenode需要的内存要大些**，这里暂时设置为1000MB，加入配置 **-Xmx1000m**：
```shell
export HADOOP_NAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```

### 4.在hadoop-env.sh文件中设置HADOOP_SECONDARYNAMENODE_OPTS属性
**该属性表示辅助namenode使用的JVM相关选项**。目前，**HADOOP_SECONDARYNAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```
namenode的堆内存设置为1000MB了，那么 **辅助namenode也要改成一样大小**：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```

### 5.在hadoop-env.sh文件中设置HADOOP_LOG_DIR属性
**该属性表示Hadoop的日志文件存放目录**，默认是$HADOOP_HOME/logs目录。

**第一步配置Hadoop日志目录**：
```shell
export HADOOP_LOG_DIR=/var/log/hadoop
```

**第二步创建/var/log/hadoop目录**：
```shell
$ sudo mkdir -p /var/log/hadoop
```

**第三步让/var/log/hadoop目录属于hadoop用户与hadoop用户组**：
```shell
$ sudo chown -R hadoop:hadoop /var/log/hadoop/
```

### 6.在$HADOOP_CONF_DIR下新增配置core-site.xml
```shell
$ sudo touch core-site.xml
$ sudo chown hadoop:hadoop core-site.xml
```
编辑：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node-master/</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/hadoop_data</value>
    </property>
</configuration>
```
创建目录并授权（**目录授予hadoop用户与hadoop用户组**）：
```shell
# namenode的元数据目录，最好配置三个。在两个磁盘上各创建一个，在NFS上再创建一个。
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/name
$ sudo mkdir -p hadoop_data/dfs/data
$ sudo mkdir -p hadoop_data/dfs/namesecondary
$ chown -R hadoop:hadoop hadoop_data/
```
**注意：上面的三个目录（dfs/name、dfs/data、dfs/namesecondary）是默认目录，就这么配置**。


### 7.在$HADOOP_CONF_DIR下新增配置hdfs-site.xml
```shell
$ sudo touch hdfs-site.xml
$ sudo chown hadoop:hadoop hdfs-site.xml
```
下面，**创建namenode的元数据目录、辅助namenode的检查点数据目录和datanode的数据块存储目录（上面已经配置过了）**。

编辑hdfs-site.xml：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <!--
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop_data/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_data/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/opt/hadoop_data/dfs/namesecondary</vlaue>
    </property>
    -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
-->
```
**注意：上面注释中的三个配置，默认已经通过${hadoop.tmp.dir}配置了，只要三个子目录固定是：dfs/name、
dfs/data、dfs/namesecondary就可以了，不要用画蛇添足**！

### 8.在$HADOOP_CONF_DIR下新增配置yarn-site.xml
```shell
$ sudo touch yarn-site.xml
$ sudo chown hadoop:hadoop yarn-site.xml
```
下面，**创建资源管理器存储临时文件的目录**：
```shell
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/yarn_local_dir
$ chown -R hadoop:hadoop hadoop_data/dfs/yarn_local_dir
```
编辑yarn-site.xml文件：
```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>node-master</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/opt/hadoop_data/dfs/yarn_local_dir</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce.shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>6144</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
    </property>
</configuration>
```

### 9.配置slaves文件
**这个slaves文件只需要在namenode节点上配置就可以了**，不用复制到其它节点。复制 **$HADOOP_HOME/etc/hadoop/slaves**
文件到 **$HADOOP_CONF_DIR** 目录，并修改它：
```shell
node-slave01
node-slave02
node-master
```

### 10. 把secondarynamenode配置到其它节点（与namenode不在同一个节点）
按原计划把辅助namenode（secondarynamenode）配置到node-slave01上。

**修改hdfs-site.xml**：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <!--
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/opt/hadoop_data/dfs/name</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_data/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/opt/hadoop_data/dfs/namesecondary</vlaue>
    </property>
    -->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>node-master:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node-slave01:50090</value>
    </property>
</configuration>
```

**在三个节点上，把上面所有相关配置配一遍！**
