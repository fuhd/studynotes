配置Hadoop
=================================================================================
```
说明：
该测试计划配置Hadoop集群，一共三个节点：
    node-master（172.16.177.166）
    node-slave01（172.16.177.167）
    node-slave02（172.16.177.168）

node-master：NameNode，DataNode，ResourceManager，NodeManager
node-slave01：DataNode，NodeManager，SecondaryNameNode
node-slave02: DataNode，NodeManager
```

### 1.在$HADOOP_CONF_DIR/hadoop-env.sh文件中设置JAVA_HOME属性
**该属性表示Hadoop要使用的Java的安装目录**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_151
```

### 2.在$HADOOP_CONF_DIR/hadoop-env.sh文件中设置HADOOP_HEAPSIZE属性
**该属性表示各个Hadoop守护进程的堆内存大小，默认为1000MB**，暂时可以不用配置。

### 3.在$HADOOP_CONF_DIR/hadoop-env.sh文件中设置HADOOP_NAMENODE_OPTS属性
**该属性表示namenode使用的JVM相关选项**。目前，**HADOOP_NAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_NAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```
**namenode需要的内存要大些**，这里暂时设置为1000MB，加入配置 **-Xmx1000m**：
```shell
export HADOOP_NAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_NAMENODE_OPTS"
```

### 4.在$HADOOP_CONF_DIR/hadoop-env.sh文件中设置HADOOP_SECONDARYNAMENODE_OPTS属性
**该属性表示辅助namenode使用的JVM相关选项**。目前，**HADOOP_SECONDARYNAMENODE_OPTS** 的默认配置是：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```
namenode的堆内存设置为1000MB了，那么 **辅助namenode也要改成一样大小**：
```shell
export HADOOP_SECONDARYNAMENODE_OPTS="-Xmx1000m -Dhadoop.security.logger=${HADOOP_SECURITY_LOGGER:-INFO,RFAS} -Dhdfs.audit.logger=${HDFS_AUDIT_LOGGER:-INFO,NullAppender} $HADOOP_SECONDARYNAMENODE_OPTS"
```

### 5.在$HADOOP_CONF_DIR/hadoop-env.sh文件中设置HADOOP_LOG_DIR属性
**该属性表示Hadoop的日志文件存放目录**，默认是$HADOOP_HOME/logs目录。

**第一步配置Hadoop日志目录**：
```shell
export HADOOP_LOG_DIR=/var/log/hadoop
```

**第二步创建/var/log/hadoop目录**：
```shell
$ sudo mkdir -p /var/log/hadoop
```

**第三步让/var/log/hadoop目录属于hadoop用户与hadoop用户组**：
```shell
$ sudo chown -R hadoop:hadoop /var/log/hadoop/
```

### 6.编辑$HADOOP_CONF_DIR目录下的core-site.xml配置文件
添加如下配置：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://node-master/</value>
    </property>
    <property>
        <name>hadoop.tmp.dir</name>
        <value>/opt/hadoop_data</value>
    </property>
</configuration>
```
创建目录并授权（**目录授予hadoop用户与hadoop用户组**）：
```shell
# namenode的元数据目录，最好配置三个。在两个磁盘上各创建一个，在NFS上再创建一个，这里我们就创建两个本地磁盘的目录吧。
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/name
$ sudo mkdir -p hadoop_data/dfs/name_bak
$ sudo mkdir -p hadoop_data/dfs/data
$ sudo mkdir -p hadoop_data/dfs/namesecondary
$ chown -R hadoop:hadoop hadoop_data/
```
**注意：上面的三个目录（dfs/name、dfs/data、dfs/namesecondary）是默认目录名，这里也不改变它们了，
另新增一个dfs/name_bak**。


### 7.编辑$HADOOP_CONF_DIR目录下的hdfs-site.xml配置文件
下面，**创建namenode的元数据目录、辅助namenode的检查点数据目录和datanode的数据块存储目录（上面已经创建过了）**。
编辑hdfs-site.xml：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://${hadoop.tmp.dir}/dfs/name,file://${hadoop.tmp.dir}/dfs/name_bak</value>
    </property>
    <!--
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_data/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/opt/hadoop_data/dfs/namesecondary</vlaue>
    </property>
    -->
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
</configuration>
-->
```
**注意：上面三个配置（dfs.namenode.name.dir、dfs.datanode.data.dir、dfs.namenode.checkpoint.dir），
默认已经通过${hadoop.tmp.dir}配置了，只要三个子目录固定是：dfs/name、dfs/data、dfs/namesecondary就可以的，
但是dfs.namenode.name.dir需要配置备份目录，所以我们就重新配置了一下！**

### 8.编辑$HADOOP_CONF_DIR目录下的yarn-site.xml配置文件
下面，**创建资源管理器存储临时文件的目录**：
```shell
$ cd /opt
$ sudo mkdir -p hadoop_data/dfs/yarn_local_dir
$ chown -R hadoop:hadoop hadoop_data/dfs/yarn_local_dir
```
编辑yarn-site.xml文件：
```xml
<?xml version="1.0"?>
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>node-master</value>
    </property>
    <property>
        <name>yarn.nodemanager.local-dirs</name>
        <value>/opt/hadoop_data/dfs/yarn_local_dir</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <!-- 注意，是下划线，不是点 -->
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.memory-mb</name>
        <value>6144</value>
    </property>
    <property>
        <name>yarn.nodemanager.resource.cpu-vcores</name>
        <value>2</value>
    </property>
</configuration>
```

### 9.编辑$HADOOP_CONF_DIR/slaves配置文件
**这个slaves文件只需要在namenode节点上配置就可以了**，不用复制到其它节点。编辑 **$HADOOP_HOME/etc/hadoop/slaves**
，添加入如配置：
```shell
node-slave01
node-slave02
node-master
```

### 10. 把secondarynamenode配置到其它节点（与namenode不在同一个节点）
按原计划把辅助namenode（secondarynamenode）配置到node-slave01上。

**编辑$HADOOP_CONF_DIR/hdfs-site.xml**：
```xml
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>file://${hadoop.tmp.dir}/dfs/name,file://${hadoop.tmp.dir}/dfs/name_bak</value>
    </property>
    <!--
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/opt/hadoop_data/dfs/data</value>
    </property>
    <property>
        <name>dfs.namenode.checkpoint.dir</name>
        <value>/opt/hadoop_data/dfs/namesecondary</vlaue>
    </property>
    -->
    <property>
        <name>dfs.namenode.http-address</name>
        <value>node-master:50070</value>
    </property>
    <property>
        <name>dfs.namenode.secondary.http-address</name>
        <value>node-slave01:50090</value>
    </property>
</configuration>
```

**在三个节点上，把上面所有相关配置配一遍！**
