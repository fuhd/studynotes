安装Spark
=================================================================================
```
说明：
该测试计划配置Hadoop集群，一共三个节点：
    node-master（172.16.177.166）
    node-slave01（172.16.177.167）
    node-slave02（172.16.177.168）

node-master：NameNode，DataNode，ResourceManager，NodeManager，worker（非进程）
node-slave01：DataNode，NodeManager，worker（非进程）
node-slave02: DataNode，NodeManager，SecondaryNameNode，worker（非进程）
```

### 解压Spark
例如，解压到/opt目录下：
```shell
$ sudo tar xzvf spark-2.2.1-bin-hadoop2.7.tgz -C /opt/
```

### 为Spark目录指定用户与用户组
```shell
$ cd /opt/
$ sudo chown -R hadoop:hadoop spark-2.2.1-bin-hadoop2.7/
```

### 配置Spark环境变量
编辑 **/etc/profile**，添加如下配置项：
```shell
#################### JAVA ###################
export JAVA_HOME=/opt/jdk1.8.0_151
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib
export PATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/bin

#################### SCALA ##################
export SCALA_HOME=/opt/scala-2.11.8
export PATH=$PATH:$SCALA_HOME/bin

#################### HADOOP #################
export HADOOP_HOME=/opt/hadoop-2.9.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

#################### SPARK ##################
export SPARK_HOME=/opt/spark-2.2.1-bin-hadoop2.7
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
```
