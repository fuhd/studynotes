数据采集、汇聚的方法和工具
===================================================================================
从空间维度来看，用户行为可以分为 **线上行为** 和 **线下行为** 两类，采集这两类行为所产生的数据所使用
的方法是不一样的，而且方法也在随着技术的演进不断发展和变化。

## 线上行为采集
在技术上，数据采集主要有 **客户端SDK埋点** 和 **服务端SDK埋点** 等方式。其中 **客户端SDK埋点主要是
通过在终端设备内嵌入埋点功能模块，通过模块提供的能力采集客户端的用户行为，并上传回行为采集服务端**。

### 1.客户端埋点
常见的客户端埋点方式有三种：**全埋点、可视化埋点和代码埋点**。
+ **全埋点**：将终端设备上用户的所有操作和内容都记录并保存下来，只需要对内嵌SDK做一些初始配置就可
以实现收集全部行为的目的。这也经常被称为 **无痕埋点、无埋点** 等。
+ **可视化埋点**：将终端设备上用户的一部分操作，通过服务端配置的方式有选择性地记录并保存。
+ **代码埋点**：根据需求来定制每次的收集内容，需要对相应的终端模块进行升级。

**全埋点适合于终端设计标准化且有统一系统接口的情形**，用户在终端上的操作，通过系统提供的事件捕获机
制，在对象事件发生时调用埋点工具中的指定处理逻辑，对该事件相关的信息进行记录。这种方法的优点是不用
频繁升级，一次性验证并发布后，就可以获取终端的全量行为数据。缺点是数据存储、传输的成本会高一些。

**可视化埋点适合于需要考虑存储和带宽成本的情形，可通过后端配置来降低对象事件行为采集数量，实现机制
和全埋点类似**。其优点是发布后不需要频繁升级，成本比全埋点低，并且能够灵活配置；缺点是当需要对某一
个对象进行分析，但发现其数据没有被采集时，需要重新配置并等数据采集完成再进行后续工作，容易影响业务
进度。

**代码埋点主要适合于终端设计非标准化、事件行为需要通过代码来控制的情形**。其优点是灵活性强，针对复
杂场景可以单独设计方案，对存储、带宽等可以做较多的优化；缺点是成本高，维护难度大，升级周期较长。

### 2.服务端埋点
**服务端埋点是通过在系统服务器端部署相应的数据采集模块，将这部分数据作为行为数据进行处理和分析**。
服务端埋点常见的形态有 **HTTP服务器中的access_log，即所有的Web服务的日志数据**。前面提到的客户端
的三种埋点方式，常见的简化实现方案一般也会配合HTTP服务器中的access_log来落地，但有时为了更好地融合，
会定制一些服务端的SDK，用于捕获服务端系统中无法通过常规访问获取的数据信息，如内部处理耗时、包大小
等数据。

其弊端也很明显，有些用户的行为不一定会发出访问服务端的请求，这种方式就无法采集这部分数据。因此，
**服务端埋点和客户端埋点的结合使用，相互补充，以完成整个用户行为的采集**。

## 线下行为采集
**线下行为数据主要通过一些硬件来采集，如常见的Wi-Fi探针、摄像头、传感器等**。随着设备的升级，各种场
景中对智能设备的应用也越来越多，安防、客户监测、考勤等都开始深入到生活中。常见的主要有Wi-Fi信号采集、
信令数据采集、图像视频采集以及传感器探测等。

## 互联网数据采集
网络爬虫又称为网页蜘蛛，是一种按照既定规则自动抓取互联网信息的程序或者脚本，常用来做网站的自动化测
试和行为模拟。Google、搜狗、百度等提供的互联网信息检索能力，都是基于它们内部自建的网格爬虫，在遵守
相关协议的情况下，不断攫取互联网上的新鲜网页信息，对内容进行处理后提供相应的检索服务。

**当企业的内部信息不足时，可以考虑利用外部互联网的数据进行一些“化学反应”，将外部的数据与内部数据
有效融合，从而让内部数据在应用上有更多价值**。网络爬虫有多种实现方式，目前有较多的开源框架可以使用，
如Apache Nutch2、WebMagic、Scrapy、PHPCrawl等，可以快速根据自己的实际应用场景去构建数据抓取逻
辑。当然，需要遵守相应的协议和法规，同时避免对目标网站造成过大的请求压力。 

## 内部数据汇聚
数据汇聚不同于数据采集，数据采集有一定的数据生产属性，将终端的用户行为信息通过特定的方法记录后，通
过中间系统的流转写入目标存储中。

**从数据组织形式来分，数据主要分成三类**：
+ **结构化数据**：规则、完整，能够通过二维逻辑来表现的数据，严格遵循数据格式与长度规范，常见的有数
据库表、Excel等二维表。
+ **半结构化数据**：数据规则、完整，同样严格遵循数据格式与长度规范，但无法通过二维关系来表现，常见
如JSON、XML等形式表达的复杂结构。
+ **非结构化数据**：数据结构不规则或不完整，不方便用二维逻辑表来表现，需要经过复杂的逻辑处理才能提
取其中的信息内容，如办公文档、图片、图像和音视频等。

**从时效性和应用场景来分，数据汇聚可以分成离线和实时两类**：
+ **离线**：主要用于 **大批量数据的周期性迁移，对时效性要求不高**，一般采用分布式批量数据同步的方式，
通过连接读取数据，读取数据过程中可以有 **全量、增量** 的方式，经过统一处理后写入到目标存储。
+ **实时**：主要面向 **低时延的数据应用场景**，一般通过 **增量日志或通知消息的方式** 实现，如通过读取
数据库的操作日志（ **RedoLog、BinLog**）来实现相应的实时处理，业界常见的 **Canal、MaxWell、
StreamSets、NiFi等框架和组件** 都有较多的实际应用。

在数据建设过程中有 **ETL**（`Extract-Transform-Load`，**抽取－转换－存储**）的操作，**即在数据抽取
过程中进行数据的加工转换，然后加载至存储中。但在大规模数据场景下，一般不建议采用ETL的方式，建议采
用ELT**（`Extract-Load-Transform`，**抽取－存储－转换**）的模式，**即将数据抽取后直接加载到存储中，
再通过大数据和人工智能相关技术对数据进行清洗和处理**。如果采用ETL的模式在传输过程中进行复杂的清洗，
会因为数据体量过大和清洗逻辑的复杂性导致数据传输的效率大大降低。另一方面，ETL模式在清洗过程中只提
取有价值的信息进行存储，而是否有价值是基于当前对数据的认知来判断的，由于数据价值会随着我们对数据的
认识以及数据智能相关技术的发展而不断被挖掘，因此ETL模式很容易出现一些有价值的数据被清洗掉，导致当
某一天需要用这些数据时，又需要重新处理，甚至数据丢失无法找回。相比存储的成本，这种损失可能会更大。

在数据能力建设过程中，很多企业结合自身的场景和最佳实践出 **开源了一些优秀的汇聚工具，如Sqoop、DataX、
Canal等**，适用场景不同，也各有优缺点。

## Canal
**Canel Server模拟MySQL Slave的交互协议，伪装自己为MySQL的Slave向Master发送dump协议，Master收到
请求后开始推送binary log，Canel解析byte流产出解析后的增量数据**。**主要优点** 是流程架构非常清晰，
部署和配置等相对简单，同时可以额外做一些配置管理、开发改造工作。**Canal的主要缺点** 是Server中的
Instance和Client之间是 **一对一的消费，不太适用于多消费和数据分发的场景**。

## Sqoop
**Sqoop是目前市面上相对通用的一种解决方案，是在结构化数据和HDFS之间进行批量数据迁移的工具。整体
框架以Hadoop为核心，底层使用MapReduce程序实现**，MapReduce天生的特性保证了并行化和高容错率，
任务运行在Hadoop集群上，减少了服务器资源的使用情况。**其主要优势是，在特定场景下，数据交换过程会有
很大的性能提升。主要缺点是，处理过程定制程度较高，目前主要通过在命令行中配置参数来调整数据同步操作
行为，在用户的一些自定义逻辑和数据同步链路监控方面比较薄弱**。除此之外，任务运行完全依赖于MapReduce，
功能扩展性方面受到比较明显的约束和限制。

## DataX
**DataX是阿里巴巴开源的一套插件式离线数据交换工具，以实现各种异构数据源之间的高效数据交换为目标而
设计，提供数据交换作业全链路的流量监控**，将作业本身的状态、数据流量、数据速度、执行进度等信息进行
展示，提供脏数据探测功能，支持传输过程中对传输报错（如类型转换错误）进行策略化处理。由于它是基于进
程内读写直连的方式，高并发数据交换场景下对机器内存要求比较高。除此之外，**DataX不支持非结构化数据
的同步，目前支持结构化数据源、半结构化数据源**。











