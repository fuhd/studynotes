数据计算能力的4种类型
===================================================================================
数据开发涉及的产品能力主要包括三个部分，分别是 **离线开发、实时开发和算法开发**。
+ **离线开发** 主要包括离线数据的加工、发布、运维管理，以及数据分析、数据探索、在线查询和即席分析相
关的工作。
+ **实时开发** 主要涉及数据的实时接入和实时管理，简化流数据的加工处理过程。
+ **算法开发** 主要提供简单易用的可视化拖曳方式和Notebook方式来实现数据价值的深度挖掘。

## 数据计算能力的4种类型
数据计算能力根据场景抽象分成四大类：**批处理、流计算、在线查询和即席分析**。

#### 1.批处理
主要用于批量数据的高延时处理场景，如离线数仓的加工、大规模数据的清洗和挖掘等。目前大多是利用MapReduce、
Hive、Spark等计算框架进行处理，其特点是数据昋吐量大、延时高，适合人机交互少的场景。

#### 2.流计算
也叫实时流计算，对于数据的加工处理和应用有较强的实效性要求，常见于监控告警场景，例如实时分析网络事
件，当有异常事件发生时能够及时介入处理。这类场景目前应用较多的计算框架主要有Flink、Spark Streaming
和Storm等。

#### 3.在线查询
主要用于数据结果的在线查询、条件过滤和筛选等，如数据检索、条件过滤等。根据不同的场景也会有多种选择，
如营销场景对响应延时要求高的，一般会采集缓存型的存储计算，如Redis、Tair等；对响应延时要求正常的，可
以选择HBase和MySQL等；需要进行条件过滤、检索的，可以选择Elasticsearch等。企业一般对在线查询的需求
比较旺盛，因此可能会有多套在线计算的能力提供服务。

#### 4.即席分析
主要用于分析型场景和经验统计。一般而言，企业80％的数据处理需求是在线查询和即席分析。针对不同维度的
分析，有多种方式可以提供，提前固定计算的维度、根据需求任意维度的交叉分析等都是常见的场景。目前也有
很多相应的产品、框架来支撑这方面的应用，如Kylin、Impala、ClickHouse、Hawk等。

## 批处理
随着数据量的不断增加，原有的计算框架已经无法支撑TB、PB甚至EB级规模的数据处理，在这种大数据场景下，
提供成本低廉且可水平扩容的计算能力，采用分而治之的方法是必然的。

MapReduce是一种分布式编程模型，采用“分而治之”的思想，将一个大规模数据集分解为多个小规模数据，
然后分发给集群中多个节点共同完成计算。这样可以有效降低每一部分的运算复杂度，达到提高运算效率的目的。

MapReduce由于设计上的一些限制，导致处理性能较慢，针对这个问题，业界也有很多优化方案及替代产品，但
真正发展起来的，目前主要有Spark。Spark在以下几方面具有优势：
+ **数据处理技术**：Spark将执行模型抽象为通用的有向无环图（DAG）执行计划，这可以将多个Stage串联或
者并行执行，而无须将Stage的中间结果输出到HDFS中。
+ **数据格式和内存布局**：Spark RDD能支持粗粒度写操作，而对于读操作，RDD可以精确到每条记录，这使
得RDD可以用来作为分布式索引。
+ **执行策略**：MapReduce在数据Shuffle之前花费了大量的时间来排序，Spark支持基于Hash的分布式聚合，
调度中采用更为通用的任务执行DAG，每一轮的输出结果都可以缓存在内存中。
