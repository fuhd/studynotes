Apache Kudu概述
================================================================================
Apache Kudu是一个 **为Hadoop平台开发的列式存储管理器**。Kudu分享Hadoop生态系统应用程序的通用
技术特性：**它运行在商用硬件上，可横向扩展，并支持高可用的操作**。

Apache Kudu是Apache软件基金会的顶级项目。Kudu的好处包括：
+ 快速处理OLAP工作负载。
+ 与MapReduce，Spark，Flume和其他Hadoop生态系统组件集成。
+ 与Apache Impala紧密集成，使其成为在Apache Parquet中使用HDFS的良好可变替代方案。
+ 强大但灵活的一致性模型，允许您根据每个请求选择一致性要求，包括严格的序列化一致性选项。
+ 强大的性能可同时运行顺序和随机工作负载。
+ 通过Cloudera Manager轻松管理。
+ 高可用性。Tablet服务器和Master服务器使用Raft一致性算法，只要有更多副本可用，就可以确保可用性。
只读的Tablet跟随者，即使在Tablet引导者发生故障的情况下也可以为其读取服务。
+ 结构化数据模型。

**通过结合所有这些属性，Kudu的目标是支持难以或不可能在当前可用的Hadoop存储技术上实现的应用程序。
Kudu是一个可行的解决方案的应用包括**：
+ 报告应将新数据立即提供给最终用户的应用程序。
+ 时间序列应用程序必须支持跨大量历史数据的查询，同时返回有关单个实体的细粒度查询。
+ 应用程序使用预测模型进行实时决策，并根据所有历史数据定期刷新预测模型。

### 1.Kudu-Impala整合
Apache Kudu与Apache Impala紧密集成，**允许您通过Impala的SQL语法使用Impala插入、查询、更新和删
除Kudu Tablet中的数据，以替代使用Kudu API构建自定义Kudu应用程序**。另外，您可以通过JDBC或ODBC将
使用任何语言、框架或商业智能工具编写的现有或新应用程序连接到Kudu数据，并使用Impala作为代理。
+ **CREATE/ALTER/DROP TABLE** - Impala支持使用Kudu作为持久层来创建，更改和删除表。这些表格遵循
与Impala中其他表格相同的内部/外部方法，允许灵活的数据提取和查询。
+ **INSERT** - 可以使用与使用HDFS或HBase持久性的其他表相同的机制将数据从Impala插入到Kudu表中。
+ **更新/删除** - Impala支持UPDATE和DELETE SQL命令，以逐行或批处理方式修改Kudu表中的现有数据。
SQL命令的语法设计为尽可能与现有解决方案兼容。除了简单的DELETE或UPDATE命令之外，还可以使用与常规SELECT
语句相同的语法，在查询的FROM子句中指定复杂的连接。
+ **灵活的分区** - 与Hive中的表分区类似，Kudu允许您通过散列或范围动态预分割表到预定义数量的Tablet，
以便在您的集群中平均分配写入和查询。您可以使用任意数量的主键列进行分区，包括任意数量的散列，拆分行列表或
这些组合。分区方案是必需的。
+ **并行扫描** - 为了在现代硬件上实现最高性能，Impala使用的Kudu客户端可以跨多个平板电脑并行扫描。
+ **高效查询** - Impala在可能的情况下将谓词评估推送到Kudu，以便尽可能接近数据评估谓词。在许多工作负载
中，查询性能与Parquet相当。

### 2.示例用例
注意：具说小米使用了Kudu。

#### 可用的接近实时流输入
一个常见的业务挑战是 **新数据快速而持续地到达，并且需要几乎实时读取，扫描和更新相同的数据**。Kudu通过高
效的列式扫描提供了快速插入和更新的强大组合，可在单一存储层上启用实时分析用例。

#### 具有广泛变化的访问模式的时间序列应用程序
时间序列模式是根据数据点发生的时间对数据点进行组织和键入的模式。这对于调查指标随时间推移的表现或尝试基于过
去的数据预测未来行为很有用。例如，时间序列客户数据既可用于存储购买点击流历史记录，也可用于预测未来购买或供客
户支持代表使用。在发生这些不同类型的分析时，插入和突变也可能单独或批量地发生，并可立即用于读取工作负载。
Kudu可以以可扩展和高效的方式同时处理所有这些访问模式。

Kudu非常适合时间序列工作负载，原因有几个。由于Kudu支持 **基于散列的分区**，加上它对复合行键的本地支持，
因此在多台服务器上建立一个表格并不会产生使用范围分区时常见的“热点”风险。Kudu的列式存储引擎在这种情况下也是
有益的，因为许多时间序列工作负载只读取了几列，而不是整行。

**在过去，您可能需要使用多个数据存储来处理不同的数据访问模式。这种做法增加了应用程序和操作的复杂性，并且复
制了数据，使所需存储量翻番（或更糟糕）。Kudu可以本地和高效地处理所有这些访问模式，而无需将工作转移到其他数
据存储区**。

#### 预测建模
数据科学家通常从大量数据集开发预测学习模型。模型和数据可能需要随着学习的进行或模拟环境的变化而经常更新或修改。
另外，科学家可能想要改变模型中的一个或多个因素，以查看随着时间的推移会发生什么。在HDFS中更新存储在文件中的大
量数据是资源密集型的，因为每个文件都需要完全重写。在Kudu，更新几乎实时发生。科学家可以调整价值，重新运行查询，
并在几秒或几分钟内刷新图表，而不是几小时或几天。另外，批处理或增量算法可以随时在数据上运行，并具有近乎实时的
结果。

#### Kudu中的数据与遗留系统的结合
公司从多个来源生成数据并将其存储在各种系统和格式中。例如，一些数据可能存储在Kudu中，一些存储在传统的RDBMS中，
一些存储在HDFS中的文件中。**您可以使用Impala访问和查询所有这些源和格式，而无需更改旧系统**。
