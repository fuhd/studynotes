CDH中的Apache Hive概述
================================================================================
**Hive数据仓库** 软件支持在分布式存储中读取，编写和管理大型数据集。使用与SQL非常相似的 **Hive查
询语言（HiveQL）**，查询被转换为一系列通过 **MapReduce** 或 **Apache Spark** 在Hadoop集群
上执行的作业。

用户可以使用Hive运行批处理工作负载，同时还可以在单个平台内使用 **Apache Impala** 或 **Apache
Spark** 等工具分析 **交互式SQL** 或 **机器学习** 工作负载的相同数据。

作为CDH的一部分，Hive还受益于：
+ 统一资源管理由YARN提供；
+ Cloudera Manager提供简化的部署和管理；
+ 共享安全和治理，以满足Apache Sentry和Cloudera Navigator提供的合规要求；

### 1.Hive的用例
由于Hive是一个基于Hadoop平台构建的 **PB级数据仓库系统**，因此对于数据量急剧增长的环境而言，它是
一个不错的选择。HDFS底层MapReduce接口很难编程，但Hive提供了一个SQL接口，可以使用现有的编程技巧
来执行数据准备。

**Hive on MapReduce** 或 **Hive on Spark** 最适合 **批量数据准备** 或 **ETL**：
+ 必须使用非常大的ETL排序和连接运行计划的批处理作业，以便为Hadoop准备数据。大多数为Impala中的BI
用户提供的数据是由使用Hive的ETL开发人员准备的。
+ 运行数据传输或转换作业需要花费许多小时。**对于Hive，如果这样的工作出现问题，它会恢复并继续**。
+ 您可以接收或提供不同格式的数据，其中Hive SerDes和各种UDF可以方便地获取和转换数据。 通常，Hive
的ETL过程的最后阶段可能是高性能，广泛支持的格式，例如 **Parquet**。

### 2.Hive组件
Hive由以下组件组成：
+ **Metastore数据库**
+ **HiveServer2**

#### 2.1.Metastore数据库
Metastore数据库是Hive基础架构的一个重要方面。它是一个独立的数据库，**依赖于传统的RDBMS**，例如
**MySQL或PostgreSQL**，它保存有关Hive数据库、表、列、分区和Hadoop特定信息（例如底层数据文件和
HDFS块位置）的元数据。

**Metastore数据库由其他组件共享**。例如，**Hive和Impala都可以插入、查询、更改等相同的表**。但
请注意，即使在您未使用Hive本身的情况下，Metastore数据库也会广泛用于Hadoop生态系统。

Metastore数据库相对紧凑，数据快速变化。备份、复制和其他类型的管理操作会影响此数据库。有关配置Hive
Metastore的详细信息，请参阅为CDH配置Hive Metastore。

**Cloudera建议您以“remote mode”部署Hive Metastore**，其中存储Hive表和分区的元数据。在此模式
下，Metastore服务在其自己的JVM进程中运行，并且其他服务（例如 **HiveServer2，HCatalog和Apache
Impala**）使用 **Thrift网络API** 与Metastre进行通信。

#### 2.2.HiveServer2
**HiveServer2是一个服务器接口，它使远程客户端能够向Hive提交查询并检索结果**（它取代了HiveServer1，
它已被弃用，并将在未来的CDH版本中被删除）。**HiveServer2支持多客户端并发**，容量规划控制，Sentry
授权，Kerberos身份验证，LDAP和SSL，并为JDBC和ODBC客户端提供更好的支持。

**HiveServer2是Hive执行引擎的容器**。对于每个客户端连接，它会创建一个新的执行上下文，用于向客户端
提供Hive SQL请求。**它支持JDBC客户端**，例如Beeline CLI和ODBC客户端。客户端通过基于Thrift API
的Hive服务连接到HiveServer2。

### 3.Hive如何与其他组件配合使用
Hive与其他组件集成，用作 **查询执行引擎** 或 **数据存储**：
+ **Hive on Spark**
+ **Hive与HBase**

#### 3.1.Hive on Spark
**Hive传统上在后台使用MapReduce来并行化工作**，并执行处理SQL语句（如排序和过滤）的低级步骤。
**Hive也可以使用Spark作为底层计算和并行化引擎**。有关将Hive配置为使用Spark作为其执行引擎的详细信
息，请参阅在CDH中的Spark上运行Apache Hive，并参阅有关在Spark中调优Hive的详细信息，请参阅CDH中的
Spark上的Apache Hive调优。

#### 3.2.Hive与HBase
**Apache HBase是一个NoSQL数据库，支持对HDFS中大型数据集的实时读/写访问**。有关配置Hive以使用
HBase的详细信息，请参阅在CDH中使用Apache Hive和HBase。有关在安全HBase服务器上运行Hive查询的信息，
请参阅使用Hive在安全HBase服务器上运行查询。
