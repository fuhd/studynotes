Apache Spark概述
================================================================================
Apache Spark是分布式计算的通用框架，可为 **批处理** 和 **交互式处理** 提供高性能。它公开了Java，
Python和Scala的API，并由Spark core和几个相关项目组成：
+ **Spark SQL** - 用于处理结构化数据的模块。允许您将SQL查询与Spark程序无缝混合。
+ **Spark Streaming** - API允许您构建可扩展的容错流应用程序。
+ **MLlib** - 实现常用机器学习算法的API。
+ **GraphX** - 用于图和图并行计算的API。

您可以在 **本地** 运行Spark应用程序，也可以通过使用 **交互式shell** 或通过 **提交应用程序** 在集群
中分布运行Spark应用程序。**以交互方式运行Spark应用程序通常在数据探索阶段和临时分析期间执行**。

要运行分布在集群中的应用程序，Spark需要一个 **集群管理器**。**Cloudera支持两个群集管理器：YARN
和Spark Standalone**。当在YARN上运行时，Spark应用程序进程由YARN ResourceManager和NodeManager
角色管理。当在Spark Standalone上运行时，Spark应用程序进程由Spark Master和Worker角色管理。
```
注意：

此页面包含与CDH相关的Spark 1.6相关信息。有关Apache Spark2的Cloudera Distribution的单独可用parcel的信息，
请参阅Apache Spark2的Cloudera Distribution的文档。
```

### 1.不支持的功能
以下Spark功能不受支持：
+ Spark SQL：
  - Thrift JDBC/ODBC服务器
  - Spark SQL CLI
+ Spark Dataset API
+ SparkR
+ GraphX
+ Spark on Scala 2.11
+ Mesos cluster manager
