Oozie工作流功能规范
===================================================================================
本文档的目标是定义一个专门用于协调Hadoop Map/Reduce和Pig作业执行的工作流引擎系统。

## 1.定义
+ **Action**：执行/计算任务（Map-Reduce作业，Pig作业，shell命令）。它也可以称为任务或“动作
节点”。
+ **Workflow**：在控件依赖关系DAG（有向无环图）中排列的动作集合。从一个动作到另一个动作的“控制
依赖性”意味着第二个动作在第一个动作完成之前无法运行。
+ **Workflow定义**：可以执行的工作流的编程描述。
+ **Workflow定义语言**：用于定义工作流定义的语言。
+ **Workflow作业**：工作流定义的可执行实例。
+ **Workflow引擎**：执行Workflow作业的系统。它也可以称为DAG引擎。

## 2.规格要点
Workflow应用程序是DAG，它协调以下类型的操作：Hadoop，Pig和子Workflow。

可以使用`decision`，`fork`和`join`节点完成Workflow应用程序中的流控制操作。不支持Workflow中
的循环。

可以使用Job属性，Action输出（即Hadoop计数器）和文件信息（文件存在，文件大小等）来参数化Action
和decision。正式参数在Workflow定义中表示为`${VAR}`变量。

Workflow应用程序是一个ZIP文件，其中包含Workflow定义（XML文件），运行所有Actions所需的所有文
件：Map/Reduce作业的JAR文件，流Map/Reduce作业的shell，本地库，Pig脚本和其他资源文件。

在运行Workflow作业之前，必须在Oozie中部署相应的Workflow应用程序。

部署Workflow应用程序和运行Workflow作业可以通过命令行工具，WS API和Java API完成。

可以通过Web控制台，命令行工具，WS API和Java API来监视系统和Workflow作业。

提交Workflow作业时，必须提供一组解析工作流定义中所有形式参数的属性。这组属性是Hadoop配置。

Workflow作业的可能状态包括：`PREP`，`RUNNING`，`SUSPENDED`，`SUCCEEDED`，`KILLED`和`FAILED`。

如果Workflow作业中的操作启动失败，则根据失败的类型，Oozie将尝试自动重试，它将请求手动重试，否则
将使工作流作业失败。

Oozie可以在Action `start`/`end`/`failure`事件和工作流`end`/'failure'事件上发出HTTP回调
通知。

在Workflow作业失败的情况下，可以重新提交工作流作业，跳过以前完成的操作。在重新提交之前，可以使用
修补程序更新Workflow应用程序，以修复Workflow应用程序代码中的问题。

## 3.Workflow定义
Workflow定义是具有 **控制流节点**（`start`，`end`，`decision`，`fork`，`join`，`kill`）
或 **动作节点**（`map-reduce`，`pig`等）的DAG，节点通过转换箭头连接。

Workflow定义语言是基于XML的，它被称为 **hPDL**（Hadoop流程定义语言）。

有关[Oozie Workflow Definition XML Schema](http://oozie.apache.org/docs/4.3.1/WorkflowFunctionalSpec.html#OozieWFSchema)的信息，请参阅附录A. 附录B包含
[工作流程定义示例](http://oozie.apache.org/docs/4.3.1/WorkflowFunctionalSpec.html#OozieWFExamples)。

### 3.1.Workflow定义中的循环
Oozie不支持Workflow定义中的循环，Workflow定义必须是严格的DAG。

在Workflow应用程序部署时，如果Oozie在Workflow定义中检测到循环，则必须使部署失败。

## 4.Workflow节点
Workflow节点分为控制流节点和操作节点：
+ **控制流节点**：控制Workflow和Workflow作业执行路径的开始和结束的节点。
+ **操作节点**：触发执行计算/处理任务的节点。

节点名称和转换必须符合以下模式`[a-zA-Z][\_-a-zA-Z0-0]`，最多20个字符。

### 4.1.控制流节点
控制流节点定义Workflow的开始和结束（`start`，`end`和`kill`节点），并提供控制工作流执行路径
（`decision`，`fork`和`join`节点）的机制。

#### 4.1.1.start控制节点
`start`节点是Workflow作业的入口点，它指示Workflow作业必须转换到的第一个工作流节点。

Workflow启动时，它会自动转换到`start`指定的节点。工作流定义必须具有一个`start`节点。

语法：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.1">
  ...
  <start to="[NODE-NAME]"/>
  ...
</workflow-app>
```
`to`属性是要执行的第一个工作流节点的名称。

示例：
```xml
<workflow-app name="foo-wf" xmlns="uri:oozie:workflow:0.1">
    ...
    <start to="firstHadoopJob"/>
    ...
</workflow-app>
```

#### 4.1.2.end控制节点
`end`节点是Workflow作业的结束，它表示Workflow作业已成功完成。

当Workflow作业到达`end`时，它成功完成（SUCCEEDED）。

如果在到达`end`节点时正在执行Workflow作业启动的一个或多个操作，则将终止操作。在此方案中，Workflow
作业仍被视为已成功运行。

Workflow定义必须具有一个`end`节点。

语法：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.1">
    ...
    <end name="[NODE-NAME]"/>
    ...
</workflow-app>
```
`name`属性是结束Workflow作业的转换的名称。

示例：
```xml
<workflow-app name="foo-wf" xmlns="uri:oozie:workflow:0.1">
    ...
    <end name="end"/>
</workflow-app>
```

#### 4.1.3.Kill控制节点
`kill`节点允许Workflow作业自行终止。当Workflow作业到达`kill`时，它完成错误（KILLED）。

如果在到达`kill`节点时正在执行Workflow作业启动的一个或多个操作，则将终止操作。

Workflow定义可以具有零个或多个终止节点。

语法：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.1">
    ...
    <kill name="[NODE-NAME]">
        <message>[MESSAGE-TO-LOG]</message>
    </kill>
    ...
</workflow-app>
```
`kill`节点中的`name`属性是Kill操作节点的名称。

将`message`元素的内容记录为Workflow作业的终止原因。

`kill`节点没有过渡元素，因为它结束了工作流作业，如`KILLED`。

示例：
```xml
<workflow-app name="foo-wf" xmlns="uri:oozie:workflow:0.1">
    ...
    <kill name="killBecauseNoInput">
        <message>Input unavailable</message>
    </kill>
    ...
</workflow-app>
```

#### 4.1.4.decision控制结点
`decision`节点使工作流能够在要遵循的执行路径上进行选择。

`decision`节点的行为可以看作是switch-case语句。

`decision`节点由谓词－转换对列表和默认转换组成。按顺序或外观评估谓词，直到其中一个评估为`true`
并进行相应的转换。如果没有谓词计算为`true`，则采用`default`转换。

谓词是JSP表达式语言（EL）表达式（参见本文档的第4.2节），它解析为布尔值，`true`或`false`。例如：
```
${fs:fileSize('/usr/foo/myinputdir') gt 10 * GB}
```
语法：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.1">
    ...
    <decision name="[NODE-NAME]">
        <switch>
            <case to="[NODE_NAME]">[PREDICATE]</case>
            ...
            <case to="[NODE_NAME]">[PREDICATE]</case>
            <default to="[NODE_NAME]"/>
        </switch>
    </decision>
    ...
</workflow-app>
```
`decision`节点中的`name`属性是decision节点的名称。

每个`case`元素都包含谓词和转换名称。按顺序计算谓词EL，直到一个返回`true`并进行相应的转换。

`default`元素表示如果没有谓词计算为`true`

所有decision节点都必须具有`default`元素，以避免在没有任何谓词计算为true时将工作流置于错误状态。

示例：
```xml
<workflow-app name="foo-wf" xmlns="uri:oozie:workflow:0.1">
    ...
    <decision name="mydecision">
        <switch>
            <case to="reconsolidatejob">
              ${fs:fileSize(secondjobOutputDir) gt 10 * GB}
            </case>
            <case to="rexpandjob">
              ${fs:fileSize(secondjobOutputDir) lt 100 * MB}
            </case>
            <case to="recomputejob">
              ${ hadoop:counters('secondjob')[RECORDS][REDUCE_OUT] lt 1000000 }
            </case>
            <default to="end"/>
        </switch>
    </decision>
    ...
</workflow-app>
```

#### 4.1.5.Fork和Join控制节点
`fork`节点将一个执行路径拆分为多个并发执行路径。

`join`节点等待，直到前一个`fork`节点的每个并发执行路径到达它。

`fork`和`join`节点必须成对使用。`join`节点假定并发执行路径是同一`fork`节点的子节点。

语法：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.1">
    ...
    <fork name="[FORK-NODE-NAME]">
        <path start="[NODE-NAME]" />
        ...
        <path start="[NODE-NAME]" />
    </fork>
    ...
    <join name="[JOIN-NODE-NAME]" to="[NODE-NAME]" />
    ...
</workflow-app>
```
`fork`节点中的`name`属性是Workflow fork节点的名称。fork节点中`path`元素中的`start`属性指
示将成为并发执行路径一部分的Workflow节点的名称。

`join`节点中的`name`属性是Workflow join节点的名称。join节点中的`to`属性指示在相应fork的所
有并发执行路径到达join节点之后将执行的工作流节点的名称。

示例：
```xml
<workflow-app name="sample-wf" xmlns="uri:oozie:workflow:0.1">
    ...
    <fork name="forking">
        <path start="firstparalleljob"/>
        <path start="secondparalleljob"/>
    </fork>
    <action name="firstparallejob">
        <map-reduce>
            <job-tracker>foo:8021</job-tracker>
            <name-node>bar:8020</name-node>
            <job-xml>job1.xml</job-xml>
        </map-reduce>
        <ok to="joining"/>
        <error to="kill"/>
    </action>
    <action name="secondparalleljob">
        <map-reduce>
            <job-tracker>foo:8021</job-tracker>
            <name-node>bar:8020</name-node>
            <job-xml>job2.xml</job-xml>
        </map-reduce>
        <ok to="joining"/>
        <error to="kill"/>
    </action>
    <join name="joining" to="nextaction"/>
    ...
</workflow-app>
```
默认情况下，Oozie执行一些验证，即Workflow中的任何分支都是有效的，不会导致任何不正确的行为或不稳
定。但是，如果Oozie阻止提交Workflow并且您确定它应该可以工作，则可以禁用forkjoin验证，以便
Oozie接受Workflow。要仅为特定工作流禁用此验证，只需在`job.properties`文件中将
`oozie.wf.validate.ForkJoin`设置为`false`。要为所有Workflow禁用此验证，只需在`oozie-site.xml`
文件中将`oozie.validate.ForkJoin`设置为`false`即可。禁用此验证由这两个属性的AND确定，因此
如果其中一个或两个都设置为`false`，则将被禁用，并且仅当两者都设置为`true`（或未指定）时才会启用。

### 4.2.Workflow动作节点
动作节点是工作流触发计算/处理任务执行的机制。

#### 4.2.1.动作基础
以下子部分定义了所有操作类型的常见行为和功能。

##### 4.2.1.1.动作计算/处理始终是远程的
由动作节点触发的所有计算/处理任务对Oozie都是远程的。在Oozie中没有执行特定于Workflow应用程序的
计算/处理任务。

##### 4.2.1.2.动作是异步的
由动作节点触发的所有计算/处理任务由Oozie异步执行。对于由Workflow操作触发的大多数类型的计算/处理
任务，Workflow作业必须等到计算/处理任务完成后才转换到Workflow中的以下节点。

例外情况是作为同步操作处理的`fs`操作。

Oozie可以通过两种不同的方式，回调和轮询来检测计算/处理任务的完成情况。

当Oozie启动计算/处理任务时，Oozie为任务提供唯一的回调URL，任务应调用给定的URL以通知其完成。

对于任务因任何原因（即瞬态网络故障）未能调用回调URL或者任务类型在完成时无法调用回调URL的情况，
Oozie有一种机制来轮询计算/处理任务以完成。

##### 4.2.1.3.动作有2个转换，ok和error
如果由Workflow触发的计算/处理任务成功完成，则转换为`ok`。

如果由Workflow触发的计算/处理任务未能成功完成，则其转换为`error`。

如果计算/处理任务出错，则计算/处理任务必须向Oozie提供`error-code`和`error-message`信息。可
以从`decision`节点使用此信息来在Workflow应用程序级别实现细粒度错误处理。

每种操作类型都必须清楚地定义它可以生成的所有错误代码。

##### 4.2.1.4.动作恢复
Oozie在开始或结束动作时提供恢复功能。

一旦动作成功启动，如果动作在执行期间失败，Oozie将不会重试启动动作。假设执行动作的外部系统（即Hadoop）
具有足够的弹性以在其启动后恢复作业（即Hadoop任务重试）。

Java动作是重试的特例。虽然Oozie本身不会重试Java动作，但如果它们在成功启动后失败，Hadoop本身可
能会导致操作重新启动，因为运行Java应用程序的map任务上的map任务重试。有关更多详细信息，请参阅下
面的Java Action部分。

对于在工作开始之前发生的故障，Oozie将根据故障的性质采用不同的恢复策略。

如果故障是暂时性的，Oozie将在预定义的时间间隔后执行重试。必须在Oozie级别预先配置某种动作的重试
次数和计时器间隔。工作流作业可以覆盖此类配置。

瞬态故障的示例是网络问题或远程系统暂时不可用。

如果故障属于非暂时性质，Oozie将暂停Workflow作业，直到手动或程序干预恢复Workflow作业并重试动作
开始或结束。管理员或外部管理系统负责在恢复Workflow作业之前执行任何必要的清理。

如果失败是错误并且重试无法解决问题，Oozie将执行操作的错误转换。

#### 4.2.2.Map-Reduce动作
`map-reduce`动作从工作流启动Hadoop map/reduce作业。Hadoop作业可以是Java Map/Reduce作业
或streaming作业。

可以将`map-reduce`动作配置为在启动map reduce作业之前执行文件系统清理和目录创建。此功能使Oozie
能够在发生瞬时故障的情况下重试Hadoop作业（Hadoop检查作业输出目录是否不存在，然后在Hadoop作业
启动时创建它，因此在不清除作业输出目录的情况下重试失败）。

Workflow作业将等待Hadoop map/reduce作业完成，然后继续执行Workflow执行路径中的下一个动作。

Hadoop作业结束后，Hadoop作业和作业退出状态（`FAILED`，`KILLED`或`SUCCEEDED`）的计数器必须
可用于Workflow作业。可以在decision节点和其他动作配置中使用此信息。

必须使用所有必需的Hadoop JobConf属性配置`map-reduce`动作以运行Hadoop map/reduce作业。

可以将Hadoop JobConf属性指定为其中一部分：
1. config-default.xml；
2. JobConf XML文件与Workflow应用程序捆绑在一起；
3. Workflow定义中的标记；
4. 内联`map-reduce`动作配置；
5. 由工作流定义中的标记指定的OozieActionConfigurator的实现。

配置属性按以下顺序加载，即`streaming`，`job-xml`，`configuration`和`config-class`，优先
顺序是稍后的值覆盖之前的值。

可以使用EL表达式对流和内联属性值进行参数化（模板化）。

`job-xml`和内联配置中不得出现Hadoop `mapred.job.tracker`和`fs.default.name`属性。

##### 4.2.2.1.为作业添加文件和存档
`file`，`archive`元素可用于map-reduce作业，文件和存档。如果指定的路径是相对路径，则假定文件
或存档位于相应子路径中的应用程序目录中。如果路径是绝对路径，则在给定的绝对路径中期望的文件或归档。

使用file元素指定的文件将是任务主目录中的符号链接。

如果文件是本地库（'.so'或'.so.＃'文件），它将在任务运行目录中符号链接为“.so”文件，因此可供任务
JVM使用。

要在任务运行目录上强制文件的符号链接，请使用“#”后跟符号链接名称。例如'mycat.sh#cat'。

有关文件和存档的详细信息，请参阅Hadoop分布式缓存文档。

##### 4.2.2.2.使用Java代码配置MapReduce操作
Java代码可用于进一步配置MapReduce动作。如果您已经拥有MapReduce操作的“驱动程序”代码，如果您更
熟悉MapReduce的Java API，如果某些配置需要逻辑，或者某些配置难以在直接XML中执行（例如Avro），
那么这将非常有用。

创建一个实现“oozie-sharelib-oozie”工件中的`org.apache.oozie.action.hadoop.OozieActionConfigurator`
接口的类。它包含一个接收JobConf作为参数的方法。MapReduce动作将使用此JobConf上设置的任何配置
属性。

OozieActionConfigurator有这个签名：
```java
public interface OozieActionConfigurator {
    public void configure(JobConf actionConf) throws OozieActionConfiguratorException;
}
```
`actionConf`是您可以更新的`JobConf`。如果需要抛出异常，可以将其包装在`OozieActionConfiguratorException`
中，也可以包含在“oozie-sharelib-oozie”工件中。

示例：
```java
package com.example;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobConf;
import org.apache.oozie.action.hadoop.OozieActionConfigurator;
import org.apache.oozie.action.hadoop.OozieActionConfiguratorException;
import org.apache.oozie.example.SampleMapper;
import org.apache.oozie.example.SampleReducer;

public class MyConfigClass implements OozieActionConfigurator {
    @Override
    public void configure(JobConf actionConf) throws OozieActionConfiguratorException {
        if (actionConf.getUser() == null) {
            throw new OozieActionConfiguratorException("No user set");
        }
        actionConf.setMapperClass(SampleMapper.class);
        actionConf.setReducerClass(SampleReducer.class);
        FileInputFormat.setInputPaths(actionConf, new Path("/user/" + actionConf.getUser() + "/input-data"));
        FileOutputFormat.setOutputPath(actionConf, new Path("/user/" + actionConf.getUser() + "/output"));
        ...
    }
}
```
要在MapReduce动作中使用配置类，只需将其编译到jar中，使jar可用于您的动作，并在`config-class`
元素中指定类名（这至少需要模式0.5）：
```xml
<workflow-app name="[WF-DEF-NAME]" xmlns="uri:oozie:workflow:0.5">
    ...
    <action name="[NODE-NAME]">
        <map-reduce>
            ...
            <job-xml>[JOB-XML-FILE]</job-xml>
            <configuration>
                <property>
                    <name>[PROPERTY-NAME]</name>
                    <value>[PROPERTY-VALUE]</value>
                </property>
                ...
            </configuration>
            <config-class>com.example.MyConfigClass</config-class>
            ...
        </map-reduce>
        <ok to="[NODE-NAME]"/>
        <error to="[NODE-NAME]"/>
    </action>
    ...
</workflow-app>
```
另一个例子可以在Oozie附带的“map-reduce”示例中找到。

一个有用的提示：传递给`configure`方法的初始`JobConf`包括Workflow中MR操作的配置部分中列出的所
有属性。如果您需要将任何信息传递给`OozieActionConfigurator`，您可以将它们放在这里。

##### 4.2.2.3.Streaming
可以在Streaming元素中指定Streaming信息。

# 未完.......................................

