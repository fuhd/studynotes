架构详解
================================================================================
Druid的目标是提供一个能够在大数据集上做实时数据消费与探索的平台。然而，**对普遍的数据平台来说，
数据的高效摄入与快速查询往往是一对难以两全的指标，因此常常需要在其中做一些取舍与权衡**。相比之下，
**Druid却能够同时提供性能卓越的数据实时摄入与复杂的查询性能**。它是怎么做到的呢？答案是 **通过
其独到的架构设计、基于DataSource与Segment的数据结构**，以及在许多系统细节上的优秀设计与实现。

## 1.Druid架构概览

![Druid架构](img/1.jpeg)

Druid总体架构图显示出Druid自身包含以下4类节点：
+ **实时节点（`Realtime Node`）：即时摄入实时数据，以及生成Segment数据文件**。 
+ **历史节点（`Historical Node`）：加载已生成好的数据文件，以供数据查询**。
+ **查询节点（`Broker Node`）：对外提供数据查询服务，并同时从实时节点与历史节点查询数据，合并
后返回给调用方**。
+ **协调节点（`Coordinator Node`）：负责历史节点的数据负载均衡，以及通过规则（Rule）管理数据
的生命周期**。

同时，集群还包含以下三类外部依赖：
+ **元数据库（`Metastore`）**：存储Druid集群的原数据信息，比如Segment的相关信息，**一般用
MySQL或PostgreSQL**。
+ **分布式协调服务（`Coordination`）**：为Druid集群提供一致性协调服务的组件，通常为 
**Zookeeper**。
+ **数据文件存储库（`DeepStorage`）**：存放生成的Segment数据文件，并供历史节点下载。对于单节
点集群可以是本地磁盘，**而对于分布式集群一般是HDFS或NFS**。

**从数据流转的角度来看，数据从架构图的左侧进入系统，分为实时流数据与批量数据。实时流数据会被实时
节点消费，然后实时节点将生成的Segment数据文件上传到数据文件存储库；而批量数据经过Druid集群消费
后会被直接上传到数据文件存储库。同时，查询节点会响应外部的查询请求，并将分别从实时节点与历史节点
查询到的结果合并后返回**。

## 2.Druid架构设计思想
**对于目前大多数Druid的使用场景来说，Druid本质上是一个分布式的时序数据库**，而对于一个数据库的
性能来说，其数据的组织方式至关重要。为了更好地阐述Druid的架构设计思想，我们得先从数据库的文件组
织方式聊起。

众所周知，数据库的数据大多存储在磁盘上，而磁盘的访问相对内存的访问来说是一项很耗时的操作。因此，
**提高数据库数据的查找速度的关键点之一便是尽量减少磁盘的访问次数**。为了加速数据库数据的访问，大
多传统的关系型数据库都会使用特殊的数据结构来帮助查找数据，这种数据结构叫作索引（`Index`）。**对
于传统的关系型数据库，考虑到经常需要范围查找某一批数据，因此其索引一般不使用Hash算法，而使用树（
`Tree`）结构**。然而，树结构的种类很多，却不一定都适合用于做数据库索引。

### 2.1.索引对树结构的选择








