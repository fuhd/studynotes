附录A：安装Apache Hadoop
=============================================================================
在单机上安装`Hadoop`来尝试一下是非常容易的，**面向集群的安装方法，可以参见第`10`章**。

这里将介绍如何使用一个`Apache Software Foundation`发布的二进制压缩包安装 **`Hadoop Common`、
`HDFS`、`MapReduce`和`YARN`**。

### 先决条件
必须确保安装的是合适版本的`Java`。可以通过`Hadoop wiki（http://wiki.apache.org/hadoop/HadoopJavaVersions）`
查看所安装版本的信息。以下命令可以帮助确认`Java`是正确安装的：
```shell
$ java -version
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```

### 安装
首先，决定以什么用户的身份来运行`Hadoop`。如果只是想试用`Hadoop`或开发`Hadoop`程序，可以用用户帐号
在单机上运行`Hadoop`。

从`Apache Hadoop`发布页面（`http://hadoop.apache.org/common/releases.html`）下载个稳定版的发布包，
再解压缩到本地文件系统：
```shell
$ tar xzvf hadoop-3.0.0.tar.gz
```
在运行`Hadoop`安装程序之前，需要指定`Java`在本地系统中的路径。**如果系统的`JAVA_HOME`环境变量已经正确地
指向一个`Java`安装路径，且用户也希望使用该`Java`安装路径，则无需进行其他配置**（这通常在一个`shell`启动文件
中设置，例如`~/.bash_profile`或者`~/.bashrc`）。否则，**仍然需要编辑`etc/hadoop/hadoop-env.sh`文件来
设置`JAVA_HOME`环境变量以指定`Java`安装路径**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
```
很容易 **创建指向`Hadoop`安装目录（依照惯例是`HADOOP_HOME`）的环境变量**；此外，还要 **将`Hadoop`的二进制目录
添加到命令行路径上**。例如：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib

export HADOOP_HOME=/opt/hadoop-3.0.0
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```
注意，**`sbin`目录下有运行`Hadoop`守护进程的脚本，因此如果计划在本地机器上运行守护进程的话，需要将该
目录包含进命令行路径中**。

输入以下指令来判断`Hadoop`是否工作：
```shell
$ hadoop version
Hadoop 3.0.0
Source code repository https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533
Compiled by andrew on 2017-12-08T19:16Z
Compiled with protoc 2.5.0
From source with checksum 397832cb5529187dc8cd74ad54ff22
This command was run using /opt/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar
```

### 配置
`Hadoop`的各个组件均可利用`XML`文件进行配置。**`core-site.xml`文件用于配置通用属性，`hdfs-site.xml`文件用于
配置`HDFS`属性，`mapred-site.xml`文件则用于配置`MapReduce`属性，`yarn-site.xml`文件用于配置`YARN`属性。
这些配置文件都放在`etc/hadoop`子目录中**。
```
上述配置文件中的属性都有默认设置，分别保存在Hadoop安装路径的share/doc子目录下，即：
share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml
share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
share/doc/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
```




