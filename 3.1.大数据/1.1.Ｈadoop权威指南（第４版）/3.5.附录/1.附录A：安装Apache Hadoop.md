附录A：安装Apache Hadoop
=============================================================================
在单机上安装`Hadoop`来尝试一下是非常容易的，**面向集群的安装方法，可以参见第`10`章**。

这里将介绍如何使用一个`Apache Software Foundation`发布的二进制压缩包安装 **`Hadoop Common`、
`HDFS`、`MapReduce`和`YARN`**。

### 先决条件
必须确保安装的是合适版本的`Java`。可以通过`Hadoop wiki（http://wiki.apache.org/hadoop/HadoopJavaVersions）`
查看所安装版本的信息。以下命令可以帮助确认`Java`是正确安装的：
```shell
$ java -version
java version "1.8.0_144"
Java(TM) SE Runtime Environment (build 1.8.0_144-b01)
Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode)
```

### 安装
首先，决定以什么用户的身份来运行`Hadoop`。如果只是想试用`Hadoop`或开发`Hadoop`程序，可以用用户帐号
在单机上运行`Hadoop`。

从`Apache Hadoop`发布页面（`http://hadoop.apache.org/common/releases.html`）下载个稳定版的发布包，
再解压缩到本地文件系统：
```shell
$ tar xzvf hadoop-3.0.0.tar.gz
```
在运行`Hadoop`安装程序之前，需要指定`Java`在本地系统中的路径。**如果系统的`JAVA_HOME`环境变量已经正确地
指向一个`Java`安装路径，且用户也希望使用该`Java`安装路径，则无需进行其他配置**（这通常在一个`shell`启动文件
中设置，例如`~/.bash_profile`或者`~/.bashrc`）。否则，**仍然需要编辑`etc/hadoop/hadoop-env.sh`文件来
设置`JAVA_HOME`环境变量以指定`Java`安装路径**：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
```
很容易 **创建指向`Hadoop`安装目录（依照惯例是`HADOOP_HOME`）的环境变量**；此外，还要 **将`Hadoop`的二进制目录
添加到命令行路径上**。例如：
```shell
export JAVA_HOME=/opt/jdk1.8.0_144
export JRE_HOME=$JAVA_HOME/jre
export CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib

export HADOOP_HOME=/opt/hadoop-3.0.0
export PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
```
注意，**`sbin`目录下有运行`Hadoop`守护进程的脚本，因此如果计划在本地机器上运行守护进程的话，需要将该
目录包含进命令行路径中**。

输入以下指令来判断`Hadoop`是否工作：
```shell
$ hadoop version
Hadoop 3.0.0
Source code repository https://git-wip-us.apache.org/repos/asf/hadoop.git -r c25427ceca461ee979d30edd7a4b0f50718e6533
Compiled by andrew on 2017-12-08T19:16Z
Compiled with protoc 2.5.0
From source with checksum 397832cb5529187dc8cd74ad54ff22
This command was run using /opt/hadoop-3.0.0/share/hadoop/common/hadoop-common-3.0.0.jar
```

### 配置
`Hadoop`的各个组件均可利用`XML`文件进行配置。**`core-site.xml`文件用于配置通用属性，`hdfs-site.xml`文件用于
配置`HDFS`属性，`mapred-site.xml`文件则用于配置`MapReduce`属性，`yarn-site.xml`文件用于配置`YARN`属性。
这些配置文件都放在`etc/hadoop`子目录中**。
```
上述配置文件中的属性都有默认设置，分别保存在Hadoop安装路径的share/doc子目录下，即：
share/doc/hadoop/hadoop-project-dist/hadoop-common/core-default.xml
share/doc/hadoop/hadoop-project-dist/hadoop-hdfs/hdfs-default.xml
share/doc/hadoop/hadoop-mapreduce-client/hadoop-mapreduce-client-core/mapred-default.xml
share/doc/hadoop/hadoop-yarn/hadoop-yarn-common/yarn-default.xml
```
`Hadoop`有以下三种运行模式：
+ **独立（或本地）模式**：无需运行任何守护进程，所有程序都在同一个`JVM`上执行。在独立模式下测试和调试`MapReduce`程序很方便，
因此该模式在开发阶段比较合适。
+ **伪分布模式**：`Hadoop`守护进程运行在本地机器上，模拟一个小规模的集群。
+ **全分布模式**：`Hadoop`守护进程运行在一个集群上。此模式的设置参见第`10`章。

在特定模式下运行`Hadoop`需要关注两个因素：**正确设置属性和启动`Hadoop`守护进程**。下表列举了配置各种模式所需要的 **最小属性集合**。
在独立模式下，将使用本地文件系统和本地`MapReduce`作业运行器；在分布模式下，将启动`HDFS`和`YARN`守护进程，此外还需配置`MapReduce`
以便能够使用`YARN`。

| 组件名称 | 属性名称 | 独立模式 | 伪分布模式 | 全分布模式 |
|:--------|:-------|:--------|:----------|:---------|
| Common | fs.defaultFS |file:/// (默认) | hdfs://localhost/ | hdfs://namenode/ |
| HDFS | dfs.replication | N/A | 1 | 3 |
| MapReduce | mapreduce.framework.name | local（默认）|yarn | yarn |
| YARN | yarn.resourcemanager.hostname, yarn.nodemanager.aux-services | N/A | localhost,mapreduce_shuffle | resourcemanager,mapreduce_shuffle |

### 独立模式
**由于默认属性专为本模式所设定，且本模式无需运行任何守护进程，因此在独立模式下不需要更多操作**。

### 伪分布模式
在伪分布模式下，使用如下内容 **创建配置文件**，并将其放在 **`etc/hadoop`** 目录下。**也可以把`etc/hadoop`目录复制到
另一个位置，然后把`*-site.xml`这些配置文件放在该目录下。这种方法的优点是，将配置设置和安装文件隔离开**。如果是这么做的，
那么需要 **将环境变量`HADOOP_CONF_DIR`设置成指向那个新目录**，或确定在启动守护进程时 **使用`--config选项**。
```xml
<?xml version="1.0"?>
<!--core-site.xml -->
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost/</value>
    </property>
</configuration>

<?xml version="1.0"?>
<!-- hdfs-site.xml -->
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

<?xml version="1.0"?>
<!-- mapred-site.xml -->
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

<?xml version="1.0"?>
<!-- yarn-site.xml -->
<configuration>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>localhost</value>
    </property>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
</configuration>
```
#### 配置SSH










