使用Hadoop来分析数据
===============================================================================
**为了充分利用`Hadoop`提供的并行处理优势，我们需要将查询表示成`MapReduce`作业**。完成某种本地端的小规模测试之后，
就可以把作业部署到在集群上运行。

### map和reduce
**`MapReduce`任务过程分为两个处理阶段。`map`阶段和`reduce`阶段**。每阶段都以 **键/值对** 作为输入和输出，其类型
由程序员来选择。程序员还需要写两个函数：**`map`函数** 和 **`reduce`函数**。

**`map`阶段的输入是`NCDC`原始数据**。我们选择 **文本格式** 作为输入格式，将数据集的 **每一行** 作为文本输入。键是
某一行起始位置相对于文件起始位置的偏移量，不过我们不需要这个信息，所以将其忽略。

我们的`map`函数很简单。由于我们只对年份和气温属性感兴趣，所以只需要取出这两个字段数据。在本例中，`map`函数只是一个数据
准备阶段，通过这种方式来准备数据，使`reduce`函数能够继续对它进行处理：


