Hadoop文件系统
============================================================================
**`Hadoop`有一个抽象的文件系统概念，`HDFS`只是其中的一个实现**。`Java`抽象类 **`org.apache
.hadoop.fs.FileSystem`定义了`Hadoop`中一个文件系统的客户端接口，并且该抽象类有几个具体实现**，
其中和`Hadoop`紧密相关的见下表：

| 文件系统 | URI方案 | Java实现（都在org.apache.hadoop包中）| 描述 |
|:--------|:-------|:----------------------------------|:-----|
| **Local** | **file** | **fs.LocalFileSystem** | 使用客户端校验和的本地磁盘文件系统。使用`RawLocalFileSystem`表示无校验和的本地磁盘文件系统 |
| **HDFS** | **hdfs** | **hdfs.DistributedFileSystem** | `Hadoop`的分布式文件系统。将`HDFS`设计成与`MapReduce`结合使用，可以实现高性能 |
| **WebHDFS** | **Webhdfs** | **Hdfs.web.WebHdfsFileSystem** | 基于`HTTP`的文件系统，提供对`HDFS`的认证读/写访问 |
| **Secure WebHDFS** | **swebhdfs** | **hdfs.web.SWebHdfsFileSystem** | `WebHDFS`的`HTTPS`版本 |
| **HAR** | **har** | **fs.HarFileSystem** | 一个构建在其他文件系统之上用于文件存档的文件系统。`Hadoop`存档文件系统通常用于将`HDFS`中的多个文件打包成一个存档文件，以减少`namenode`内存的使用。使用`hadoop`的`achive`命令来创建`HAR`文件 |
| **View** | **viewfs** | **viewfs.ViewFileSystem** | 针对其他`Hadoop`文件系统的客户端挂载表。通常用于为联邦`namenode`创建挂载点 |
| **FTP** | **ftp** | **fs.ftp.FTPFileSystem** | 由`FTP`服务器支持的文件系统 |
| S3 | S3a | fs.s3a.S3AFileSystem | 由`Amazon S3`支持的文件系统。替代老版本的`s3n`（`S3`原生）实现 |
| Azure | wasb | fs.azure.NativeAzureFileSystem | 由`Microsoft Azure`支持的文件系统 |
| Swift | swift | fs.swift.snative.SwiftNativeFileSystem | 由`OpenStack  Swift`支持的文件系统 |

尽管运行的`MapReduce`程序可以访问任何文件系统（有时也很方便），但在处理大数据集时，**建议你还是选
择一个有数据本地优化的分布式文件系统，如`HDFS`**。

### 接口
`Hadoop`是用`Java`写的，通过`Java API`可以调用大部分`Hadoop`文件系统的交互操作。例如，文件
系统的命令解释器就是一个`Java`应用，它使用`Java`的`FileSystem`类来提供文件系统操作。其他一些
文件系统接口也将在本小节中做简单介绍。这些接口通常与`HDFS`一同使用，因为`Hadoop`中的其它文件系统
一般都有访问基本文件系统的工具（对于`FTP`，有`FTP`客户端；对于`S3`，有`S3`工具，等等），但它们
大多数都能用于任何`Hadoop`文件系统。

#### 1.HTTP
`Hadoop`以`Java API`的形式提供文件系统访问接口，非`Java`开发的应用访问`HDFS`会很不方便。**由
`WebHDFS`协议提供的`HTTP REST API`则使得其他语言开发的应用能够更方便地与`HDFS`交互**。注意，
**`HTTP`接口比原生的`Java`客户端要慢，所以不到万不得已，尽量不要用它来传输特大数据**。

通过`HTTP`来访问`HDFS`有 **两种方法：直接访问**，`HDFS`守护进程直接服务于来自客户端的`HTTP`
请求；**通过代理（一个或多个）访问**，客户端通常使用`DistributedFileSystem API`访问`HDFS`。
因为这种接口使用较少，所以不做详细的说明了。

#### 2.C语言
`Hadoop`提供了一个名为`libhdfs`的`C`语言库，该语言库是`Java FileSystem`接口类的一个镜像（
它被写成访问`HDFS`的`C`语言库，但其实它可以访问任何一个`Hadoop`文件系统）。它使用`Java`原生接
口（`JNI`，`Java Native Interface`）调用`Java`文件系统客户端。同样还有一个`libwebhdfs`库，
该库使用了前述章节描述的`WebHDFS`接口。

这个`C`语言`API`与`Java`的`API`非常相似，**但它的开发滞后于`Java API`，因此目前一些新的特性可能
还不支持**。

#### 3.NFS
使用`Hadoop`的 **`NFSv3`网关** 将`HDFS`挂载为本地客户端的文件系统是可行的。然后你可以使用`Unix`实用
程序（如`ls`和`cat`）与该文件系统交互，上传文件，通过任意一种编程语言调用`POSIX`库来访问文件系统。
由于`HDFS`仅能以追加模式写文件，因此可以往文件末尾添加数据，但不能随机修改文件。




























































ssss
