HDFS的设计
=============================================================================
当数据集的大小超过一台独立的物理计算机的存储能力时，就有必要对它进行分区（`partition`）并存储到若干台单独的计算机上。
管理网络中跨多台计算机存储的文件系统称为 **分布式文件系统（`distributed filesystem`）**。

`Hadoop`自带一个称为 **`HDFS`** 的分布式文件系统，即 **`Hadoop Distributed Filesystem`**。

**`HDFS`以流式数据访问模式来存储超大文件**，运行于商用硬件集群上。
+ **超大文件**：“超大文件”在这里指具有几百`MB`、几百`GB`甚至几百`TB`大小的文件。目前已经有存储`PB`级数据的`Hadoop`集群了。
+ **流式数据访问**：**`HDFS`的构建思路是这样的：一次写入、多次读取是最高效的访问模式**。数据集通常由数据源生成或从数据源复制而来，
接着长时间在此数据集上进行各种分析。**每次分析都将涉及该数据集的大部分数据甚至全部**，因此读取整个数据集的时间延迟比读取第一条记录的
时间延迟更重要。
+ **商用硬件**：`Hadoop`并不需要运行在昂贵且高可靠的硬件上。它是设计运行在 **商用硬件（在各种零售店都能买到的普通硬件）** 的集群上的，
因此至少对于庞大的集群来说，节点故障的几率还是非常高的。**`HDFS`遇到上述故障时，被设计成能够继续运行且不让用户察觉到明显的中断**。

同样，那些不适合在`HDFS`上运行的应用也值得研究。**目前`HDFS`对某些应用领域并不适合**，不过以后可能会有所改进。
+ **低时间延迟的数据访问**：要求低时间延迟数据访问的应用，例如几十毫秒范围，不适合在`HDFS`上运行。记住，**`HDFS`是为高数据吞吐量
应用优化的**，这可能会以提高时间延迟为代价。目前，**对于低延迟的访问需求，`HBase`是更好的选择**。