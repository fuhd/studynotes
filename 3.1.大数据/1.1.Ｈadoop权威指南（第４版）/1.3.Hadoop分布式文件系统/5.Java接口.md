Java接口
===============================================================================
我们要深入探索`Hadoop`的 **`Filesystem`类：它是与`Hadoop`的某一文件系统进行交互的`API`。
虽然我们主要聚焦于`HDFS`实例，即`DistributedFileSystem`**，但总体来说，还是应该集成`Filesystem`
抽象类，并编写代码，使其在不同文件系统中可移植。

### 从Hadoop URL读取数据
**要从`Hadoop`文件系统读取文件，最简单的方法是使用`java.net.URL`对象打开数据流，从中读取数据**。
具体格式如下：
```java
package com.hadoop.hdfs;

import org.apache.hadoop.fs.FsUrlStreamHandlerFactory;
import org.apache.hadoop.io.IOUtils;
import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStream;
import java.io.InputStreamReader;
import java.net.URL;

public class TestHadoopURL {
    static {
        //注释A 
        URL.setURLStreamHandlerFactory(new FsUrlStreamHandlerFactory());
    }
    public static void main(String[] args) {
        InputStream in = null;
        try {
            in = new URL("hdfs://localhost/quangle.txt").openStream();
            BufferedReader reader = new BufferedReader(new InputStreamReader(in));
            reader.lines().forEach(data -> System.out.printf("data: %s\n", data));
        } catch (IOException e) {
            e.printStackTrace();
        } finally {
            IOUtils.closeStream(in);
        }
    }
}
```
**让`java`程序能够识别`Hadoop`的`hdfs URL`方案需要一些额外的工作。这里采用的方法是通过
`FsUrlStreamHandlerFactory`实例调用`java.net.URL`对象的`setURLStreamHandlerFactory()`
方法**，见上面的代码注释A。
















































sss
