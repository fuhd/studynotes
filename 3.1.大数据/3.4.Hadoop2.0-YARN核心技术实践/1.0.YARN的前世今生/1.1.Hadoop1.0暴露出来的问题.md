Hadoop1.0暴露出来的问题
================================================================================
## 1.存在单点故障、影响可扩展性、稳定性
**Hadoop1.0中Namenode和JobTracker设计成单一节点，一旦该节点出现故障，对整个系统有致命性影响**。
这个节点是整个系统的单点故障源（SPOF），严重制约了整个Hadoop的可扩展性和可靠性。Datanode定期
向Namenode发送Block Report，这些数据是占用内存空间的，随着Hadoop集群存储空间的增多，这些Block
Report也会越来越多，因此，Namenode的内存容量成为制约Hadoop集群规模的一个重要因素。JobTracker
也存在同样的问题，由于随着JobTracker业务的增长，处理的任务也随之增长，从而造成内存消耗过大，同
时任务失败的概率也随之增加。

## 2.计算模式比较单一，只支持MapReduce模式
**Hadoop1.0中对计算模式的支持比较单一，只支持MapReduce模式**。然而，实现业务处理却存在多种需求。
例如需要对实时业务进行及时处理，于是产生了Storm，Spark系统；需要对具有工作流性质的业务进行处理，
于是产生了Tez项目，能够提供更底层的DAG编程接口；需要基于图业务性质进行处理，于是产生了Giraph图
计算项目。这些系统的产生是对MapReduce模式的有效补充。

## 3.Map和Reduce模式绑定太死，不灵活
**在Hadoop1.0最初设计的时候，Map和Reduce是作为一个整体来提供给用户使用的**。然后，并不是每个
业务都同时需要这两人个操作，有的时候只需要其中之一。然而，现有机制中TaskTracker会把任务分成Map 
Task Slot和Reduce Task Slot，如果当前节点仅存在Map Task或者Reduce Task，则会造成资源浪费。

## 4.资源管理方案不灵活
**Hadoop1.0中采用静态slot资源分配策略，在节点启动前为每个节点配置好slot总数，一量启动后，就不
能动态更改**。此外，Hadoop1.0中将slot分为Map slot和Reduce slot两种，且不允许交换共享。而节
点在真实运行情况下往往是Map slot紧张而Reduce slot空闲，或者反之。在任务紧张的时候很大地阻碍了
Hadoop的性能。再者，Hadoop默认情况下是按照2GB内存和1个CPU来为每个slot分配资源，如果task使用
内存过多（如5G），则很可能把节点撑爆。如果task使用内存过小（如1G），又可能造成资源浪费。而且对
资源的描述比较单一，只是从CPU和内存数量进行描述，实际上影响任务的资源还有很多，例如带宽、传输速
度、存储空间等。




