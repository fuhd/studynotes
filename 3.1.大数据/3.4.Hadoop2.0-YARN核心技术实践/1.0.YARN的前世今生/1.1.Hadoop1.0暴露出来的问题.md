Hadoop1.0暴露出来的问题
================================================================================
## 1.存在单点故障、影响可扩展性、稳定性
**Hadoop1.0中Namenode和JobTracker设计成单一节点，一旦该节点出现故障，对整个系统有致命性影响**。
这个节点是整个系统的单点故障源（SPOF），严重制约了整个Hadoop的可扩展性和可靠性。Datanode定期
向Namenode发送Block Report，这些数据是占用内存空间的，随着Hadoop集群存储空间的增多，这些Block
Report也会越来越多，因此，Namenode的内存容量成为制约Hadoop集群规模的一个重要因素。JobTracker
也存在同样的问题，由于随着JobTracker业务的增长，处理的任务也随之增长，从而造成内存消耗过大，同
时任务失败的概率也随之增加。

## 2.计算模式比较单一，只支持MapReduce模式
**Hadoop1.0中对计算模式的支持比较单一，只支持MapReduce模式**。然而，实现业务处理却存在多种需求。
例如需要对实时业务进行及时处理，于是产生了Storm，Spark系统；需要对具有工作流性质的业务进行处理，
于是产生了Tez项目，能够提供更底层的DAG编程接口；需要基于图业务性质进行处理，于是产生了Giraph图
计算项目。这些系统的产生是对MapReduce模式的有效补充。

## 3.Map和Reduce模式绑定太死，不灵活
**在Hadoop1.0最初设计的时候，Map和Reduce是作为一个整体来提供给用户使用的**。然后，并不是每个
业务都同时需要这两人个操作，有的时候只需要其中之一。然而，现有机制中TaskTracker会把任务分成Map 
Task Slot和Reduce Task Slot，如果当前节点仅存在Map Task或者Reduce Task，则会造成资源浪费。

## 4.资源管理方案不灵活
**Hadoop1.0中采用静态slot资源分配策略，在节点启动前为每个节点配置好slot总数，一量启动后，就不
能动态更改**。此外，Hadoop1.0中将slot分为Map slot和Reduce slot两种，且不允许交换共享。而节
点在真实运行情况下往往是Map slot紧张而Reduce slot空闲，或者反之。在任务紧张的时候很大地阻碍了
Hadoop的性能。再者，Hadoop默认情况下是按照2GB内存和1个CPU来为每个slot分配资源，如果task使用
内存过多（如5G），则很可能把节点撑爆。如果task使用内存过小（如1G），又可能造成资源浪费。而且对
资源的描述比较单一，只是从CPU和内存数量进行描述，实际上影响任务的资源还有很多，例如带宽、传输速
度、存储空间等。

```
关于slot

首先，slot不是CPU的Core，也不是memory chip，它是一个逻辑概念，一个节点的slot的数量用来表示某个节点的资源的容量或者说
是能力的大小，因而slot是Hadoop的资源单位。

Hadoop利用slots来管理分配节点的资源。每个Job申请资源以slots为单位，每个节点会确定自己的计算能力以及memory，确定自己包
含的slots总量。当某个Job要开始执行时，先向JobTracker申请slots，JobTracker分配空闲的slots，Job再占用slots，Job结
束后，归还slots。每个TaskTracker定期通过心跳(hearbeat)与Jobtracker通信，一方面汇报自己当前工作状态，JobTracker得
够某个TaskTracker是否Alive；同时汇报自身空闲slots数量。JobTracker利用某个调度规则，如Hadoop默认调度器FIFO或者
Capacity Scheduler、FairScheduler等。

Hadoop里有两种slots，map slots和reduce slots，map task使用map slots，一一对应，reduce task使用reduce slots。
现在越来越多的观点认为应该打破map slots与 reduce slots的界限，应该被视为统一的资源池，they are all resource，从
而提高资源的利用率。区分map slots和reduce slots，容易导致某一种资源紧张，而另一个资源却有空闲。在Hadoop的下一代框架
MapR中，已经取消了map slots与reduce slots的概念，并将Jobtracker的功能一分为二，用ResourceManager来管理节点资源，
用ApplicationMaster来监控与调度作业。ApplicationMaster是每个Application都有一个单独的实例，application是用户提交
的一任务，它可以是一个或多个job的任务组成。（这段描述应该还是基于Hadoop1.0的）
```




