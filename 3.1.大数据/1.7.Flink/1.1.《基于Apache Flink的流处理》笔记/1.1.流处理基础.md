流处理基础
================================================================================
## 1.Dataflow编程概述

### 1.1.Dataflow图
**Dataflow** 程序通常表示为 **有向图**。图中 **顶点称为算子，表示计算；而边表示数据依赖关系**。
算子是Dataflow程序的基本功能单元，它们从输入获取数据，对其进行计算，然后产生数据并发往输出以供后
续处理。**没有输入端的算子称为数据源，没有输出端的算子称为数据汇。一个Dataflow图至少要有一个数
据源和一个数据汇**。如下图展示了一个从推文输入流中提取并统计主题标签的Dataflow程序。

![推文分析程序](img/6.png)

类似上图的Dataflow图被称作 **逻辑图**，因为它们表达了高层视角下的计算逻辑。为了执行Dataflow程
序，需要将逻辑图转化为 **物理Dataflow图**，后都会指定程序的执行细节。下图展示了上图中逻辑图所对
应的物理Dataflow图。**在逻辑Dataflow图中，顶点代表算子；在物理Dataflow图中，顶点代表任务**，
”抽取主题标签“和”计数“算子都包含两个并行算子任务，每个任务负责计算一部分输入数据。

![推文分析程序2](img/7.png)

## 1.2.数据并行与任务并行
Dataflow图的并行性可以通过多种方式加以利用。首先，**你可以将输入数据分组，让同一操作的多个任务
并行执行在不同数据子集上，这种并行称为数据并行**。数据并行非常有用，因为它能够将计算负载分配到多
个节点上从而允许处理大规模的数据。再者，**你可以让不同算子的任务（基于相同或不同的数据）并行计算，
这种并行称为任务并行**。通过任务并行，可以更好地利用集群的计算资源。

## 1.3.数据交换策略
**数据交换策略定义了如何将数据项分配给物理Dataflow图中的不同任务。这些策略可以由执行引擎根据算
子的语义自动选择，也可以由Dataflow编程人员显式指定**。如下图：

![数据交换策略](img/8.png)

+ **转发策略（`forward strategy`）在发送端任务和接收端任务之间一对一地进行数据传输。如果两端
任务运行在同一物理机器上（通常由任务调度器决定），该交换策略可以避免网络通信**。
+ **广播策略（`broadcast strategy`）会把每个数据项发往下游算子的全部并行任务。该策略会把数据
复制多份且涉及网络通信，因此代价十分昂贵**。
+ **基于键值的策略（`key-based strategy`）根据某一键值属性对数据分区，并保证键值相同的数据项
会交由同一任务处理。**
+ **随机策略（`random strategy`）会将数据均匀分配至算子的所有任务，以实现计算任务的负载均衡**。

## 2.并行流处理
数据流中的事件可以表示监控数据、传感器测量值、信用卡交易、气象站观测数据、在线用户交互、以及网络
搜索等。本节你将学到 **如何利用Dataflow编程范式并行处理无限数据流**。

### 2.1.延迟和吞吐
对 **批处理应用** 而言，我们通常会关心 **作业的总执行时间**，或者说处理引擎读取输入、执行计算、
写回结果总共需要多长时间。但由于流式应用会持续执行且输入可能是无限的，所以在数据流处理中没有总执
行时间的概念。取而代之的是，**流式应用** 需要针对到来数据尽可能快地计算结果，同时还要应对很高的
事件接入速率，**我们用延迟和吞吐来表示这两方面的性能需求**。

#### 延迟
**延迟表示处理一个事件所需的时间。本质上，它是从接收事件到在输出中观察到事件处理效果的时间间隔**。
在流处理中，延迟是以时间片（例如毫秒）为单位测量的。根据应用的不同，你可能会关注平均延迟、最大延
迟或延迟的百分位数值。例如，平均延迟为10毫秒表示平均每条数据会在10毫秒内处理；而第95百分位延迟在
10毫秒意味着95%的事件会在10毫秒内处理。

保证低延迟对很多流式应用（例如：诈骗识别、系统告警、网络监测等）而言至关重要。**低延迟是流处理的
一个关键特性，它滋生出了所谓的实时应用。像Apache Flink这样的现代化流处理引擎可以提供低至几毫秒
的延迟**。真正的流模型中，事件一到达系统就可以进行处理，延迟会更加真实地反映出每个事件都要经历的
实际处理工作。

#### 吞吐 
**吞吐是用来衡量系统处理能力（处理速率）的指标**。它告诉我们系统每单位时间可以处理多少事件。**通
常情况下延迟是越低越好，而显然吞吐则是越高越好**。吞吐的衡量方式是计算每个单位时间的事件或操作数。
位要注意，处理速率取决于数据到来速率，因此吞吐低不一定意味着性能差。在流处理系统中，你通常希望系
统有能力应对以最大期望速率到来的事件。换言之，**首要的关注点是确定峰值吞吐，即系统满负载时的性能
上限。如果系统持续以力不能及的高速率接收数据，那么缓冲区可能会用尽，继而可能导致数据丢失。这种情形
通常被称为背压（`backpressure`）**，我们有多种可选策略来处理它。

#### 延迟与吞吐
**延迟与吞吐并非相互独立的指标**。如果事件在数据处理管道中传输时间太久，我们将难以确保高吞吐；同
样，如果系统性能不足，事件很容易堆积缓冲，必须等待一段时间才能处理。

### 2.2.数据流上的操作 










## 3.时间语义


















## 4.状态和一致性模型
