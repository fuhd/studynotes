设置Apache Flink开发环境
================================================================================
## 1.所需软件
基于类Unix系统会享有最丰富的工具支持，因为大多数Flink开发人员都偏爱这类环境。我们假设本章其余部
分介绍的设置都是基于类Unix系统来完成。

Flink DataStream API支持Java和Scala语言，因此在写DataStream应用前需要安装Java JDK8或更高
版本（只有Java JRE是不够的）。

此外，虽不强制，但我们假设以下软件也已装好：
+ Apache Maven3.X版本。
+ 用于Java/Scala开发的IDE。这里我们使用：IntelliJ IDEA。它需要相应安装一些插件（例如Maven
插件、Git插件及Scala插件）。

## 2.在IDE中运行和调试Flink程序
尽管Flink是一个分布式的数据处理系统，**但你通常可以在本地机器上进行开发并运行一些初始测试**。这
让开发过程变得更容易，也让集群部署更简单，因为你 **可以在不对代码进行任何修改的情况下直接切换到集
群环境中运行**。

### 2.1.在IDE中导入书中示例
书中的示例代码托管在GitHub上。在本书的GitHub页面上，你会看到两个分别包含Scala示例和Java示例的
代码仓库。我们将选用Scala仓库进行设置。

打开终端运行以下Git命令将examples-scala库克隆到你的机器上：
```shell
git clone https://github.com/streaming-with-flink/examples-scala
```
书中的示例都是以Maven项目的形式出现。你可以在`src/`目录中找到按照章节组织的源代码。

### 2.2.在IDE中运行Flink程序 
下一步让我们尝试在IDE里运行书中的一个示例程序。找到`AverageSensorReadings`类，打开它。我们
第1章的“Flink快览”中讲过，**这个程序会模拟生成多个多传感器的读数事件，将其中的温度由华氏度改为
摄氏 度，然后计算每个传感器每秒的平均温度。程序的结果会写到标准输出**。和大多数DataStream应用
一样，该程序的数据源、数据汇以及其他算子都是在`AverageSensorReadings`类的`main()`方法中进
行组装的。

直接运行`main()`方法就能启动应用。程序的输出会写到你IDE的标准输出（或控制台）窗口。一旦所有任务 
启动起来并开始运行，程序就会开始生成类似下面的这样的结果：
```
4> SensorReading(sensor_32,1605441417000,1.1814500737638118)
3> SensorReading(sensor_34,1605441417000,12.288397077605124)
1> SensorReading(sensor_38,1605441417000,12.698114607845845)
3> SensorReading(sensor_37,1605441417000,23.799252862361968)
.....
```
如果不手动终止，这个程序会不停生成新的事件、对它们进行处理并每秒产生新的结果。

接下来我们快速看一下程序内部发生了什么。**Flink应用会提交至`JobManager（master）`，后者负责
将需要执行的任务分配给一个或多个`TaskManager（worker）`。Flink作为一个分布式系统，其JobManager
和TaskManager一般会在不同机器上作为独立的JVM进程运行**。

**通常情况下程序的`main()`方法会把Dataflow组装好，然后在`StreamExecutionEnvironment.execute()`
方法被调用时将其提交到远程的`JobManager`上**。

**但除此之外还有一种执行模式。当程序的`execute()`方法被调用时，会在同一个JVM中以独立线程的方式
启动一个`JobManager`线程和一个`TaskManager`（默认的处理槽数等于CPU的线程数）。这样整个Flink
应用会以多线程的方式在同一个JVM进程中执行。该模式可用于在IDE中执行Flink应用**。

## 3.在IDE中调试Flink程序 
由于单JVM执行模式的存在，你可以像调试其他程序那样在IDE中调试Flink应用，如同往常一般，在代码里设
置断点、开启调试。

但在调试时需要注意以下几点：
+ **除非手工指定并行度，否则程序的线程数会和你开发机器的CPU线程数一样多**，所以你应该做好调试多
线程程序的准备。
+ 与把Flink程序发送到远程JobManager执行相比，**将程序放在单个JVM进程中执行可能会导致某些问题
（例如类加载）无法正确调试**。
+ **虽然程序运行在单个JVM内，但出于跨线程通信和潜在的状态持久化需求考虑，记录都会被序列化**。

## 4.创建Flink Maven项目
将`examples-scala`库导入IDE来体验Flink是一个良好的开端。但同时你也要掌握如何从头开始创建一个
新的Flink项目。

Flink提供了Maven模板来为Java或Scala的Flink应用生成Maven项目。你可以打开终端运行以下命令来创
建Flink Maven Quickstart Scala项目，并以它为基础开发Flink应用：
```shell
mvn archetype:generate                                              \
    -DarchetypeGroupId=org.apache.flink                             \
    -DarchetypeArtifactId=flink-quickstart-scala                    \
    -DarchetypeVersion=1.7.1                                        \
    -DgroupId=org.apache.flink.quickstart                           \
    -DartifactId=flink-scala-project                                \
    -Dversion=0.1                                                   \
    -Dpackage=org.apache.flink.quickstart                           \
    -DinteractiveMode=false
```
**上述命令会在`flink-scala-project`文件夹内生成一个Flink 1.7.1版本的Maven项目。你可以通过
改变`mvn`命令的相应参数来更改Flink版本、Maven的组标识符和项目标识符、项目版本以及生成的包。生成 
的文件夹内包含了一个`src/`目录和一个`pom.xml`文件**。`src/`目录的结构如下：
```

├── pom.xml
└── src
    └── main
        ├── resources
        │   └── log4j.properties
        └── scala
            └── org
                └── apache
                    └── flink
                        └── quickstart
                            ├── BatchJob.scala
                            └── StreamingJob.scala
```
你可以使用项目生成的两个框架文件`BatchJob.scala`和`StreamingJob.scala`，作为你程序的起点。
如果不需要，也可以将它们删除。

此时，你可以按照我们在上一节介绍的步骤把项目导入IDE，也可以执行以下命令来构建一个JAR文件。
```shell
mvn clean package -Pbuild-kar
```
如果命令成功完成，你会在项目目录里看到一个新的`target`文件夹。该文件夹里会有一个
`flink-scala-project-0.1.jar`文件，也就是你Flink应用打成的JAR包生成的`pom.xml`文件里还包
含一些如何往项目中添 中其他依赖的说明。

