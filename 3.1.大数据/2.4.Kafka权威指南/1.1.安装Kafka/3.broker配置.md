broker配置
===================================================================================
**Kafka发行包里自带的配置样本可以用来安装单机服务**，但并不能满足大多数安装场景的要求。Kafka有很多
配置选项，涉及安装和调优的方方面面。不过大多数调优选项可以使用默认配置，除非你对调优有特别的要求。

## 1.常规配置
有一些配置选项，在单机安装时可以直接使用默认值，但在部署到其他环境时要格外小心。这些参数是单个服务
器最基本的配置，**它们中的大部分需要经过修改后才能用在集群里**。

### 1.1.broker.id
**每个broker都需要有一个标识符，使用`broker.id`来表示。它的默认值是`0`，也可以被设置成其他任意整数。
这个值在整个Kafka集群里必须是唯一的**。这个值可以任意选定，如果出于维护的需要，可以在服务器节点间交
换使用这些ID。**建议把它们设置成与机器名具有相关性的整数**，这样在进行维护时，将ID号映射到机器名就
没有那么麻烦了。例如，如果机器名包含唯一性的数字（比如`host1.example.com`、`host2.example.com`、
`host3.example.com`），那么用这些数字来设置broker.id就再好不过了。

### 1.2.port
**如果使用配置样本来启动Kafka，它会监听9092端口**。修改port配置参数可以把它设置成其他任意可用的端
口。**要注意，如果使用1024以下的端口，需要使用root权限启动Kafka，不过不建议这么做**。

### 1.3.zookeeper.connect
**用于保存broker元数据的Zookeeper地址是通过zookeeper.connect来指定的**。`localhost:2181`表示这
个Zookeeper是运行在本地的2181端口上。**该配置参数是用冒号分隔的一组hostname:port/path列表**，每
一部分的含义如下：
+ `hostname`是Zookeeper服务器的机器名或IP地址；
+ `port`是可选的Zookeeper的客户端连接端口；
+ `/path`是可选的Zookeeper路径，作为Kafka集群的`chroot`环境。如果不指定。默认使用根路径；

**如果指定的chroot路径不存在，broker会在启动的时候创建它**。
```
什么是chroot路径？

chroot，即 change root directory (更改 root 目录)。在 linux 系统中，系统默认的目录结构都是以 /，即以根 (root) 开始的。而在使用
chroot 之后，系统的目录结构将以指定的位置作为 / 位置。

为什么使用chroot路径？

在Kafka集群里使用chroot路径是一种最佳实践。Zookeeper群组可以共享给其他应用程序，即使还有其他Kafka集群存在，也不会产生
冲突。最好是在配置文件里指定一组Zookeeper服务器。用分号把它们隔开。一旦有一个Zookeeper服务器宕机，broker可以连接到
Zookeeper群组的另一个节点上。
```

### 1.4.log.dirs
**Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过`log.dirs`指定的。它是一组用逗号分隔的
本地文件系统路径**。如果指定了多个路径，那么broker会根据“**最少使用**”原则，**把同一个分区的日志
片断保存到同一个路径下。要注意，broker会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间
的路径新增分区**。

### 1.5.num.recovery.threads.per.data.dir
对于如下3种情况，**Kafka会使用可配置的线程池来处理日志片段**：
+ **服务器正常启动，用于打开每个分区的日志片段**；
+ **服务器崩溃后重启，用于检查和截短每个分区的日志片段**；
+ **服务器正常关闭，用于关闭日志片段**；

**默认情况下，每个日志目录只使用一个线程**。因为这些线程只是在服务器启动和关闭时会用到，所以完全
**可以设置大量的线程来达到并行操作的目的。特别是对于包含大量分区的服务器来说，一旦发生崩溃，在进行
恢复时使用并行操作可能会省下数小时的时间。设置此参数时需要注意，所配置的数字对应的是`log.dirs`指定
的单个日志目录**。也就是说，**如果`num.recovery.threads.per.data.dir`被设置为8，并且`log.dirs`指定了
3个路径，那么总共需要24个线程**。

### 1.6.auto.create.topics.enable
**默认情况下**，Kafka会在如下几种情形下 **自动创建主题**：
+ **当一个生产者开始往主题写入消息时**；
+ **当一个消费者开始从主题读取消息时**；
+ **当任意一个客户端向主题发送元数据请求时**；

很多时候，这些行为都是非预期的。而且，根据Kafka协议，如果一个主题不先被创建，根本无法知道它是否已
经存在。**如果显式地创建主题，不管是手动创建还是通过其他配置系统来创建，都可以把
`auto.create.topics.enable`设为false**。

## 2.主题的默认配置
**Kafka为新创建的主题提供了很多默认配置参数。可以通过管理工具为每个主题单独配置一部分参数**，比如
分区个数和数据保留策略。服务器提供的默认配置可以作为基准，它们适用于大部分主题。
```
使用主题配置覆盖（overrride）

之前的Kafka版本允许主题覆盖服务器的默认配置，包括log.retention.hours.per.topic、log.retention.bytes.per.topic和
log.segment.bytes.per.topic这几个参数。新版本不再支持这些参数，而且如果要对参数进行覆盖，需要使用管理工具。
```

### 2.1.num.partitions
**`num.partitions`参数指定了新创建的主题将包含多少个分区。如果启用了主题自动创建功能（该功能默认是
启用的），主题分区的个数就是该参数指定的值。该参数的默认值是1。要注意，我们可以增加主题分区的个数，
但不能减少分区的个数。所以，如果要让一个主题的分区个数少于`num.partitions`指定的值，需要手动创建该
主题**。
```
如何选定分区数量

为主题选定分区数量并不是一件可有可无的事情，在进行数量选择时，需要考虑如下几个因素：
+ 主题需要达到多大的吞吐量？例如，是希望每秒钟写入100KB还是1GB？
+ 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费者，如果你知道消费者将数据写入数据库的速度不会超过每秒钟50MB，

```













