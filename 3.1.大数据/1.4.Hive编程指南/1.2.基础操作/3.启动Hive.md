启动Hive
=================================================================================
终于我们可以从Hive命令行界面（CLI）开始执行一些命令了。

在后面的会话中，我们将使用 **$HIVE_HOME/bin/hive** 命令，这是个bash shell脚本 ，用于启动CLI。
下面脚本中出现的$HIVE_HOME可以根据需要替换为用户的Hive安装目录路径。**如果用户已经将$HIVE_HOME/bin
加入到环境变量PATH中了，那么只需要输入hive就可以执行命令了**。

和以前一样，$是bash提示符。**在Hive CLI中，字符串hive>是Hive的提示符，而大于号 > 是第2个提示符**。

### 第一步：Hive配置Hadoop HDFS

#### 新建hive-site.xml
**最好不要复制hive-default.xml.template文件，新建一个空文件**。
```shell
$ cd /opt/apache-hive-2.3.2/conf
$ touch hive-site.xml
```

#### 新建hdfs目录
使用hadoop新建hdfs目录,因为在 **hive-default.xml.template** 中有默认如下配置：
```xml
<property>
    <name>hive.metastore.warehouse.dir</name>
    <value>/user/hive/warehouse</value>
    <description>location of default database for the warehouse</description>
</property>
```
进入hadoop安装目录，**执行hadoop命令新建/user/hive/warehouse目录，并授权**，用于存储文件：
```shell
$ cd /opt/hadoop-2.9.0

$ hadoop fs -mkdir -p /user/hive/warehouse  
$ hadoop fs -mkdir -p /tmp  
$ hadoop fs -chmod -R g+w /user/hive/warehouse  
$ hadoop fs -chmod -R g+w /tmp
```
用以下命令检查目录是否创建成功：
```shell
$ hadoop fs -ls /user/hive
```
#### 修改hive-site.xml
```xml
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<configuration>
<!-- 修改下面的配置，对于derby数据库来说，url用绝对路径，要不然只能去数据库所在目录下执行 -->
<!-- 注意：给/opt/hive-derby目录应有的权限 -->
    <property>
        <name>javax.jdo.option.ConnectionURL</name>
        <value>jdbc:derby:;databaseName=/opt/hive-derby/metastore_db;create=true</value>
    </property>
</configuration>
```

### 第二步：初始化schema
当前默认使用的是derdy数据库，所以使用如下命令：
```shell
# 初始化,如果是mysql则derby可以直接替换成mysql
$ schematool -initSchema -dbType derby
```
```
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.2/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.9.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]
Metastore connection URL:	 jdbc:derby:;databaseName=metastore_db;create=true
Metastore Connection Driver :	 org.apache.derby.jdbc.EmbeddedDriver
Metastore connection User:	 APP
Starting metastore schema initialization to 2.3.0
Initialization script hive-schema-2.3.0.derby.sql
Initialization script completed
schemaTool completed
```

### 第三步：创建表、执行语句
这里有个样例会话：
```shell
$ hive
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/opt/apache-hive-2.3.2/lib/log4j-slf4j-impl-2.6.2.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/opt/hadoop-2.9.0/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.apache.logging.slf4j.Log4jLoggerFactory]

Logging initialized using configuration in jar:file:/opt/apache-hive-2.3.2/lib/hive-common-2.3.2.jar!/hive-log4j2.properties Async: true
Hive-on-MR is deprecated in Hive 2 and may not be available in the future versions. Consider using a different execution engine (i.e. spark, tez) or using Hive 1.X releases.
hive>
```
注： 日志上说，**Hive 2中配置Hive-on-MR是过时的，要求使用spark、tez作为计算引擎**。

如果直接执行代码：
```shell
hive> CREATE TABLE x (a INT);
OK
Time taken: 0.48 seconds

hive> SELECT * FROM x;
OK
Time taken: 1.345 seconds

hive> SELECT *
    > FROM x;
OK
Time taken: 0.14 seconds

hive> DROP TABLE x;
OK
Time taken: 1.346 seconds

hive> exit;
$
```
```
提示：
我们将按照SQL民惯例使用大写字母显示Hive的关键字（例如：CREATE、TABLE、SELECT和FROM），尽管在Hive中关键字是大小写无关的，
这也和SQL的惯例是一致的。
```
通过上面一系列连续的提示符，我们创建了一个简单的表，表名是x，包含有一个名为a的INT（4字节整型）类型
字段，然后对这个表查询了2次，第2次查询是为了显示查询语句和命令，可以多行输入。最后，我们删除了这个表。

**如果用户使用默认的Derby数据库作为元数据存储的话，那么这时可以注意到在用户当前工作目录下新出现了一
个名为metastore_db的目录，这个目录是在启动Hive会话时由Derby创建的**。

**在用户所在的任意工作目录下都创建一个名为metastore_db的子目录并不方便，因为当用户切换到新的工作目
录下时，Derby会“忘记”在前一个目录下的元数据存储信息**！
```
注意：上面的示例中，metastore_db，我们使用的绝对路径！所以不会有这个问题。具体看下一章节。
```
