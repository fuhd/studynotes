Hadoop和MapReduce综述
=================================================================================
**Hadoop生态系统就是为处理大数据集而产生的一个合乎成本效益的解决方案。Hadoop实现了一个特别的计算
模型，也就是MapReduce，其可以将计算任务分割成多个处理单元然后分散到一群家用的或服务器级别的硬件机
器上，从而降低成本并提供水平可伸缩性**。这个计算模型的下面是一个被称为Hadoop分布式文件系统（**HDFS**）
的分布式文件系统。这个文件系统是“可插拔的”，**而且现在已经出现了几个商用的和开源的替代方案**。

不过，仍然存在一个挑战，那就是用户如何从一个 **现有的数据基础架构转移到Hadoop上**，而这个 **基础架
构是基于传统关系型数据库和结构化查询语句（SQL）的**。对于大量的SQL用户（包括专业数据库设计师和管理员，
也包括那些使用SQL从数据仓库中抽取信息的临时用户）来说，这个问题又将如何解决呢？

这就是Hive出现的原因。**Hive提供了一个被称为Hive查询语言（简称HiveQL或HQL）的SQL方言，来查询存储
在Hadoop集群中的数据**。

SQL知识分布广泛的一个原因是：它是一个可以有效地、合理地且直观地组织和使用数据的模型。即使对于经验丰
富的Java开发工程师来说，将这些常见的数据运算对应到底层的MapReduce Java API也是令人畏缩的。Hive
可以帮助用户来做这些苦活，这样用户就可以集中精力关注于查询本身了。**Hive可以将大多数的查询转换为
MapReduce任务（job）**，进而在介绍一个令人熟悉的SQL抽象的同时，拓宽Hadoop的可扩展性。

**Hive最适合于数据仓库应用程序，使用该应用程序进行相关的静态数据分析，不需要快速响应给出结果，而且
数据本身不会频繁变化**。

**Hive不是一个完整的数据库。Hadoop以及HDFS的设计本身约束和局限性地限制了Hive所能胜任的工作。其中最
大的限制就是Hive不支持记录级别的更新、插入或者删除操作。但是用户可以通过查询生成新表或者将查询结果导
入到文件中**。同时，因为Hadoop是一个面向批处理的系统，而MapReduce任务（job）的启动过程需要消耗较长
的时间，所以Hive查询延时比较严重。**传统数据库中在秒级别可以完成的查询，在Hive中，即使数据集相对较小，
往往也需要执行更长的时间**。最后需要说明的是，**Hive不支持事务**。

因此，**Hive不支持OLTP（联机事务处理）所需的关键功能，而更接近成为一个OLAP（联机分析技术）工具**。
但是我们将会看到，由于Hadoop本身的时间开销很大，并且Hadoop所被设计用来处理的数据规模非常大，因此
提交查询和返回结果是可能具有非常大的延时的，**所以Hive并没有满足OLAP中的“联机”部分，至少目前并没有
满足（不知道现在能不能满足? 编辑于2018.01.04）**。

**如果用户需要对大规模数据使用OLTP功能的话，那么应该选择使用一个NoSQL数据库**，例如，和Hadoop结合
使用的 **HBase** 及 **Cassandra**。用户甚至可以和这些数据库（还包括其他一些数据库）结合来使用
Hive。

因此，**Hive是最适合数据仓库应用程序的**，其可以维护海量数据，而且可以对数据进行挖掘，然后形成意见
和报告等。

因为大多数的数据仓库应用程序是使用基于SQL的关系型数据库实现的，所以Hive降低了将这些应用程序移植到
Hadoop上的障碍。

不过，和大多数SQL方言一样，**HiveQL并不符合ANSI SQL标准**，其和Oracle，MySQL，SQL Server支
持的常规SQL方言在很多方面存在差异（不过，**HiveQL和MySQL提供的SQL方言最接近**）。

### Hadoop和MapReduce综述
虽然 **用户无需精通MapReduce就可以使用Hive**，但是理解MapReduce的基本原理将帮助于用户了解Hive
在底层是如何运行的，以及了解如何才能更高效地使用Hive。

#### MapReduce
**MapReduce是一种计算模型**，该模型可将大型数据处理任务分解成很多单个的、可以在服务器集群中并行
执行的任务。这些任务的计算结果可以合并在一起来计算最终的结果。

MapReduce这个术语来自于 **两个基本的数据转换操作：map过程和reduce过程**。一个 **map操作** 会将
集合中的元素从一种形式转换成另一种形式。在这种情况下，**输入的键/值对会被转换成零到多个键/值对输出**。
其中，**输入和输出的键必须完全不同，而输入和输出的值则可能完全不同**。

在MapReduce计算框架中，**某个键的所有键/值对都会被分发到同一个reduce操作中**。确切地说，**这个键
和这个键所对应的所有值都会被传递给同一个Reduce**。reduce过程的目的是 **将值的集合转换成一个值（例
如对一组数值求和或求平均值），或者转换成另一个集合。这个Reduce最终会产生一个键/值对**。再次说明一下，
**输入和输出的键和值可能是不同的**。需要说明的是，**如果job不需要reduce过程的话，那么也是可以无
reduce过程的**。

Hadoop提供了一套基础设施来处理大多数困难的工作以保证任务能够执行成功。例如，Hadoop决定如何将提交
的job分解成多个独立的map和reduce任务（task）来执行，**它就会对这些task进行调度并为其分配合合适
的资源，决定将某个task分配到集群中哪个位置（如果可能，通常是这个task所要处理的数据所在的位置，这
样可以最小化网络开销）。它会监控每一个task以确保其成功完成，并重启一些失败的task**。

Hadoop分布式文件系统（也就是HDFS），或者一个同类的分布式文件系统，管理着集群中的数据。**每个数据块
（block）都会被冗余多份（通常默认会冗余3份），这样可以保证不会因单个硬盘或服务器的损坏导致数据丢失**。
同时，因为其目标是优化处理非常大的数据集，所以HDFS以及类似的文件系统所使用的数据块都非常大，通常是
64MB（**Hadoop2.0后，默认是128MB**）或是这个值的若干倍。**这么大的数据块可以在硬盘上连续进行存储，
这样可以保证以最少的磁盘寻址次数来进行写入和读取，从而最大化提高读写性能**。
