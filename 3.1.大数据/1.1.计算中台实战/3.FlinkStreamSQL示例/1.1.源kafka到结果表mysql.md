源kafka到结果表mysql
================================================================================
该示例是一个流计算的示例（Flink示例）。从Kafka中读取数据与MySQL中的维表进行关联分析，然后把结
果输出到MySQL中。

## 1. FlinkStreamSQL代码
```sql
-----------------------------------------------------------------
---------------------- 当前示例测试数据实时存储 ---------------------
-----------------------------------------------------------------

-- 数据源表（学生表），数据从Kafka中来
CREATE TABLE Student(
    name VARCHAR,
    age INT,
    sex INT,
    myClass VARCHAR
)WITH(
    type ='kafka',
    bootstrapServers ='bigdata001:9092,bigdata002:9020,bigdata003:9020',
    zookeeperQuorum ='bigdata001:2181/kafka,bigdata002:2181/kafka,bigdata003:2181/kafka',
    offsetReset ='latest',
    topic ='topic01',
    parallelism ='3',
    sourcedatatype ='json'
);
 
-- mysql中的维表，定义一个全量维表(班级表)
CREATE TABLE Class(
    id INT,
    class VARCHAR,
    PRIMARY KEY(class) ,
    PERIOD FOR SYSTEM_TIME
)WITH(
    type = 'mysql',
    url ='jdbc:mysql://bigdata001:3306/test',
    userName ='root',
    password ='MyPass68@',
    tableName ='class01',
    cache ='ALL',
    cacheTTLMs ='60000',
    parallelism ='1'
);
 
-- mysql中的结果表，统计结果表
CREATE TABLE Result02(
    num BIGINT,
    class VARCHAR,
    primary key (class)
)WITH(
    type ='mysql',
    url ='jdbc:mysql://bigdata001:3306/test',
    userName ='root',
    password ='MyPass68@',
    tableName ='result01',
    parallelism ='1',
    batchWaitInterval = '2000',
    allReplace = 'true'
);


-- ETL代码
insert into Result02 select count(s.name) as num, s.myClass as class from Student as s 
    join Class as c on s.myClass = c.class group by s.myClass;
```

## 2. MySQL中的表与操作
```sql
-- 创建维表
create table if not exists `class01`(
    `id` INT AUTO_INCREMENT,
    `class` VARCHAR(10),
    PRIMARY KEY (`id`)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- 创建结果表
create table if not exists `result01`(
    `num` INT,
    `class` VARCHAR(10),
    -- 这里要设置主键，写入该结果表时才会是更新而不是插入
    PRIMARY KEY (`class`)
)ENGINE=InnoDB DEFAULT CHARSET=utf8;

-- 插入维表数据
INSERT INTO class01(class) VALUES ('A'),('B'),('C'),('D'),('E');
```

## 3. Kafka的生产者代码
```java
package com.kafka.test;

import org.apache.kafka.clients.producer.KafkaProducer;
import org.apache.kafka.clients.producer.ProducerRecord;
import org.apache.kafka.common.serialization.StringSerializer;

import java.util.Properties;
import java.util.Timer;
import java.util.concurrent.TimeUnit;

public class MyProducer {
    public static void main(String[] args) {
        Properties props = new Properties();
        //kafka服务器地址
        props.put("bootstrap.servers", "bigdata001:9092,bigdata002:9020,bigdata003:9020");
        props.put("key.serializer", StringSerializer.class);
        props.put("value.serializer", StringSerializer.class);
        KafkaProducer<String, String> producer = new KafkaProducer<>(props);
        for (int i = 0; i < 1000; i++) {
            try {
                TimeUnit.SECONDS.sleep(1);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            String name = "stu" + (i + 1);
            Integer age = 22;
            Integer sex = i % 2 == 0 ? 0 : 1;
            String myClass = i % 2 == 0 ? "A" : "B";
            String value = "{\"name\": \"" + name +
                    "\",\"age\":" + age +
                    ",\"sex\":" + sex +
                    ",\"myClass\":\"" + myClass + "\"}";
            System.out.println(value);
            ProducerRecord record = new ProducerRecord("topic01", value);
            producer.send(record);
        }
        producer.close();
    }
}
```

**pom.xml:**
```xml
<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>

    <groupId>org.example</groupId>
    <artifactId>kafka-test</artifactId>
    <version>1.0-SNAPSHOT</version>

    <properties>
        <maven.compiler.source>8</maven.compiler.source>
        <maven.compiler.target>8</maven.compiler.target>
    </properties>

    <dependencies>
        <dependency>
            <groupId>org.apache.kafka</groupId>
            <artifactId>kafka-clients</artifactId>
            <version>2.4.1</version>
        </dependency>
    </dependencies>

    <build>
        <finalName>kafka_test</finalName>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <version>2.4</version>
                <configuration>
                    <archive>
                        <manifest>
                            <addClasspath>true</addClasspath>
                            <classpathPrefix>lib/</classpathPrefix>
                            <mainClass>com.kafka.test.MyProducer</mainClass>
                        </manifest>
                    </archive>
                </configuration>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-dependency-plugin</artifactId>
                <version>2.10</version>
                <executions>
                    <execution>
                        <id>copy-dependencies</id>
                        <phase>package</phase>
                        <goals>
                            <goal>copy-dependencies</goal>
                        </goals>
                        <configuration>
                            <outputDirectory>${project.build.directory}/lib</outputDirectory>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
        </plugins>
    </build>
</project>
```

## 4. Kafka会用到的一些操作
```shell
# 消费数据
bin/kafka-console-consumer.sh --bootstrap-server bigdata001:9092,bigdata002:9092,bigdata003:9092 --from-beginning --topic topic01

# 删除主题命令
bin/kafka-topics.sh --delete --topic topic01 --zookeeper bigdata001:2181,bigdata002:2181,bigdata003:2181

# 查看主题列表
bin/kafka-topics.sh --list --zookeeper bigdata001:2181,bigdata002:2181,bigdata003:2181
```

## 5. 还存在的问题
目前输出到结果表（MySQL）还存在中文乱码的问题！！！