I/O多路复用技术
=======================================
这里我们重点讲一下 **I/O多路复用技术** ，因为 **Java NIO的核心类库多路复用器`Selector`就是基于`epoll`
的多路复用技术实现**。

在I/O编程过程中，当需要同时处理 **多个客户端** 接入请求时，可以利用 **多线程** 或者 **I/O多路复用技术** 进行处理。
**I/O多路复用技术通过把多个I/O的阻塞复用到同一个`select`的阻塞上，从而使用系统在单线程/进程的情况下可以
同时处理多个客户端请求**。与传统的多线程/多进程模型比，I/O多路复用的最大优势是 **系统开销小**，系统不需要创建新
的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源。

I/O多路复用的场景如下：
+ 服务器需要同时处理 **多个处于监听状态或者多个连接状态的套接字**；
+ 服务器需要同时处理 **多种网络协议的套接字**；

目前支持I/O多路复用的系统调用有`select`，`pselect`，`poll`，`epoll`。**在Linux网络编程过程中，
很长一段时间都使用`select`做轮询和网络事件通知，然而`select`的一些固有缺陷导致了它的应用受到了很大的限制，
最终Linux不得不在新的内核版本中寻找`select`的替代方案，最终选择了`epoll`**。`epoll`与`select`的原理比较
类似，为了克服`select`的缺点，`epoll`作了很多重大改进。

### epoll相比select的优点
#### 支持一个进程打开的`socket`描述符（FD）不受限制（仅受限于操作系统的最大文件句柄数）
`select`最大的缺陷就是 **单个进程** 所打开的FD是有一定限制的，它由`FD_SETSIZE`设置，默认值是 **`1024`**。
对于那些需要支持上万个TCP连接的大型服务器来说显然太少了。我们也可以通过选择多进程的方案（传统的Apache方案）
解决这个问题，不过虽然在Linux上创建进程的代价比较小，但仍旧是不可忽视的，另外，进程间的数据交换非常麻烦。
对于Java，由于没有共享内存，需要通过`Socket`通信或者其他方式进行数据同步，这带来了额外的性能损耗，
增加了程序复杂度，所以也不是一种完美的解决方案。值得庆幸的是，`epoll`并没有这个限制，它所支持的FD上限是
操作系统的最大文件句柄数，这个数字远远大于`1024`。例如，在1GB内存的机器上大约是10万个句柄左右，具体的值可以
通过命令：
```powershell
$ cat /proc/sys/fs/file-max
```
察看，通常情况下这个值跟系统内存关系比较大。

#### I/O效率不会随着FD数目的增加而线性下降
传统的`select/poll`另一个致命弱点就是当你拥有一个很大的`socket`集合，由于网络延时或者链路空闲，
任一时刻只有少部分的`socket`是“活跃”的，但是`select/poll`每次调用都会线性扫描全部的集合，
导致效率呈现线性下降。`epoll`不存在这个问题，它只会对“活跃”的`socket`进行操作（这是因为在内核实现
中`epoll`是根据每个`fd`上面的`callback`函数实现的。那么只有“活跃”的`socket`才会主动的去调用`callback`
函数，其它`idle`状态`socket`则不会。在这点上，`epoll`实现了一个伪AIO）。

#### 使用mmap加速内核与用户空间的消息传递
无论是`select`，`poll`还是`epoll`都需要内核把FD消息通知给用户空间，**如何避免不必要的内存复制** 就显得
非常重要，**`epoll`是通过内核和用户空间mmap同一块内存实现的**。

#### epoll的API更加简单
包括创建一个`epoll`描述符，添加监听事件，阻塞等待所监听的事件发生，关闭`epoll`描述符等。
