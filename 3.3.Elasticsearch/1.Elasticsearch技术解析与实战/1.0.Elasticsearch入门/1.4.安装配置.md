安装配置
================================================================================
### 1.安装Java
Elasticsearch需要Java7或者更高版本的支持。建议使用最新的Java8+。（安装略）

### 2.安装Elasticsearch
中国官网: https://www.elastic.co/cn/ ，这里我们主要使用 **elasticsearch2.4.6**。

Elasticsearch是Java开发的，所以JVM的环境变量 **JAVA_OPTS** 对Elasticsearch是非常重要的。
在JAVA_OPTS中对Elasticsearch最重要的参数是　**-Xmx** 最大可以使用内存的参数，一般情况下大内存
更能发挥Elasticsearch作用，**建议-Xmx设置为物理内存的一半，为了减少内存分配带来的性能损耗，最好一
开始就设置初始内存和最大内存都为物理内存的一半，即Xms和Xmx这两个参数**。

由于JAVA_OPTS大多数时候对整个机器环境起作用，**所以最好是保留默认的JAVA_OPTS，最好用ES_JAVA_OPTS
环境变量设置来作为JAVA_OPTS参数**。

### 3.配置
Elasticsearch配置文件在 **elasticsearch/config** 文件夹下。在这个文件夹中有两个文件，一个是
Elasticsearch配置不同模块的配置文件 **elasticsearch.yml**，另一个是Elasticsearch日志的配置文件
**logging.yml**。

**Elasticsearch提供了多种方式进行设置**，在系统内部，都使用 **命名空间** 来表示这些设置，根据这些命
名空间，系统可以很容易地扩展到其他格式。比如我们设置节点名称如下：
1. **yml格式** 为：node.name: node-1
2. **JSON格式** 为：只需要把elasticsearch.yml名修改成elasticsearch.json。配置的方式为：
```json
｛
    “node”: {"name": "node-1"}
 ｝
```
3. 通过Elasticsearch **命令的参数** 来设置配置信息。例如：
```shell
elasticssarch -Ees.node.name=node-1
```
4. Elasticsearch还可以通过 **交互式方式** 进行设置，通过 **${prompt.text}** 或者
**${prompt.secret}** 来指定，**${prompt.secret}表示在终端中隐藏输入的值，${prompt.text}表**
示在终端中显式输入的值。例如：
```yaml
node.name: ${prompt.text}
```
在Elasticsearch命令执行时，将提示你输入的实际值，例如下面的提示：
```
Enter value for ［node.name]：
```
**注：当Elasticsearch作为服务或者在后台启动的时候，这两个参数不起作用**。

#### 3.1.elasticsearch.yml配置说明
**集群名称**：
```yaml
cluster.name: my-application
```
**确保在不同的环境中集群的名称不重复**，否则，节点可能会连接到错误的集群上。

**节点名称**：
```yaml
node.name: node-1
```
**默认情况下**，当节点启动时Elasticsearch将 **随机在一份3000个名字的列表中随机指定一个**。如果
机器上只运行一个集群Elasticsearch节点，可以用 **${HOSTNAME}** 设置节点的名称为主机名。

**节点描述**：
```yaml
node.rack: r1
```

**索引存储位置**：
```yaml
path.data: /path/to/data
```

**日志存储位置**：
```yaml
path.logs: /path/to/logs
```

**内存分配模式**：
```yaml
bootstrap.mlockall: true
```

**绑定的网卡IP**：
```yaml
network.host: 192.168.0.1
```

**http协议端口**：
```yaml
http.port: 9200
```

**开始发现新节点的IP地址**：
```yaml
discovery.zen.ping.unicast.hosts: ["host1", "host2"]
```
**最多发现主节点的个数**：
```yaml
discovery.zen.minimum_master_nodes: 3
```
**当重启集群节点后最少启动N个节点后开始做恢复**:
```yaml
gateway.recover_after_nodes: 3
```
**在一台机器上最多启动的节点数**：
```yaml
node.max_local_storage_nodes: 1
```
**当删除一个索引的时候，需要指定具体索引的名称**：
```yaml
action.destructive_reguires_name: true
```

#### 3.2.索引配置说明
在集群中创建的索引 **可以提供每个索引自己的设置**。例如，下面创建一个索引刷新间隔是5秒钟而不是默认的
刷新间隔（格式可以是YAML或JSON）：

请求：
```
PUT http://127.0.0.1:9200/kimchy
```
参数：
```yaml
index：refresh_interval: 5s
```
**这个索引参数可以设置在节点上**，例如，在 **elasticsearch.yml** 文件中可以设置：
```yaml
index.refresh_interval: 5s
```
这意味着除非索引明确定义，这个节点上创建的每个索引的刷新间隔为5秒。当然也 **可以在启动Elasticsearch的
时候用参数指定**：
```shell
elasticsearch -Des.index.refresh_interval=5s
```

#### 3.3.日志配置说明
Elasticsearch内部使用log4j记录系统日志，它试图通过使用YAML配置方式来简化log4j的配置，**配置文件
位置为elasticsearch/config/logging.yml**。JSON格式和键值对的格式也是支持的。可以加载多个配置
文件，在启动Elasticsearch后系统自动合并多个配置文件。支持不同的后缀格式，例如：（.yml、.yaml、
.json or .properties）。

由于日志比较重要，**正常情况下不要禁止日志的产生**，如果感觉日志过多，可以提高日志的级别。系统日志每
日会生成一个新的文件。

### 4.运行
在Linux下运行：
```shell
$ ./elasticsearch
```
输出：
```
$ ./elasticsearch

[2018-05-09 20:19:45,162][INFO ][node                     ] [Alexander Goodwin Pierce] version[2.4.6], pid[6754], build[5376dca/2017-07-18T12:17:44Z]
[2018-05-09 20:19:45,163][INFO ][node                     ] [Alexander Goodwin Pierce] initializing ...
[2018-05-09 20:19:45,581][INFO ][plugins                  ] [Alexander Goodwin Pierce] modules [reindex, lang-expression, lang-groovy], plugins [], sites []
[2018-05-09 20:19:45,633][INFO ][env                      ] [Alexander Goodwin Pierce] using [1] data paths, mounts [[/ (/dev/sda1)]], net usable_space [56.3gb], net total_space [90.4gb], spins? [possibly], types [ext4]
[2018-05-09 20:19:45,633][INFO ][env                      ] [Alexander Goodwin Pierce] heap size [990.7mb], compressed ordinary object pointers [true]
[2018-05-09 20:19:47,146][INFO ][node                     ] [Alexander Goodwin Pierce] initialized
[2018-05-09 20:19:47,147][INFO ][node                     ] [Alexander Goodwin Pierce] starting ...
[2018-05-09 20:19:47,234][INFO ][transport                ] [Alexander Goodwin Pierce] publish_address {127.0.0.1:9300}, bound_addresses {[::1]:9300}, {127.0.0.1:9300}
[2018-05-09 20:19:47,239][INFO ][discovery                ] [Alexander Goodwin Pierce] elasticsearch/pxDpz-YkSFySSXmByAof3w
[2018-05-09 20:19:50,304][INFO ][cluster.service          ] [Alexander Goodwin Pierce] new_master {Alexander Goodwin Pierce}{pxDpz-YkSFySSXmByAof3w}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2018-05-09 20:19:50,329][INFO ][gateway                  ] [Alexander Goodwin Pierce] recovered [0] indices into cluster_state
[2018-05-09 20:19:50,346][INFO ][http                     ] [Alexander Goodwin Pierce] publish_address {127.0.0.1:9200}, bound_addresses {[::1]:9200}, {127.0.0.1:9200}
[2018-05-09 20:19:50,346][INFO ][node                     ] [Alexander Goodwin Pierce] started
```
当然我们也可以在 **启动的时候修改集群的名称和节点的名称**。例如：
```shell
$ ./elasticsearch -Dcluster.name=mycluster -Dnode.name=mynode
```
**默认情况下，Elasticsearch使用9200端口提供的REST API。该端口是可配置的**。

在本机访问：http://127.0.0.1:9200/ ，将会得到以下内容：
```json
{
  "name" : "Alexander Goodwin Pierce",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "E9Xc8tmBRneftP7hxru-lQ",
  "version" : {
    "number" : "2.4.6",
    "build_hash" : "5376dca9f70f3abef96a77f4bb22720ace8240fd",
    "build_timestamp" : "2017-07-18T12:17:44Z",
    "build_snapshot" : false,
    "lucene_version" : "5.5.4"
  },
  "tagline" : "You Know, for Search"
}
```
Elasticsearch提供了非常全面和强大的REST API，通过这些API，我们可以了解集群的信息。这些API可以
做如下事情：
1. **检查集群、节点和索引的情况、状态和统计**。
2. **管理集群、节点、索引数据和文档数据**。
3. **执行CRUD（创建、读取、更新和删除）操作，可以对索引进行操作**。
4. **执行高级搜索操作，如分页、排序、过滤、脚本、聚合及其他操作**。

### 5.停止
如果需要停止Elasticsearch，有以下两种方法：
+ 如果节点是连接到控制台，按下：**Ctrl＋C**；
+ 杀进程（**Linux是kill**，Windows下用任务管理器）；

由于Elasticsearch常用在集群中，**集群停止相对有些复杂**（参考下一小节）。

### 6.集群重启
1. **关闭分片分配**。当我们试图关闭一个节点的时候，Elasticsearch会立即试图复制这个节点的数据到
集群中的其他节点上。**这将导致大量的IO请求**。在关闭该节点的时候可以通过设置一下参数来避免此问题的
发生：
```json
PUT /_cluster/settings
{
  "transient": {"cluster.routing.allocation.enable": "none"}
}
```
2. **执行一个同步刷新**。当停止一个索引的时候，分片的恢复会很快，所以要进行同步刷新请求。
```
POST /_flush/synced
```
同步刷新请求是非常有效的一种操作，**当任何索引操作失败的时候，可以执行同步刷新请求，必要的时候可以执
行多次**。
3. **停止在集群中的所有节点上的服务**。
4. **启动集群。如果你有专门的主节点（node.master节点设置为true，node.data节点设置为false），
则先启动主节点。等待它们形成一个集群，然后选择一个主数据节点进行启动**。你可以通过查看日志来检查启动
情况。通过下面命令可以监控集群的启动情况，检查所有节点是否已成功加入集群。
```
GET _cat/health
GET _cat/nodes
```
5. **等待黄色集群状态**。当节点加入集群后，它首先恢复存储在本地的主分片数据。最初的时候，通过
**_cat/health** 请求发现集群的状态是 **红色**，意味着 **不是所有的主分片都已分配**。当每个节点都
恢复完成后，集群的状态将会变成 **黄色**，这意味着 **所有主分片已民经被找到**，但是 **并不是所有的副
本分片都恢复**。
6. **重新分配**。延迟副本的分配直到所有节点都加入集群，在集群的所有节点，可以 **重新启用碎片分配**：
```
PUT /_cluster/settings
{
  "persistent": {"cluster.routing.allocation.enable": "all"}
}
```
这个时候集群将开始复制所有副本到数据节点上，这样可以安全地恢复索引和搜索。如果你能延迟索引和搜索直到
所有的分片已经恢复，这样可以加快集群的恢复。可以通过下面API监控恢复的进度和健康情况：
```
GET _cat/health
GET _cat/recovery
```
最后当集群的状态出现 **绿色** 的时候，**表示本次集群升级全部完成**。
