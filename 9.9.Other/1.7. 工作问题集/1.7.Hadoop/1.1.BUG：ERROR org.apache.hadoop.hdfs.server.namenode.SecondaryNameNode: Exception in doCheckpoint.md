BUG：ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
==============================================================================================
### 概念介绍
**`hadoop.tmp.dir`配置参数指定`hdfs`的默认临时路径。这个最好配置，如果在新增节点或者其他情况下莫名其妙的
`DataNode`启动不了，就删除此文件中的`tmp`目录即可**。不过如果删除了`NameNode`机器的此目录，那么就需要
**重新执行`NameNode`格式化的命令**。

`hadoop.tmp.dir`，此参数最好在安装时进行配置：
```xml
<!-- etc/hadoop/core-site.xml -->
<property>
    <name>hadoop.tmp.dir</name>
    <value>/data/hadoop/tmp</value>
</property>
```

### hdfs的SecondaryNameNode的日志报Inconsistent checkpoint fields异常的原因
最近在本机测试`hadoop`伪分布模式时，发现`hadoop-fuhd-secondarynamenode-ubuntu.log`的日志总是报
`Inconsistent checkpoint fields`异常：
```
2017-12-21 13:44:55,313 ERROR org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode: Exception in doCheckpoint
java.io.IOException: Inconsistent checkpoint fields.
LV = -64 namespaceID = 1272541873 cTime = 1513833510412 ; clusterId = CID-7dc1ec62-68a8-4818-a262-cba0c233c008 ; blockpoolId = BP-309176173-127.0.1.1-1513833510412.
Expecting respectively: -64; 2055687505; 1513829213135; CID-51c7fa1a-685b-4335-9e1a-661a283e1742; BP-916121108-127.0.1.1-1513829213135.
	at org.apache.hadoop.hdfs.server.namenode.CheckpointSignature.validateStorageInfo(CheckpointSignature.java:143)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doCheckpoint(SecondaryNameNode.java:550)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.doWork(SecondaryNameNode.java:360)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode$1.run(SecondaryNameNode.java:325)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:481)
	at org.apache.hadoop.hdfs.server.namenode.SecondaryNameNode.run(SecondaryNameNode.java:321)
	at java.lang.Thread.run(Thread.java:748)
```
**此异常即是配置`hadoop.tmp.dir`参数引起的，在`hdfs-site.xml`中增加此参数，重新启动即可**。