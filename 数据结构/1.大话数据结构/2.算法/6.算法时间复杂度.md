算法时间复杂度
======================================================
### 算法时间复杂度定义
在进行算法分析时，语句总的执行次数`T(n)`是关于问题规模`n`的函数，进而分析`T(n)`随`n`的变化情况并确定
`T(n)`的数量级。算法的时间复杂度，也就是算法的时间量度，记作：**`T(n)＝O(f(n))`**。它表示随问题规模`n`的增大，
算法执行时间的增长率和`f(n)`的增长率相同，称作算法的渐近时间复杂度，简称为时间复杂度。其中`f(n)`是问题
规模`n`的某个函数。
+ `n`：问题规模；
+ `f(n)`：问题规模`n`的某个函数；
+ `T(n)`：关于问题规模`n`的总的执行次数的函数；

这样用大写`O()`来体现算法时间复杂度的记法，我们称之为 **大`O`记法**。一般情况下，**随着`n`的增大，`T(n)`增长最慢
的算法为最优算法**。

### 推导大O阶方法
那么如何分析一个算法的时间复杂度呢？即如何推导大O阶呢？我们给出了下面的推导方法：
+ **用常数1取代运行时间中的所有加法常数**。
+ **在修改后的运行次数函数中，只保留最高阶项**。
+ **如果最高阶项存在且不是1，则去除与这个项相乘的常数**。

这样，得到的结果就是大O阶。

### 常数阶
如下示例，为什么时间复杂度不是`O(3)`，而是`O(1)`：
```C
int sum = 0, n = 100;       //执行一次
sum = (i + n) * n/2；       //执行一次
printf("%d", sum);          //执行一次
```
这个算法的运行次数函数是`f(n)=3`。根据推导大O阶的方法，第一步就是把常数项3改为1。在保留最高阶项时发现，
它根本没有 最高阶项，所以这个算法的时间复杂度为`O(1)`。

事实上无论`n`为多少，这种与问题的大小无关（`n`的多少）,执行时间恒定的算法，我们称之为具有`O(1)`的
时间复杂度，又叫 **常数阶**。

**注意：不管这个常数是多少，我们都记作`O(1)`，而不能是`O(3)`，`O(12)`等其他任何数字，这是初学者常常犯的错误**。

对于分支结构而言，无论是真，还是假，执行的次数都是恒定的，不会随着`n`的变大而发生变化，所以单纯的分支结构
（不包含在循环结构中），其时间复杂度也是`O(1)`。

### 线性阶
**线性阶的循环结构会复杂很多**。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个语句集运行的次数。
因此，**我们要分析算法的复杂度，关键就是要分析循环结构的运行情况**。示例：
```C
int i;
for (i = 0; i < n; i++) {
    // 时间复杂度为O(1)的程序步骤序列
}
```
上面这段代码，它的循环的时间复杂度为 **`O(n)`**，因为循环体中的代码须要执行`n`次。

### 对数阶
下面的这段代码，时间复杂度又是多少呢？
```C
int count = 1;
while (count < n) {
    count = count * 2;
    //时间复杂度为O(1)的程序步骤序列
}
```
由于每次`count`乘以2之后，就距离`n`更近了一分。也就是说，有多少个2相乘后大于`n`，则会退出循环。
由2的`x`次方等于`n`得到`x`等于`log`以2为底的`n`的 **对数**。所以这个循环的时间复杂度为 **`O(logn)`**。

### 平方阶
下面例子是一个循环嵌套，它的内循环上面已经分析过了，时间复杂度为`O(n)`：
```C
int i,j;
for (i = 0; i < n; i++) {
    for (j = 0; j < n; j++) {
        //时间复杂度为O(1)的程序步骤序列
    }
}
```
而对于外层的循环，不过是内部这个时间复杂度为`O(n)`的语句，再循环`n`次。所以这段代码的时间复杂度为 **`O(n2)`**。

那么下面这个循环嵌套，它的时间复杂度是多少？
```C
int i,j;
for (i = 0; i < n; i++) {
    //注意是j = i，而不是0
    for (j = i; j < n; j++) {
        //时间复杂度为O(1)的程序步骤序列
    }
}
```
运算次数为：**n2/2 + n/2**。用我们推导大O阶的方法，第一次，没有加法常数不考虑；第二条，只保留最高阶项，
因此保留`n2/2`；第三条，去除这个项相乘的常数，也就是去除`1/2`，最终这段代码的时间复杂度为 **`O(n2)`**。
